[
  {
    "objectID": "syllabus.html",
    "href": "syllabus.html",
    "title": "Syllabus",
    "section": "",
    "text": "Location: In person for Fall 2023\nCourse time: Tuesdays and Thursdays from 1:30-2:50pm (Eastern Daylight Time zone)\nCourse location: W4030\nAssignments: Four projects\n\n\n\n\nStephanie C. Hicks (https://www.stephaniehicks.com)\n\nOffice Location: E3545, Wolfe Street building\nEmail: shicks19@jhu.edu\n\n\nI am an Associate Professor in the Department of Biostatistics at the Bloomberg School of Public Health and Department of Biomedical Engineering in the Whiting School of Engineering at Johns Hopkins University, a faculty member of the Johns Hopkins Data Science Lab, and have affiliations with the Malone Center for Engineering in Healthcare, Center for Computational Biology, the Department of Genetic Medicine, and the Department of Biochemistry and Molecular Biology.\nMy research focuses on developing fast, scalable, statistical methodology and open-source software for genomics and biomedical data analysis for human health and disease. My research is problem-forward: I develop statistical methods and software that are motivated by concrete problems, often with real-world, noisy, messy data. I’m also interested in developing theory for how to incorporate design thinking (alongside statistical thinking) in practice of data analysis.\nIf you want, you can find me on Twitter. I’m also a co-host of the The Corresponding Author podcast, member of the Editorial Board for Genome Biology, an Associate Editor for Reproducibility at the Journal of the American Statistical Association, and co-founder of R-Ladies Baltimore.\n\n\n\nJoe Sartini (jsartin1@jhu.edu) is a third year Ph.D. student in Biostatistics, with interest in models for precision medicine applications. Currently, the focus of his work is extracting meaningful insights from time-series produced by Continuous Glucose Monitoring and other devices worn by Type 2 diabetics. Outside of research, he enjoys participating in endurance sports and weightlifting.\nAngela Zhao (azhao29@jh.edu) is a second year ScM student in Biostatistics interested in functional data analysis and stochastic models. Her main projects involve using physical activity data derived from wearable devices to predict time-to-event outcomes. For leisure, she enjoys bouldering and stand-up comedy.\nInstructor and TA office hours are announced on CoursePlus. If there are conflicts and/or need to cancel office hours, announcements will be made on CoursePlus.\n\n\n\n\nCourse website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023\n\n\n\n\nUpon successfully completing this course, students will be able to:\n\nWrite unix code with command-line tools\nInstall and configure software necessary for a statistical programming environment and with version control\nWrite code for advanced programming topics in R, Python, SQL, and tidyverse\nBuild and organize a software package with documentation for publishing on the internet\nWrite code using functional or other programming paradigms and discuss strategies for getting data from APIs or working with large data\nBuild an interactive web application using Shiny or other dashboard tools"
  },
  {
    "objectID": "syllabus.html#instructor",
    "href": "syllabus.html#instructor",
    "title": "Syllabus",
    "section": "",
    "text": "Stephanie C. Hicks (https://www.stephaniehicks.com)\n\nOffice Location: E3545, Wolfe Street building\nEmail: shicks19@jhu.edu\n\n\nI am an Associate Professor in the Department of Biostatistics at the Bloomberg School of Public Health and Department of Biomedical Engineering in the Whiting School of Engineering at Johns Hopkins University, a faculty member of the Johns Hopkins Data Science Lab, and have affiliations with the Malone Center for Engineering in Healthcare, Center for Computational Biology, the Department of Genetic Medicine, and the Department of Biochemistry and Molecular Biology.\nMy research focuses on developing fast, scalable, statistical methodology and open-source software for genomics and biomedical data analysis for human health and disease. My research is problem-forward: I develop statistical methods and software that are motivated by concrete problems, often with real-world, noisy, messy data. I’m also interested in developing theory for how to incorporate design thinking (alongside statistical thinking) in practice of data analysis.\nIf you want, you can find me on Twitter. I’m also a co-host of the The Corresponding Author podcast, member of the Editorial Board for Genome Biology, an Associate Editor for Reproducibility at the Journal of the American Statistical Association, and co-founder of R-Ladies Baltimore."
  },
  {
    "objectID": "syllabus.html#teaching-assistants",
    "href": "syllabus.html#teaching-assistants",
    "title": "Syllabus",
    "section": "",
    "text": "Joe Sartini (jsartin1@jhu.edu) is a third year Ph.D. student in Biostatistics, with interest in models for precision medicine applications. Currently, the focus of his work is extracting meaningful insights from time-series produced by Continuous Glucose Monitoring and other devices worn by Type 2 diabetics. Outside of research, he enjoys participating in endurance sports and weightlifting.\nAngela Zhao (azhao29@jh.edu) is a second year ScM student in Biostatistics interested in functional data analysis and stochastic models. Her main projects involve using physical activity data derived from wearable devices to predict time-to-event outcomes. For leisure, she enjoys bouldering and stand-up comedy.\nInstructor and TA office hours are announced on CoursePlus. If there are conflicts and/or need to cancel office hours, announcements will be made on CoursePlus."
  },
  {
    "objectID": "syllabus.html#important-links",
    "href": "syllabus.html#important-links",
    "title": "Syllabus",
    "section": "",
    "text": "Course website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023"
  },
  {
    "objectID": "syllabus.html#learning-objectives",
    "href": "syllabus.html#learning-objectives",
    "title": "Syllabus",
    "section": "",
    "text": "Upon successfully completing this course, students will be able to:\n\nWrite unix code with command-line tools\nInstall and configure software necessary for a statistical programming environment and with version control\nWrite code for advanced programming topics in R, Python, SQL, and tidyverse\nBuild and organize a software package with documentation for publishing on the internet\nWrite code using functional or other programming paradigms and discuss strategies for getting data from APIs or working with large data\nBuild an interactive web application using Shiny or other dashboard tools"
  },
  {
    "objectID": "syllabus.html#courseplus",
    "href": "syllabus.html#courseplus",
    "title": "Syllabus",
    "section": "Courseplus",
    "text": "Courseplus\nThe primary communication for the class will go through Courseplus. That is where we will post course announcements, share resources, host most of our asynchronous course discussion, and as the primary means of communication between course participants and course instructors\n\n\n\n\n\n\nImportant\n\n\n\nIf you are registered for the course, you should have access to Courseplus now. Once you have access you will also be able to find all material and dates/times of drop-in hours. Any zoom links will be posted on Courseplus.\n\n\nThe course will make use of the CoursePlus Discussion Forum in order to ask and answer questions regarding any of the course materials. The Instructor and the Teaching Assistant will monitor the discussion boards and answer questions when appropriate."
  },
  {
    "objectID": "syllabus.html#github",
    "href": "syllabus.html#github",
    "title": "Syllabus",
    "section": "GitHub",
    "text": "GitHub\nYou can access all course materials (e.g. lectures, project assignments) here\n\nCourse website: https://stephaniehicks.com/jhustatprogramming2023\nGitHub repository with all course material: https://github.com/stephaniehicks/jhustatprogramming2023"
  },
  {
    "objectID": "syllabus.html#lectures",
    "href": "syllabus.html#lectures",
    "title": "Syllabus",
    "section": "Lectures",
    "text": "Lectures\nThis is course has only one section ending in .01, which means it is an Onsite Synchronous course. This means you are expected to attend class in person. While, I will record the lectures via a zoom recording, I do not plan to post the recordings on CoursePlus. If you have an unexpected / emergency event that comes up and you are unable to attend the lecture in person, you can email me to ask for the recording. I just ask that you briefly provide 1 sentence explanation.\nAttendance is not taken, but I strongly encourage you to attend class to ask questions and participate in class exercises. You will get as much out of the course as you put into it."
  },
  {
    "objectID": "syllabus.html#getting-help",
    "href": "syllabus.html#getting-help",
    "title": "Syllabus",
    "section": "Getting help",
    "text": "Getting help\nIn order of preference, here is a preferred list of ways to get help:\n\nWe strongly encourage you to use Courseplus to ask questions first, before joining office hours. The reason for this is so that other students in the class (who likely have similar questions) can also benefit from the questions and answers asked by your colleagues.\nYou are welcome to join office hours to get more group interactive feedback.\nIf you are not able to make the office hours, appointments can be made by email with the instructor."
  },
  {
    "objectID": "syllabus.html#textbook-and-other-course-material",
    "href": "syllabus.html#textbook-and-other-course-material",
    "title": "Syllabus",
    "section": "Textbook and Other Course Material",
    "text": "Textbook and Other Course Material\nThere is no required textbook. We will make use of several freely available textbooks and other materials. All course materials will be provided. We will use the R and Python software for data analysis, which is freely available for download."
  },
  {
    "objectID": "syllabus.html#software",
    "href": "syllabus.html#software",
    "title": "Syllabus",
    "section": "Software",
    "text": "Software\nWe will make heavy use of R in this course, so you should have R installed. You can obtain R from the Comprehensive R Archive Network. There are versions available for Mac, Windows, and Unix/Linux. This software is required for this course.\nIt is important that you have the latest version of R installed. For this course we will be using R version 4.3.1. You can determine what version of R you have by starting up R and typing into the console R.version.string and hitting the return/enter key. If you do not have this version of R installed, go to CRAN and download and install the latest version.\nWe will also make use of the RStudio interactive development environment (IDE). RStudio requires that R be installed, and so is an “add-on” to R. You can obtain the RStudio Desktop for free from the RStudio web site. In particular, we will make heavy use of it when developing R packages. It is also essential that you have the latest release of RStudio. You can determine the version of RStudio by looking at menu item Help &gt; About RStudio. You should be using RStudio version 2023.09.1+494 (2023.09.1+494) or higher, which requires R version 3.3.0 or higher."
  },
  {
    "objectID": "syllabus.html#projects",
    "href": "syllabus.html#projects",
    "title": "Syllabus",
    "section": "Projects",
    "text": "Projects\nThere will be 4 assignments, due every 2–3 weeks. Projects will be submitted electronically via the Drop Box on the CoursePlus web site (unless otherwise specified).\nThe project assignments will be due on\n\nProject 1: Friday November 10, 11:59pm\nProject 2: Tuesday November 28, 11:59pm\nProject 3: Tuesday December 12, 11:59pm\nProject 4: Friday December 22, 11:59pm\n\n\nProject collaboration\nPlease feel free to study together and talk to one another about project assignments. The mutual instruction that students give each other is among the most valuable that can be achieved.\nHowever, it is expected that project assignments will be implemented and written up independently unless otherwise specified. Specifically, please do not share analytic code or output. Please do not collaborate on write-up and interpretation. Please do not access or use solutions from any source before your project assignment is submitted for grading."
  },
  {
    "objectID": "syllabus.html#exams",
    "href": "syllabus.html#exams",
    "title": "Syllabus",
    "section": "Exams",
    "text": "Exams\nThere are no exams in this course."
  },
  {
    "objectID": "syllabus.html#grading",
    "href": "syllabus.html#grading",
    "title": "Syllabus",
    "section": "Grading",
    "text": "Grading\nGrades in the course will be based on Projects 1–4. Grades for the projects and the final grade will be issued via the CoursePlus grade book.\n\nRelative weights\nThe grades are based on four projects. The breakdown of grading will be\n\n25% for Project 1\n25% for Project 2\n25% for Project 3\n25% for Project 4"
  },
  {
    "objectID": "syllabus.html#policy-for-submitted-projects-late",
    "href": "syllabus.html#policy-for-submitted-projects-late",
    "title": "Syllabus",
    "section": "Policy for submitted projects late",
    "text": "Policy for submitted projects late\n\n\n\n\n\n\nImportant\n\n\n\nThe instructor and TA(s) will not accept email late day policy requests.\n\n\nThis is the policy for late submissions that applies to Projects 1-4.\n\nEach student will be given three “free late days” for the rest of the course.\nA late day extends the individual project deadline by 24 hours without penalty.\nThe late days can be applied to just one project (e.g. two late days for Project 2), or they can be split across the two projects (one late day for Project 2 and one late day for Project 3). This is entirely left up to the discretion of the student.\nA max of two “free late days” can be applied to any one project.\nFree late days are intended to give you flexibility: you can use them for any reason no questions asked.\nYou do not get any bonus points for not using your late days.\n\nAlthough the each student is only given a total of three “free late days”, we will be accepting homework from students that pass this limit.\n\nWe will deduct 5% off the 100% starting point for each day the assignment is late.\nIf you use two “free late days” for project, but need a 3rd day, there will be no penalty for the first two late days and there will be a 5% penalty for the 3rd late day.\nIf you do not have any more late days for the term, we will deduct 5% for the assignment that is &lt;24 hours late, 10% points for the assignment that is 24-48 hours late, and 15% points for the assignment that is 48-72 hours late.\n\n\n\n\n\n\n\nImportant\n\n\n\nWe will not grade assignments that are more than 3 days (or more than 72 hours) past the original due date.\n\n\n\nRegrading Policy\nIt is very important to us that all assignments are properly graded. If you believe there is an error in your assignment grading, please send an email to the instructor within 7 days of receiving the grade. No re-grade requests will be accepted orally, and no regrade requests will be accepted more than 7 days after you receive the grade for the assignment."
  },
  {
    "objectID": "syllabus.html#use-of-ai-tools",
    "href": "syllabus.html#use-of-ai-tools",
    "title": "Syllabus",
    "section": "Use of AI tools",
    "text": "Use of AI tools\nUse of AI tools (including ChatGPT, Bard, Microsoft Copilot, etc) to assist in completing this assignment/exam is permitted with your writing and/or programming. Be aware, however, that such tools often introduce errors or fabricate information; it is your responsibility to ensure the factual accuracy of whatever you claim as your writing/code. I recommend using such tools particularly for learning to code, just make sure the code does what it is supposed to, and that you understand what the code does.\nWith respect to writing, as with all sources, proper references and use of quotation marks should be used (if precise language generated by the software is used). The reference must include the website and specific prompts used to generate the referenced output."
  },
  {
    "objectID": "syllabus.html#academic-ethics-and-student-conduct-code",
    "href": "syllabus.html#academic-ethics-and-student-conduct-code",
    "title": "Syllabus",
    "section": "Academic Ethics and Student Conduct Code",
    "text": "Academic Ethics and Student Conduct Code\nStudents enrolled in the Bloomberg School of Public Health of The Johns Hopkins University assume an obligation to conduct themselves in a manner appropriate to the University’s mission as an institution of higher education. A student is obligated to refrain from acts which he or she knows, or under the circumstances has reason to know, impair the academic integrity of the University. Violations of academic integrity include, but are not limited to: cheating; plagiarism; knowingly furnishing false information to any agent of the University for inclusion in the academic record; violation of the rights and welfare of animal or human subjects in research; and misconduct as a member of either School or University committees or recognized groups or organizations.\nStudents should be familiar with the policies and procedures specified under Policy and Procedure Manual Student-01 (Academic Ethics), available on the school’s portal.\nThe faculty, staff and students of the Bloomberg School of Public Health and the Johns Hopkins University have the shared responsibility to conduct themselves in a manner that upholds the law and respects the rights of others. Students enrolled in the School are subject to the Student Conduct Code (detailed in Policy and Procedure Manual Student-06) and assume an obligation to conduct themselves in a manner which upholds the law and respects the rights of others. They are responsible for maintaining the academic integrity of the institution and for preserving an environment conducive to the safe pursuit of the School’s educational, research, and professional practice missions.\n\nCourse code of Conduct\nWe are committed to providing a welcoming, inclusive, and harassment-free experience for everyone, regardless of gender, gender identity and expression, age, sexual orientation, disability, physical appearance, body size, race, ethnicity, religion (or lack thereof), political beliefs/leanings, or technology choices. We do not tolerate harassment of course participants in any form. Sexual language and imagery is not appropriate for any work event, including group meetings, conferences, talks, parties, Twitter and other online media. This code of conduct applies to all course participants, including instructors and TAs, and applies to all modes of interaction, both in-person and online, including GitHub project repos, Slack channels, and Twitter.\nCourse participants violating these rules will be referred to leadership of the Department of Biostatistics and the Title IX coordinator at JHU and may face expulsion from the class.\nAll class participants agree to:\n\nBe considerate in speech and actions, and actively seek to acknowledge and respect the boundaries of other members.\nBe respectful. Disagreements happen, but do not require poor behavior or poor manners. Frustration is inevitable, but it should never turn into a personal attack. A community where people feel uncomfortable or threatened is not a productive one. Course participants should be respectful both of the other course participants and those outside the course.\nRefrain from demeaning, discriminatory, or harassing behavior and speech. Harassment includes, but is not limited to: deliberate intimidation; stalking; unwanted photography or recording; sustained or willful disruption of talks or other events; inappropriate physical contact; use of sexual or discriminatory imagery, comments, or jokes; and unwelcome sexual attention. If you feel that someone has harassed you or otherwise treated you inappropriately, please alert Stephanie Hicks.\nTake care of each other. Refrain from advocating for, or encouraging, any of the above behavior. And, if someone asks you to stop, then stop. Alert Stephanie Hicks if you notice a dangerous situation, someone in distress, or violations of this code of conduct, even if they seem inconsequential.\n\n\n\nNeed Help?\nPlease speak with Stephanie Hicks or one of the TAs. You can also reach out to Karen Bandeen-Roche, chair of the department of Biostatistics or Margaret Taub, Ombudsman for the Department of Biostatistics.\nYou may also reach out to any Hopkins resource for sexual harassment, discrimination, or misconduct:\n\nJHU Sexual Assault Helpline, 410-516-7333 (confidential)\n\nUniversity Sexual Assault Response and Prevention website\nJohns Hopkins Compliance Hotline, 844-SPEAK2US (844-733-2528)\nHopkins Policies Online\nJHU Office of Institutional Equity 410-516-8075 (nonconfidential)\nJohns Hopkins Student Assistance Program (JHSAP), 443-287-7000\nUniversity Health Services, 410-955-1892\nThe Faculty and Staff Assistance Program (FASAP), 443-997-7000"
  },
  {
    "objectID": "syllabus.html#license-and-attribution",
    "href": "syllabus.html#license-and-attribution",
    "title": "Syllabus",
    "section": "License and attribution",
    "text": "License and attribution\nThis Code of Conduct is distributed under a Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0) license. Portions of above text comprised of language from the Codes of Conduct adopted by rOpenSci and Django, which are licensed by CC BY-SA 4.0 and CC BY 3.0. This work was further inspired by Ada Initiative’s ‘’how to design a code of conduct for your community’’ and Geek Feminism’s Code of conduct evaluations and expanded by Ashley Johnson and Shannon Ellis in the Jeff Leek group."
  },
  {
    "objectID": "syllabus.html#disability-support-service",
    "href": "syllabus.html#disability-support-service",
    "title": "Syllabus",
    "section": "Disability Support Service",
    "text": "Disability Support Service\nStudents requiring accommodations for disabilities should register with Student Disability Service (SDS). It is the responsibility of the student to register for accommodations with SDS. Accommodations take effect upon approval and apply to the remainder of the time for which a student is registered and enrolled at the Bloomberg School of Public Health. Once a student has been approved for accommodations, the student will receive formal notification and the student will be encouraged to reach out to the instructor.\nIf you have questions about requesting accommodations, please contact BSPH.dss@jhu.edu."
  },
  {
    "objectID": "syllabus.html#prerequisites",
    "href": "syllabus.html#prerequisites",
    "title": "Syllabus",
    "section": "Prerequisites",
    "text": "Prerequisites\nPrerequisite for the course is Biostatistics 140.776 or knowledge of material from 140.776 is assumed.\nIf you did not take the above course, please contact course instructor to get permission to enroll."
  },
  {
    "objectID": "syllabus.html#general-disclaimers",
    "href": "syllabus.html#general-disclaimers",
    "title": "Syllabus",
    "section": "General Disclaimers",
    "text": "General Disclaimers\nThis syllabus is a general plan, deviations announced to the class by the instructor may be necessary."
  },
  {
    "objectID": "syllabus.html#typos-and-corrections",
    "href": "syllabus.html#typos-and-corrections",
    "title": "Syllabus",
    "section": "Typos and corrections",
    "text": "Typos and corrections\nFeel free to submit typos/errors/etc via the github repository associated with the class: https://github.com/stephaniehicks/jhustatprogramming2023. You will have the thanks of your grateful instructor!"
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "Resources",
    "section": "",
    "text": "Learning R\n\nBig Book of R: https://www.bigbookofr.com\nList of resources to learn R (but also Python, SQL, Javascript): https://github.com/delabj/datacamp_alternatives/blob/master/index.md\nlearnr4free. Resources (books, videos, interactive websites, papers) to learn R. Some of the resources are beginner-friendly and start with the installation process: https://www.learnr4free.com/en\nData Science with R by Danielle Navarro: https://robust-tools.djnavarro.net"
  },
  {
    "objectID": "projects/2023-11-28-project-3/index.html",
    "href": "projects/2023-11-28-project-3/index.html",
    "title": "Project 3",
    "section": "",
    "text": "library(tidyverse)\n\nDue date: December 12 at 11:59pm\nThe goal of this assignment is to practice building websites for R packages, along with practice functional programming and using APIs.\n\n\nIn both parts below, you will need to create two separate github repositories for yourself. The links to create the repositories will be in CoursePlus.\nThe first one (Part 1) will be a public repository to build a website for an R package. It is public because you will need to deploy the website.\nThe second one (Part 2) will be a private repository to practice using an APIs, practice functional programming, and building data analyses."
  },
  {
    "objectID": "projects/2023-11-28-project-3/index.html#part-1a-create-website-locally",
    "href": "projects/2023-11-28-project-3/index.html#part-1a-create-website-locally",
    "title": "Project 3",
    "section": "Part 1A: Create website locally",
    "text": "Part 1A: Create website locally\nFork the GitHub repository from the original location to your own GitHub account. Clone the repository to your local computer.\nUse usethis and pkgdown to create a website locally for the R package of your choice."
  },
  {
    "objectID": "projects/2023-11-28-project-3/index.html#part-1b-customize-the-website",
    "href": "projects/2023-11-28-project-3/index.html#part-1b-customize-the-website",
    "title": "Project 3",
    "section": "Part 1B: Customize the website",
    "text": "Part 1B: Customize the website\nHere, you need to customize the website in at least 5 ways. How you customize is up to you. The pkgdown website has lots of suggestions for you to try out!"
  },
  {
    "objectID": "projects/2023-11-28-project-3/index.html#part-1c-create-an-example-data-analysis",
    "href": "projects/2023-11-28-project-3/index.html#part-1c-create-an-example-data-analysis",
    "title": "Project 3",
    "section": "Part 1C: Create an example data analysis",
    "text": "Part 1C: Create an example data analysis\nIn this part, you will create a data analysis (or a case study) where you demonstrate the functions in the R package. Specifically, you will add another article or vignette titled “Example analysis” inside the /vignettes folder.\nSimilar to Project 2, you must pick out a data set from TidyTuesday that you have not worked with before (i.e. not in a previous project or assignment from this class or from 776, but other classes or personal projects are acceptable). You must also demonstrate wrangling and plotting the data. Finally, your example analysis, must also demonstrate at least 2 functions from the R package in some way in the vignette.\nOther requirements for this part of vignette are the following:\n\nPick any data set you wish from TidyTuesday to analyze.\n\n\nYou must describe what is the question you aim to answer with the data and data analysis.\nYou must describe and link to where the original data come from that you chose.\nYou must include a link to a data dictionary for the data or create one inside the webpage.\n\n\nLoad the data into R\n\n\nIn this step, you must test if a directory named data exists locally. If it does not, write an R function that creates it programmatically.\n\nSaves the data only once (not each time you knit/render the document).\nRead in the data locally each time you knit/render.\n\n\nYour analysis must include some form of data wrangling and data visualization.\n\n\nYou must use at least six different functions from dplyr, tidyr, lubridate, stringr, or forcats.\nYou must use at least two functions from purrr.\nYour analysis should include at least three plots with you using at least three different geom_*() functions from ggplot2 (or another package with geom_*() functions).\n\nPlots should have titles, subtitles, captions, and human-understandable axis labels.\nAt least one plot should using a type of faceting (facet_grid() or facet_wrap()).\n\n\n\nApply at least 2 functions from the R package in the vignette.\nSummarize and interpret the results in 1-2 sentences.\nAt the end of the data analysis, list out each of the functions you used from each of the packages (dplyr, tidyr, ggplot2, etc) to help the TA with respect to making sure you met all the requirements described above."
  },
  {
    "objectID": "projects/2023-11-28-project-3/index.html#part-1d-create-a-readme.md-file",
    "href": "projects/2023-11-28-project-3/index.html#part-1d-create-a-readme.md-file",
    "title": "Project 3",
    "section": "Part 1D: Create a README.md file",
    "text": "Part 1D: Create a README.md file\nIf the package does not already include one, create and include a README.md file in the folder where the R package and pkgdown files are on your computer and add the following information below.\nIf it already has a README.md file, just edit the top of the file with the following information:\n\nInclude a URL to the GitHub link to where the original R package came from.\nInclude a URL to the deployed website that you will do in Part 1E, but it should be something like https://jhu-statprogramming-fall-2022.github.io/biostat840-project3-pkgdown-&lt;your_github_username&gt;.\nInclude a description of the 5 things you customized in your pkgdown website (excluding adding the example data analysis from Part 1C).\n\nThe readme must also include (if it does not already):\n\nThe title of package\nThe original author of the package (and you who made the website and example data analysis)\nA goal / description of the package\nA list of exported functions that are in the package. Briefly describe each function.\nA basic example with one of the functions."
  },
  {
    "objectID": "projects/2023-11-28-project-3/index.html#part-1e-deploy-the-website",
    "href": "projects/2023-11-28-project-3/index.html#part-1e-deploy-the-website",
    "title": "Project 3",
    "section": "Part 1E: Deploy the website",
    "text": "Part 1E: Deploy the website\nThe link to create a public GitHub repository for yourself to complete this part of Project 3 will be posted in CoursePlus. This creates an empty GitHub repository.\nWhen ready, deploy the website.\n\n\n\n\n\n\nNote\n\n\n\nYou need to modify the template code that is provided to you from GitHub when you set the remote. When you fork the repository, there will already be a remote origin (from where you cloned the remote repository to your local repository), which you can see with\n\n\nBash\n\ngit remote -v\n\nIn GitHub Classroom, you will create a repo for this part of the project. When you click on the link in the Courseplus discussion form to create the link, you will see this line:\n\n\nBash\n\ngit remote add origin &lt;link&gt;\n\nInstead of pushing to the forked repository, you want to change where you push your code (i.e. you want to push to the private repo on GitHub Classroom). To do this, you want ot change the above line to this where &lt;link&gt; is the GitHub Classroom link:\n\n\nBash\n\ngit remote add upstream &lt;link&gt;\n\nand when you push your code, you want to use git push -u upstream main, for example (not git push -u origin main)."
  },
  {
    "objectID": "projects/2023-10-26-project-1/index.html",
    "href": "projects/2023-10-26-project-1/index.html",
    "title": "Project 1",
    "section": "",
    "text": "Due date: November 10 at 11:59pm\nThe goal of this assignment is to practice some of the skills we have been learning about in class around Quarto, command-line, and version control by building and deploying a website. You also are asked to practice with some command-line skills more formally.\n\n\nPlease use this Quarto file (.qmd) and fill in the requested components by adding the URLs pointing to the private and public repositories and deployed websites. Render this file to a HTML file and submit your HTML file to the dropbox on CoursePlus. Please show all your code, if relevant to a section."
  },
  {
    "objectID": "projects/2023-10-26-project-1/index.html#create-a-github-repo-for-your-website",
    "href": "projects/2023-10-26-project-1/index.html#create-a-github-repo-for-your-website",
    "title": "Project 1",
    "section": "1. Create a GitHub repo for your website",
    "text": "1. Create a GitHub repo for your website\nCreate a new public GitHub repository titled biostat777-intro-&lt;firstname&gt;-&lt;lastname&gt; (where you replace &lt;firstname&gt; with your first name and &lt;lastname&gt; with your last name) in your own personal GitHub account (e.g. https://github.com/&lt;yourgithubusername&gt;/biostat777-intro-&lt;firstname&gt;-&lt;lastname&gt;)."
  },
  {
    "objectID": "projects/2023-10-26-project-1/index.html#build-a-website-using-quarto",
    "href": "projects/2023-10-26-project-1/index.html#build-a-website-using-quarto",
    "title": "Project 1",
    "section": "2. Build a website using Quarto",
    "text": "2. Build a website using Quarto\nCreate a new project locally within RStudio and build a website for yourself. Your website should include the following:\n\nA home/landing page. This is home page that someone will land on your website. At minimum it should include your name, a short summary about yourself (max 2-3 sentences), and a picture of something you enjoy to do for fun (or a picture of yourself if you are comfortable sharing one).\nA page titled ‘About’. This page should describe who you are in greater detail. It could include your professional interests and your educational and/or professional background and/or experience. It could also include any personal information you feel conformable sharing on the website.\nA data analysis page called ‘Example analysis’. You can pick any dataset you wish you analyze. In this webpage, you will analyze a dataset and summarize the results. The requirements for this webpage are the following:\n\nYou must describe what is the question you aim to answer with the data and data analysis.\nYou must describe who is the intended audience for the data analysis.\nYou must describe and link to where the original data come from that you chose.\nYou must include a link to a data dictionary for the data or create one inside the webpage.\nYour analysis must include some minimal form of data wrangling with you using at least five different functions from dplyr or tidyr.\nYour analysis should include at least three plots with you using at least three different geom_*() functions from ggplot2 (or another package with geom_*() functions).\nPlots should have titles, subtitles, captions, and human-understandable axis labels.\nAt least one plot should using a type of faceting (facet_grid() or facet_wrap()).\nYour analysis must include one image or table (not one you created yourself, but one you have saved locally or one from the web).\nYour analysis must include at least two different callout blocks.\nYour analysis must include a .bib file, which you use to reference at least three unique citations. For example, it could be to a website or paper from where the original data came from or it could be to a paper describing a method you are using to analyze the data.\nYour analysis must include the use of at least 1 margin content.\nYou must summarize your analysis and/or results with a paragraph (4-6 sentences).\nAt the end of the data analysis, list out each of the functions you used from each of the packages (dplyr, tidyr, and ggplot2) to help the TA with respect to making sure you met all the requirements described above."
  },
  {
    "objectID": "projects/2023-10-26-project-1/index.html#include-a-readme.md-file",
    "href": "projects/2023-10-26-project-1/index.html#include-a-readme.md-file",
    "title": "Project 1",
    "section": "3. Include a README.md file",
    "text": "3. Include a README.md file\nYour local repository should include a README.md file describing who is the author of the website and a link to the website after it has been deployed. Other things you might include are the technical details for how the website was created and/or deployed."
  },
  {
    "objectID": "projects/2023-10-26-project-1/index.html#deploy-your-website",
    "href": "projects/2023-10-26-project-1/index.html#deploy-your-website",
    "title": "Project 1",
    "section": "4. Deploy your website",
    "text": "4. Deploy your website\nDeploy your website using Quarto Pub, GitHub pages, or Netlify. (Note: Deploying your website to RPubs will not be accepted)."
  },
  {
    "objectID": "projects/2023-10-26-project-1/index.html#share-your-website",
    "href": "projects/2023-10-26-project-1/index.html#share-your-website",
    "title": "Project 1",
    "section": "5. Share your website",
    "text": "5. Share your website\nGo to the Discussion Board in CoursePlus and write a short post with a link (URL) to your website (and URL to the corresponding GitHub repository) that you created. Also, list the URLs below for the purposes of grading.\nAs you read the introductions from other folks in the class, feel free to comment/reply using Discussion board.\n\nLink to your GitHub repository: [Delete this text and replace the text with the link to the public GitHub repo you created above for your website]\nLink to your deployed website: [Delete this and replace the text with the link to the public deployed website you created above]"
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html",
    "title": "Strategies for dealing with large data",
    "section": "",
    "text": "Material for this lecture was borrowed and adopted from\n\nA great blog post from 2019 by Alex Gold from RStudio.\nhttps://www.stephaniehicks.com/jhustatcomputing2021/posts/2021-10-12-dealing-with-large-data"
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#loading-data-into-memory",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#loading-data-into-memory",
    "title": "Strategies for dealing with large data",
    "section": "Loading data into memory",
    "text": "Loading data into memory\nLet’s say you are able load part of the data into the RAM on your machine (in-memory).\nIf you had something like a zipped .csv file, you could always try loading just the first few lines into memory (see n_max = 8 below) to see what is inside the files, but eventually you will likely need a different strategy.\n\nread_csv(readr_example(\"mtcars.csv.bz2\"), \n         skip = 0, n_max = 8, progress = show_progress())\n\n# A tibble: 8 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  21       6  160    110  3.9   2.62  16.5     0     1     4     4\n2  21       6  160    110  3.9   2.88  17.0     0     1     4     4\n3  22.8     4  108     93  3.85  2.32  18.6     1     1     4     1\n4  21.4     6  258    110  3.08  3.22  19.4     1     0     3     1\n5  18.7     8  360    175  3.15  3.44  17.0     0     0     3     2\n6  18.1     6  225    105  2.76  3.46  20.2     1     0     3     1\n7  14.3     8  360    245  3.21  3.57  15.8     0     0     3     4\n8  24.4     4  147.    62  3.69  3.19  20       1     0     4     2"
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#memory-for-calculations",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#memory-for-calculations",
    "title": "Strategies for dealing with large data",
    "section": "Memory for calculations",
    "text": "Memory for calculations\nYou have to keep in mind that you will need to do something with the data too (typically need 2-3 times the RAM of the size of your data).\nThis may or may not be a problem for your hardware that you are working with."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#transfer-speeds-can-be-slow",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#transfer-speeds-can-be-slow",
    "title": "Strategies for dealing with large data",
    "section": "Transfer speeds can be slow",
    "text": "Transfer speeds can be slow\nIf you are working with data on a server that needs to be transferred somewhere to do the processing or computation once the data has been transferred.\nFor example, the time it takes to make a call over the internet from San Francisco to New York City takes over 4 times longer than reading from a standard hard drive and over 200 times longer than reading from a solid state hard drive.\n\n\n\n\n\n[image source]\nThis is an especially big problem early in developing a model or performing a data analysis, when data might have to be pulled repeatedly.\nToday we are going to discuss some strategies (and R packages) for working with big data in R. We will also go through some examples of how to execute these strategies in R."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#sqlite-databases",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#sqlite-databases",
    "title": "Strategies for dealing with large data",
    "section": "SQLite databases",
    "text": "SQLite databases\nOK so as mentioned above, let’s use the SQLite format to demonstrate the strategies for dealing with large data. However, they can easily transfer other data formats.\nReminder: There are several ways to query SQL or SQLite databases in R.\nOk, we will set up the SQLite database using the nycflights13_sqlite() function in the dbplyr package.\n\nlibrary(nycflights13)\nif(!file.exists(here(\"data\", \"nycflights13\", \"nycflights13.sqlite\"))){\n  dir.create(here(\"data\", \"nycflights13\"))\n  dbplyr::nycflights13_sqlite(path=here(\"data\", \"nycflights13\"))\n}\n\nWe can check to see what file has been created\n\nlist.files(here(\"data\", \"nycflights13\"))\n\n[1] \"nycflights13.sqlite\"\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nHow can we use the DBI::dbConnect() function with RSQLite::SQLite() backend to connect to the SQLite database?\n\nlibrary(DBI)\n# try it yourself \n\n\n\nClick here for the answer.\n\n\nlibrary(DBI)\nconn &lt;- dbConnect(RSQLite::SQLite(), \n                  here(\"data\", \"nycflights13\", \"nycflights13.sqlite\"))\nconn\n\n&lt;SQLiteConnection&gt;\n  Path: /Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/data/nycflights13/nycflights13.sqlite\n  Extensions: TRUE\n\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nNext, let’s use the dplyr::tbl() function returns something that feels like a data frame with the flights dataset. Finally, show the first 10 rows of the data frame.\n\n# try it yourself \n\n\n\nClick here for the answer.\n\n\ntbl(conn, \"flights\")  |&gt; \n  head(n=10)\n\n# Source:   SQL [10 x 19]\n# Database: sqlite 3.43.2 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/data/nycflights13/nycflights13.sqlite]\n    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt;          &lt;int&gt;     &lt;dbl&gt;    &lt;int&gt;          &lt;int&gt;\n 1  2013     1     1      517            515         2      830            819\n 2  2013     1     1      533            529         4      850            830\n 3  2013     1     1      542            540         2      923            850\n 4  2013     1     1      544            545        -1     1004           1022\n 5  2013     1     1      554            600        -6      812            837\n 6  2013     1     1      554            558        -4      740            728\n 7  2013     1     1      555            600        -5      913            854\n 8  2013     1     1      557            600        -3      709            723\n 9  2013     1     1      557            600        -3      838            846\n10  2013     1     1      558            600        -2      753            745\n# ℹ 11 more variables: arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;,\n#   tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;,\n#   hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dbl&gt;\n\n\n\n\n\nBefore we jump into the next section, let’s save this data frame as flights_df and count the number of rows using dplyr::tally():\n\nflights_df &lt;- dplyr::tbl(conn, \"flights\")\nflights_df |&gt; \n  tally()\n\n# Source:   SQL [1 x 1]\n# Database: sqlite 3.43.2 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/data/nycflights13/nycflights13.sqlite]\n       n\n   &lt;int&gt;\n1 336776\n\n\nEven though it only has a few hundred thousand rows, it is still useful to demonstrate some strategies for dealing with big data in R."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#advantages",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#advantages",
    "title": "Strategies for dealing with large data",
    "section": "Advantages",
    "text": "Advantages\n\nSpeed. Relative to working on your entire data set, working on just a sample can drastically decrease run times and increase iteration speed.\nPrototyping. Even if you will eventually have to run your model on the entire data set, this can be a good way to refine hyperparameters and do feature engineering for your model.\nPackages. Since you are working on a regular, in-memory data set, you can use all your favorite R packages."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#disadvantages",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#disadvantages",
    "title": "Strategies for dealing with large data",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nSampling. Downsampling is not terribly difficult, but does need to be done with care to ensure that the sample is valid and that you have pulled enough points from the original data set.\nScaling. If you are using sample and model to prototype something that will later be run on the full data set, you will need to have a strategy (such as pushing compute to the data) for scaling your prototype version back to the full data set.\nTotals. Business Intelligence (BI) – or strategies and technologies used by enterprises for the data analysis of business information (e.g. data mining, reporting, predictive analytics, etc) – tasks frequently answer questions about totals, like the count of all sales in a month. One of the other strategies is usually a better fit in this case."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#example",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#example",
    "title": "Strategies for dealing with large data",
    "section": "Example",
    "text": "Example\nLet’s say we want to model whether flights will be delayed or not. We will start with some minor cleaning of the data.\nFirst, we will create a is_delayed column in the database:\n\nflights_df &lt;- \n  flights_df |&gt;\n    dplyr::mutate(is_delayed = arr_delay &gt; 0,\n                  hour = sched_dep_time / 100) |&gt; # Get just hour (currently formatted so 6 pm = 1800)\n    # Remove small carriers that make modeling difficult\n    dplyr::filter(!is.na(is_delayed) & !carrier %in% c(\"OO\", \"HA\"))\n\nHere are the total number of flights that were delayed or not:\n\nflights_df |&gt; \n  dplyr::count(is_delayed)\n\n# Source:   SQL [2 x 2]\n# Database: sqlite 3.43.2 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/data/nycflights13/nycflights13.sqlite]\n  is_delayed      n\n       &lt;int&gt;  &lt;int&gt;\n1          0 194078\n2          1 132897\n\n\nThese classes are reasonably well balanced, but we going to use logistic regression, so I will load a perfectly balanced sample of 40,000 data points.\nFor most databases, random sampling methods do not work smoothly with R.\n\nflights_df |&gt; \n  dplyr::sample_n(size = 1000)\n\nError in `dplyr::sample_n()`:\n! `tbl` must be a data frame, not a\n  &lt;tbl_SQLiteConnection/tbl_dbi/tbl_sql/tbl_lazy/tbl&gt; object.\n\n\nSo it is not suggested to use dplyr::sample_n() or dplyr::sample_frac(). So we will have to be a little more manual.\n\nset.seed(1234)\n\nn_rows &lt;- flights_df |&gt; tally() |&gt; pull()\nidx &lt;- sample(0:n_rows, replace = FALSE)\n\n# Create a modeling data set \n# df_mod &lt;- \n  \n  df_mod &lt;- flights_df |&gt;\n    mutate(x = runif(n()))\n\n\n\n\n\n\n\nNote\n\n\n\ndplyr::collect() forces a computation of a database query and retrieves data into a local tibble\nSo, here, we take the first 5% for each class for training set:\n\ndf_train &lt;- df_mod |&gt;\n  group_by(is_delayed) |&gt;\n  filter(x &lt;= .05) |&gt;\n  collect() \n\n\n\nThen, we take next 5% for test set:\n\ndf_test &lt;- df_mod |&gt;\n  group_by(is_delayed) |&gt;\n  filter(x &gt; .05 & x &lt;= .10) |&gt;\n  collect() # again, this data is now loaded locally\n\n\n# How many are in each group\ncount(df_train, is_delayed)\n\n# A tibble: 2 × 2\n# Groups:   is_delayed [2]\n  is_delayed     n\n       &lt;int&gt; &lt;int&gt;\n1          0  9692\n2          1  6576\n\ncount(df_test, is_delayed)\n\n# A tibble: 2 × 2\n# Groups:   is_delayed [2]\n  is_delayed     n\n       &lt;int&gt; &lt;int&gt;\n1          0 18509\n2          1 12495\n\n\nNow let’s build a model – let’s see if we can predict whether there will be a delay or not by the combination of the carrier, and the month of the flight.\n\nSys.time()\n\n[1] \"2023-12-19 13:20:34 EST\"\n\nmod &lt;- glm(is_delayed ~ carrier + as.factor(month),\n           family = \"binomial\", data = df_train)\nSys.time()\n\n[1] \"2023-12-19 13:20:34 EST\"\n\n\n\nsummary(mod)\n\n\nCall:\nglm(formula = is_delayed ~ carrier + as.factor(month), family = \"binomial\", \n    data = df_train)\n\nCoefficients:\n                   Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)        -0.49800    0.08937  -5.572 2.52e-08 ***\ncarrierAA          -0.16310    0.08809  -1.851 0.064098 .  \ncarrierAS          -0.64695    0.41476  -1.560 0.118805    \ncarrierB6           0.21192    0.08112   2.612 0.008991 ** \ncarrierDL          -0.18266    0.08332  -2.192 0.028361 *  \ncarrierEV           0.46099    0.08120   5.677 1.37e-08 ***\ncarrierF9           0.82748    0.36188   2.287 0.022219 *  \ncarrierFL           0.64539    0.17220   3.748 0.000178 ***\ncarrierMQ           0.45737    0.09141   5.003 5.63e-07 ***\ncarrierUA          -0.05147    0.08132  -0.633 0.526795    \ncarrierUS          -0.06926    0.09743  -0.711 0.477151    \ncarrierVX          -0.30117    0.14905  -2.021 0.043325 *  \ncarrierWN           0.35344    0.10985   3.217 0.001293 ** \ncarrierYV           0.35012    0.39539   0.886 0.375881    \nas.factor(month)2   0.05337    0.08218   0.650 0.516013    \nas.factor(month)3   0.04211    0.07973   0.528 0.597423    \nas.factor(month)4   0.15307    0.07943   1.927 0.053977 .  \nas.factor(month)5  -0.14693    0.07940  -1.851 0.064218 .  \nas.factor(month)6   0.09601    0.07929   1.211 0.225980    \nas.factor(month)7   0.24004    0.07753   3.096 0.001962 ** \nas.factor(month)8   0.03314    0.07838   0.423 0.672471    \nas.factor(month)9  -0.78077    0.08611  -9.067  &lt; 2e-16 ***\nas.factor(month)10 -0.12925    0.07862  -1.644 0.100177    \nas.factor(month)11 -0.20703    0.08102  -2.555 0.010609 *  \nas.factor(month)12  0.55460    0.07954   6.973 3.11e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 21952  on 16267  degrees of freedom\nResidual deviance: 21382  on 16243  degrees of freedom\nAIC: 21432\n\nNumber of Fisher Scoring iterations: 4\n\n\n\n# Out-of-Sample AUROC\ndf_test$pred &lt;- predict(mod, newdata = df_test)\nauc &lt;- suppressMessages(pROC::auc(df_test$is_delayed, df_test$pred))\nauc\n\nArea under the curve: 0.6023\n\n\nAs you can see, this is not a great model, but that’s not the point here!\nInstead, we showed how to build a model on a small subset of a big data set. Including sampling time, this took my laptop a second to run, making it easy to iterate quickly as I want to improve the model. After I’m happy with this model, I could pull down a larger sample or even the entire data set if it is feasible, or do something with the model from the sample."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#advantages-1",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#advantages-1",
    "title": "Strategies for dealing with large data",
    "section": "Advantages",
    "text": "Advantages\n\nFull data set. The entire data set gets used.\nParallelization. If the chunks are run separately, the problem is easy to treat as embarassingly parallel and make use of parallelization to speed runtimes."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#disadvantages-1",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#disadvantages-1",
    "title": "Strategies for dealing with large data",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nNeed Chunks. Your data needs to have separable chunks for chunk and pull to be appropriate.\nPull All Data. Eventually have to pull in all data, which may still be very time and memory intensive.\nStale Data. The data may require periodic refreshes from the database to stay up-to-date since you’re saving a version on your local machine."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#example-1",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#example-1",
    "title": "Strategies for dealing with large data",
    "section": "Example",
    "text": "Example\nIn this case, I want to build another model of on-time arrival, but I want to do it per-carrier. This is exactly the kind of use case that is ideal for chunk and pull.\nI am going to separately pull the data in by carrier and run the model on each carrier’s data.\nI am going to start by just getting the complete list of the carriers.\n\n# Get all unique carriers\ncarriers &lt;- flights_df |&gt; \n  select(carrier) |&gt; \n  distinct() |&gt; \n  pull(carrier)\n\ncarriers\n\n [1] \"9E\" \"AA\" \"AS\" \"B6\" \"DL\" \"EV\" \"F9\" \"FL\" \"MQ\" \"UA\" \"US\" \"VX\" \"WN\" \"YV\"\n\n\nNow, I will write a function that\n\ntakes the name of a carrier as input\npulls the data for that carrier into R\nsplits the data into training and test\ntrains the model\noutputs the out-of-sample AUROC (a common measure of model quality)\n\n\ncarrier_model &lt;- function(carrier_name) {\n  # Pull a chunk of data\n  df_mod &lt;- flights_df |&gt;\n    filter(carrier == carrier_name) |&gt;\n    collect()\n  \n  # Split into training and test\n  split &lt;- df_mod |&gt;\n    rsample::initial_split(prop = 0.9, strata = \"is_delayed\") |&gt; \n    suppressMessages()\n  \n  # Get training data\n  df_train &lt;- split |&gt; \n                rsample::training()\n  \n  # Train model\n  mod &lt;- glm(is_delayed ~ as.factor(month),\n             family = \"binomial\", data = df_train)\n  \n  # Get out-of-sample AUROC\n  df_test &lt;- split |&gt; \n                rsample::testing()\n  df_test$pred &lt;- predict(mod, newdata = df_test)\n  suppressMessages(auc &lt;- pROC::auc(df_test$is_delayed ~ df_test$pred))\n  \n  auc\n}\n\nNow, I am going to actually run the carrier model function across each of the carriers. This code runs pretty quickly, and so I do not think the overhead of parallelization would be worth it.\n\nset.seed(1234)\nmods &lt;- lapply(carriers, carrier_model) |&gt;\n  suppressMessages()\n\nnames(mods) &lt;- carriers\n\nLet’s look at the results.\n\nmods\n\n$`9E`\nArea under the curve: 0.5711\n\n$AA\nArea under the curve: 0.5731\n\n$AS\nArea under the curve: 0.5597\n\n$B6\nArea under the curve: 0.6208\n\n$DL\nArea under the curve: 0.5817\n\n$EV\nArea under the curve: 0.588\n\n$F9\nArea under the curve: 0.5134\n\n$FL\nArea under the curve: 0.5508\n\n$MQ\nArea under the curve: 0.572\n\n$UA\nArea under the curve: 0.6046\n\n$US\nArea under the curve: 0.5811\n\n$VX\nArea under the curve: 0.67\n\n$WN\nArea under the curve: 0.5607\n\n$YV\nArea under the curve: 0.6041\n\n\nSo these models (again) are a little better than random chance. The point was that we utilized the chunk and pull strategy to pull the data separately by logical units and building a model on each chunk."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#advantages-2",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#advantages-2",
    "title": "Strategies for dealing with large data",
    "section": "Advantages",
    "text": "Advantages\n\nUse the Database. Takes advantage of what databases are often best at: quickly summarizing and filtering data based on a query.\nMore Info, Less Transfer. By compressing before pulling data back to R, the entire data set gets used, but transfer times are far less than moving the entire data set."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#disadvantages-2",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#disadvantages-2",
    "title": "Strategies for dealing with large data",
    "section": "Disadvantages",
    "text": "Disadvantages\n\nDatabase Operations. Depending on what database you are using, some operations might not be supported.\nDatabase Speed. In some contexts, the limiting factor for data analysis is the speed of the database itself, and so pushing more work onto the database is the last thing analysts want to do."
  },
  {
    "objectID": "posts/2023-12-19-dealing-with-large-data/index.html#example-2",
    "href": "posts/2023-12-19-dealing-with-large-data/index.html#example-2",
    "title": "Strategies for dealing with large data",
    "section": "Example",
    "text": "Example\nIn this case, I am doing a pretty simple BI task - plotting the proportion of flights that are late by the hour of departure and the airline.\nJust by way of comparison, let’s run this first the naive way -– pulling all the data to my system and then doing my data manipulation to plot.\n\nsystem.time(\n  df_plot &lt;- flights_df |&gt;\n    collect() |&gt;\n    group_by(carrier, sched_dep_time) |&gt;\n    # Get proportion per carrier-time\n    summarize(delay_pct = mean(is_delayed, na.rm = TRUE)) |&gt;\n    ungroup() |&gt;\n    # Change string times into actual times\n    dplyr::mutate(sched_dep_time = \n                    stringr::str_pad(sched_dep_time, 4, \"left\", \"0\") |&gt; \n             strptime(\"%H%M\") |&gt;  # converts character class into POSIXlt class\n             as.POSIXct()) # converts POSIXlt class to POSIXct class\n  ) -&gt; timing1\n\ntiming1\n\n   user  system elapsed \n  0.925   0.015   0.953 \n\n\nNow that wasn’t too bad, just 0.953 seconds on my laptop.\nBut let’s see how much of a speedup we can get from chunk and pull. The conceptual change here is significant - I’m doing as much work as possible in the SQLite server now instead of locally.\nBut using dplyr means that the code change is minimal. The only difference in the code is that the collect() call got moved down by a few lines (to below ungroup()).\n\nsystem.time(\n  df_plot &lt;- flights_df |&gt;\n    dplyr::group_by(carrier, sched_dep_time) |&gt;\n    # Get proportion per carrier-time\n    dplyr::summarize(delay_pct = mean(is_delayed, na.rm = TRUE)) |&gt;\n    dplyr::ungroup() |&gt;\n    dplyr::collect() |&gt;\n    # Change string times into actual times\n    dplyr::mutate(sched_dep_time = \n                    stringr::str_pad(sched_dep_time, 4, \"left\", \"0\") |&gt; \n             strptime(\"%H%M\") |&gt; \n             as.POSIXct())) -&gt; timing2\n\n`summarise()` has grouped output by \"carrier\". You can override using the\n`.groups` argument.\n\ntiming2\n\n   user  system elapsed \n  0.289   0.046   0.339 \n\n\nIt might have taken you the same time to read this code as the last chunk, but this took only 0.339 seconds to run, almost an order of magnitude faster! That’s pretty good for just moving one line of code.\nNow that we have done a speed comparison, we can create the nice plot we all came for.\n\ndf_plot |&gt;\n  dplyr::mutate(carrier = paste0(\"Carrier: \", carrier)) |&gt;\n  ggplot(aes(x = sched_dep_time, y = delay_pct)) +\n    geom_line() +\n    facet_wrap(\"carrier\") +\n    ylab(\"Proportion of Flights Delayed\") +\n    xlab(\"Time of Day\") +\n    scale_y_continuous(labels = scales::percent) +\n    scale_x_datetime(date_breaks = \"4 hours\", \n                    date_labels = \"%H\")\n\n\n\n\nIt looks to me like flights later in the day might be a little more likely to experience delays."
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html",
    "href": "posts/2023-12-12-flexdashboard/index.html",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nInformation about creating dashboards: https://pkgs.rstudio.com/flexdashboard\nExamples of flexdashboard dashboards: https://pkgs.rstudio.com/flexdashboard/articles/examples\n\n\n\n\n\n\nBefore starting you must install three additional packages:\n\nflexdashboard - this provides tools for easily building dashboards\nDT - this provides built-in data display functionality\nshiny - this provides functionality to create interactive dashboard elements\n\nYou can do this by calling\n\ninstall.packages(c(\"flexdashboard\", \"DT\", \"shiny\"))\n\nor use the “Install Packages…” option from the “Tools” menu in RStudio.\n\n\n\n\n“R for Data Science” by Grolemund and Wickham, sections 29.6 and 29.7.2. It is based on lecture notes initially developed by Margaret Taub and Leah Jager.\nhttps://epirhandbook.com/en/dashboards-with-r-markdown.html"
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html#examples",
    "href": "posts/2023-12-12-flexdashboard/index.html#examples",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "Examples",
    "text": "Examples\nHere’s an example of what a flexdashboard might look like:\n\n\n\n\n\nA screenshot of a dashboard created with flexdashboard\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more examples of flexdashboard dashboards, check out here:\n\nhttps://pkgs.rstudio.com/flexdashboard/articles/examples"
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html#getting-started",
    "href": "posts/2023-12-12-flexdashboard/index.html#getting-started",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "Getting started",
    "text": "Getting started\nTo author a flexdashboard you create an R Markdown document within RStudio using the New R Markdown dialog:\n\n\n\n\n\nA screenshot of opening a new RMarkdown with a flexdashboard template\n\n\n\n\nTo create a new dashboard, use the menus at the top of RStudio:\n\nSelect File\nSelect New File\nSelect R Markdown…\n\nChoose From Template in the box on the left\nSelect Flex Dashboard from the box on the right\nThen click OK\n\nThis will open up a dashboard template.\n\n\n\n\n\n\nNote\n\n\n\nThis option will only appear once you have installed the flexdashboard package.\n\n\nYou can knit this file just as you would a regular R Markdown document.\n\n\n\n\n\n\nTry it out\n\n\n\nLet’s try this out. We will:\n\nCreate a new Project in RStudio.\nCreate a new R Markdown with the flexdashbard template following instructions above.\nKnit the file and take a look at what we get!\n\nNote: you will have to save this file first before knitting. Save it in your project directory as trial_dashboard.Rmd when prompted."
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html#a-quick-view",
    "href": "posts/2023-12-12-flexdashboard/index.html#a-quick-view",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "A quick view",
    "text": "A quick view\nLet’s explore the R Markdown a bit.\n\nYAML\nSimilar to other R Markdown and Quarto documents, there is a YAML at the top of the file. The YAML parameter output: is required and specifies the type of file to be produced (e.g. html_document, pdf_document, word_document, or powerpoint_presentation).\nFor flexdashboard, output must be set as output:flexdashboard::flex_dashboard, which is a bit confusing looking.\nTo make thing even more confusing, there is often an additional colon and indented sub-parameter (see orientation: and vertical_layout: parameters below).\n\ntitle: \"Untitled\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\n\n\n\n\n\n\n\nNote\n\n\n\n\nTwo spaces are important to define the subparameters.\nUse an additional colon after things like key:value if you want to further define subparameters.\nIf appropriate, logical values should be given in YAML in lowercase (true, false, null).\n\n\n\n\n\nCode chunks and text\nSimilar to other R Markdown files, these files also can contain multiple code chunks.\nThey are structured in the same way you would structure them with three back-ticks and curly brackets with a lowercase “r” within.\nYou can write narrative text similarly as well with all the markdown syntax you are already familiar with with italics, bold, bullets, numbering, etc.\n\n\nHeadings\nNotice the layout of the blank document is given by the hash (#) signs. In general:\n\nEach level 1 header (#) begins a new page in the dashboard.\nEach level 2 header (##) begins a new column or a row depending on your orientation: parameter.\nEach level 3 header (###) create panels for plots, charts, tables, text, etc.\n\n# First-level heading (page)\n\n## Second level heading (row or column)  \n\n### Third-level heading (pane for plot, chart, etc.)\nIn our blank document, you see the blank output with the title: \"Untitled\" and then three rows of charts (Chart A, Chart B, and Chart C.\nThe code in the three sections with these three titles are all blank.\n\n\nSection attributes\nAnother thing you might notice is that you can specify section attributes to apply to parts of the dashboard in a key=value structure after the heading and within curly brackets { }.\nFor example, the {data-width=} and {data-height=} attributes set relative size of charts, columns, rows laid out in the same dimension (horizontal or vertical).\n## Column {data-width=650}\n\n\n\n\n\n\nNote\n\n\n\n\nThese attributes are written after a heading in a text portion of the script.\nThese are different than the knitr options inserted within at the top of R code chunks, such as out.height =.\n\n\n\nSome section attributes specific to flexdashboard include:\n\n{data-orientation=} Set to either rows or columns. If your dashboard has multiple pages, add this attribute to each page to indicate orientation.\n\n{data-width=} and {data-height=} set relative size of charts, columns, rows laid out in the same dimension (horizontal or vertical).\n\nHeight of charts also depends on whether you set the YAML parameter vertical_layout: fill or vertical_layout: scroll. If set to scroll, figure height will reflect the traditional fig.height = option in the R code chunk.\n\nSee complete size documentation at the flexdashboard website\n\n\n{.hidden} Use this to exclude a specific page from the navigation bar\n\n{data-navbar=} Use this in a page-level heading to nest it within a navigation bar drop-down menu. Provide the name (in quotes) of the drop-down menu. See example below.\n\n\n\n\n\n\n\nGroup exercise\n\n\n\nFor the next 5 minutes, pair up with a partner (or try it alone) and explore the template dashboard and adjust the layout in the following ways:\n\nTry adding pages, columns/rows, and charts with R Markdown headings (e.g. #, ##, or ###)\n\nAdjust the orientation using the YAML parameter orientation: to either rows or columns\nSpecify whether the layout fills the browser or allows for a scrolling layout\nAdd tabs to a particular section heading using the {.tabset} attribute\nAdd a navigation menu or side bar using the {data-navmenu} attribute or the {.sidebar} attribute, respectively.\n\nBe sure to open the resulting dashboard in a browser window to really see it; you won’t be able to view it very well in the small viewer pane within RStudio.\n\n\n\n\nDiamonds dashboard\nThere are several example dashboards included in the folder containing today’s lecture.\nHere is is a dashboard using the diamonds dataset in the ggplot2 package:\n\n\n---\ntitle: \"Diamonds distribution dashboard\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\n---\n\n```{r setup, include = FALSE}\nlibrary(ggplot2)\nlibrary(dplyr)\nknitr::opts_chunk$set(fig.width = 5, fig.asp = 1/3)\n```\n\n## Column 1\n\n### Carat\n\n```{r}\ndiamonds |&gt; \n  ggplot(aes(carat)) + \n  geom_histogram(binwidth = 0.1)\n```\n\n### Cut\n\n```{r}\ndiamonds |&gt; \n  ggplot(aes(cut)) + \n  geom_bar()\n```\n\n### Colour\n\n```{r}\ndiamonds |&gt; \n  ggplot(aes(color)) + \n  geom_bar()\n```\n\n## Column 2\n\n### The largest diamonds\n\n```{r}\ndiamonds %&gt;% \n  arrange(desc(carat)) %&gt;% \n  head(100) %&gt;% \n  select(carat, cut, color, price) %&gt;% \n  DT::datatable()\n```\n\n\nAbove, you can see there are two columns (designated by ##) and various rows within each column (designated with ###).\n\n\n\n\n\n\nTip\n\n\n\nThis code relies on the DT package, which is an interface to the DataTables JavaScript library.\nThe DT package provides a nice way to display R matrices or data frames as interactive HTML tables that support filtering, pagination, and sorting.\n\n\n\n\n\n\n\n\nGroup exercise\n\n\n\nFor the next 5 minutes, pair up with a partner (or try it alone), open the file Diamond_dashboard_example.Rmd and knit it. Explore to see if you can make the following changes:\n\nCan you change the titles of each of the graphs in the column on the left?\nHow could you change the first graph on the left to be a histogram of prices instead of carats?\nOr could you add a fourth graph to the dashboard that shows price?\n\nNote that to get access to the diamonds dataset that the dashboard uses, you will have to have loaded the ggplot2 package, which is part of the tidyverse. You can see that the dashboard uses this package by looking at the first set-up code chunk in the dashboard .Rmd file."
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html#section",
    "href": "posts/2023-12-12-flexdashboard/index.html#section",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "",
    "text": "Embedding shiny in flexdashboard is however, a fundamental change to your flexdashboard. It will no longer produce an HTML output that you can send by email and anyone could open and view.\nInstead, it will be an “app”. The “Knit” button at the top of the script will be replaced by a “Run document” icon, which will open an instance of the interactive the dashboard locally on your computer.\nSharing your dashboard will now require that you either:\n\nSend the Rmd script to the viewer, they open it in R on their computer, and run the app, or\n\nThe app/dashboard is hosted on a server accessible to the viewer (most typical scenario)\n\nThus, there are benefits to integrating shiny, but also complications.\n\n\n\n\n\n\nDeploy on a server\n\n\n\nShiny documents need to be deployed to a Shiny Server to be shared broadly.\nSee instructions for creating a free account at http://www.shinyapps.io/ and instructions on how to publish to the web."
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html#settings",
    "href": "posts/2023-12-12-flexdashboard/index.html#settings",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "Settings",
    "text": "Settings\nTo embed shiny reactivity into flexdashboard, you need only make a few changes to your flexdashboard R Markdown script.\nSpecifically, you need to add the YAML parameter runtime: shiny at the same indentation level as output:, as below:\n---\ntitle: \"Outbreak dashboard (Shiny demo)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---\nIt is also convenient to enable a “side bar” to hold the shiny input widgets that will collect information from the user.\n\n\n\n\n\n\nPro-tip\n\n\n\nCreate a column and indicate the {.sidebar} option to create a side bar on the left side.\nYou can add text and R chunks containing the shiny input commands within this column.\n\n\nIf your app/dashboard is hosted on a server and may have multiple simultaneous users, name the first R code chunk as global.\n\nInclude the commands to import/load your data in this chunk.\nThis special named chunk is treated differently, and the data imported within it are only imported once (not continuously) and are available for all users.\nThis improves the start-up speed of the app."
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html#shiny-syntax",
    "href": "posts/2023-12-12-flexdashboard/index.html#shiny-syntax",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "Shiny syntax",
    "text": "Shiny syntax\nYou can have input that is text, numeric, selecting from a menu, or checking a box, as shown below. (Don’t run this code, it’s just there to show you what the syntax looks like!)\n\ntextInput(\"name\", \"What is your name?\")\nnumericInput(\"age\", \"How old are you?\", NA, min = 0, max = 150)\nselectInput(\"variable\", \"Variable:\",\n                  c(\"Cylinders (cyl)\" = \"cyl\",\n                    \"Transmission (am)\" = \"am\",\n                    \"Gears (gear)\" = \"gear\"))\ncheckboxInput(\"outliers\", \"Show outliers\", TRUE)\n\nWhat is happening above?\n\nThe first argument\nThe input values are stored in the object given by the first argument of these input functions. For example,\n\nThe text input is stored in an object called name\nThe numeric input is stored in an object called age\n\nYou can then refer to the values with input$name and input$age, and the code that uses them will be automatically re-run whenever they change.\n\n\nThe second argument\nThe second argument gives the text that is displayed to the user to prompt their input. For example,\n\nThe input area for name will show “What is your name?” and so on.\n\nLater arguments for each type give additional information about that input, such as minimum and maximum allowed values for numeric input and menu options for the select input.\n\n\n\n\n\n\nShiny best practices\n\n\n\nTo add Shiny components to a flex dashboard you will want to do the following:\n\nAdd runtime: shiny to the YAML header at the top of the document.\nAdd the {.sidebar} attribute to the first column of the dashboard to make it a host for Shiny input controls (note this step isn’t strictly required, but many Shiny based dashboards will want to do this).\nAdd Shiny inputs and outputs as appropriate using the input functions.\nWhen including plots, be sure to wrap them in a call to renderPlot. This is important not only for dynamically responding to changes but also to ensure that they are automatically re-sized when their container changes."
  },
  {
    "objectID": "posts/2023-12-12-flexdashboard/index.html#examples-1",
    "href": "posts/2023-12-12-flexdashboard/index.html#examples-1",
    "title": "Building dashboards with flexdashboard and shinydashboard",
    "section": "Examples",
    "text": "Examples\nThere are a couple examples of simple flex dashboards that use Shiny in the following files that are included with this lecture.\nOpen each one of these files and run it by clicking the “Run document” button that is where the “Knit” button usually is.\nShiny apps must be run rather than knitted, but the idea is the same! Be sure to open the output in a browser tab.\n\nGeyser dashboard\nHere is a dashboard using the faithful dataset in base R, which contains the waiting time between eruptions and the duration of the eruption for the Old Faithful geyser in Yellowstone National Park, Wyoming, USA.\n\n\n---\ntitle: \"Old Faithful Eruptions\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\nruntime: shiny\n---\n\n```{r global, include=FALSE}\n# load data in 'global' chunk so it can be shared by all users of the dashboard\nlibrary(datasets)\ndata(faithful)\n```\n\n## Column {.sidebar}\n\nWaiting time between eruptions and the duration of the eruption for the\nOld Faithful geyser in Yellowstone National Park, Wyoming, USA.\n\n```{r}\nselectInput(\"n_breaks\", label = \"Number of bins:\",\n            choices = c(10, 20, 35, 50), selected = 20)\n\nsliderInput(\"bw_adjust\", label = \"Bandwidth adjustment:\",\n            min = 0.2, max = 2, value = 1, step = 0.2)\n```\n\n## Column\n\n### Geyser Eruption Duration\n\n```{r}\nrenderPlot({\n  hist(faithful$eruptions, probability = TRUE, breaks = as.numeric(input$n_breaks),\n       xlab = \"Duration (minutes)\", main = \"Geyser Eruption Duration\")\n  \n  dens &lt;- density(faithful$eruptions, adjust = input$bw_adjust)\n  lines(dens, col = \"blue\")\n})\n```\n\n\n\n\n\n\n\n\nGroup exercise\n\n\n\nFor the next 5 minutes, pair up with a partner (or try it alone) and explore Geyser flexdashboard, which includes interactive elements from Shiny.\n\nPlay with the user input options in the left hand sidebar to see how the user can interact with the data through the dashboard.\nThen look at both the code and the output to see how the code relates to what is shown in the dashboard.\nPlay around with the options in the code chunks to see if you can get a sense of what they are doing.\n\n\n\n\n\nMile per gallon dashboard\nOne thing to point out in the MPGFlexDashboard.Rmd file is the following chunk of code:\n\nformulaText &lt;- reactive({\n    paste(\"mpg ~\", input$variable)\n  })\n\nThis chunk of code allows the title of the graph to change depending on the input given by the user.\nIt uses the reactive() function to specify that the text is not static but will change depending on what is selected by the user.\nYou can see here the object formulaText will contain text consisting of pasting together “mpg ~” and the variable value selected from the user in the drop-down menu.\nThen, this formulaText object is used as the title in the plot! And even more importantly, it is used in the call to the boxplot function, to determine which variable to display in the plot.\nSuper cool!"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html",
    "href": "posts/2023-12-05-gettingdata-api/index.html",
    "title": "Retrieving data from APIs with httr",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://jeroen.cran.dev/jsonlite\nhttps://httr.r-lib.org\n\n\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://jhu-advdatasci.github.io/2019/lectures/04-gettingdata-api.html\nhttps://aws.amazon.com/what-is/api\nhttps://bookdown.org/paul/apis_for_social_scientists/github.com-api.html\nhttps://statisticsglobe.com/api-in-r\n\n\n\n\nBefore we begin, you will need to install these packages\n\ninstall.packages(\"jsonlite\")\ninstall.packages(\"httr\")\n\nNow we load a few R packages\n\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(httr)"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#raw-vs-clean-data",
    "href": "posts/2023-12-05-gettingdata-api/index.html#raw-vs-clean-data",
    "title": "Retrieving data from APIs with httr",
    "section": "“Raw” vs “Clean” data",
    "text": "“Raw” vs “Clean” data\nAs data analysts, this is what we wished data looked like whenever we start a project\n\n\n\n\n\nHowever, the reality, is data is rarely in that form in comes in all types of “raw” formats that need to be transformed into a “clean” format.\nFor example, in field of genomics, raw data looks like something like this:\n\n\n\n\n\nOr if you are interested in analyzing data from Twitter:\n\n\n\n\n\nOr data from Electronic Healthcare Records (EHRs):\n\n\n\n\n\nWe all have our scary spreadsheet tales. Here is Jenny Bryan from Posit and UBC actually asking for some of those spreadsheet tales on twitter.\n\n\n\n\n\nFor example, this is an actual spreadsheet from Enron in 2001:"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#what-do-we-mean-by-raw-data",
    "href": "posts/2023-12-05-gettingdata-api/index.html#what-do-we-mean-by-raw-data",
    "title": "Retrieving data from APIs with httr",
    "section": "What do we mean by “raw” data?",
    "text": "What do we mean by “raw” data?\nFrom https://simplystatistics.org/posts/2016-07-20-relativity-raw-data/ raw data is defined as data…\n\n…if you have done no processing, manipulation, coding, or analysis of the data. In other words, the file you received from the person before you is untouched. But it may not be the rawest version of the data. The person who gave you the raw data may have done some computations. They have a different “raw data set”."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#where-do-data-live",
    "href": "posts/2023-12-05-gettingdata-api/index.html#where-do-data-live",
    "title": "Retrieving data from APIs with httr",
    "section": "Where do data live?",
    "text": "Where do data live?\nData lives anywhere and everywhere. Data might be stored simply in a .csv or .txt file. Data might be stored in an Excel or Google Spreadsheet. Data might be stored in large databases that require users to write special functions to interact with to extract the data they are interested in.\nFor example, you may have heard of the terms mySQL or MongoDB.\nFrom Wikipedia, MySQL is defined as an open-source relational database management system (RDBMS). Its name is a combination of “My”, the name of co-founder Michael Widenius’s daughter,[7] and “SQL”, the abbreviation for Structured Query Language.\nFrom Wikipeda, MongoDB is defined as “a free and open-source cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schemata.”\nSo after reading that, we get the sense that there are multiple ways large databases can be structured, data can be formatted and interacted with. In addition, we see that database programs (e.g. MySQL and MongoDB) can also interact with each other.\n\n\n\n\n\nWe will learn more about JSON today and learn about SQL in a later lecture more formally."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#json-files",
    "href": "posts/2023-12-05-gettingdata-api/index.html#json-files",
    "title": "Retrieving data from APIs with httr",
    "section": "JSON files",
    "text": "JSON files\nJSON (or JavaScript Object Notation) is a file format that stores information in human-readable, organized, logical, easy-to-access manner.\nFor example, here is what a JSON file looks like:\nvar stephanie = {\n    \"job-title\" : \"Associate Professor\",\n    \"hometown\" : \"Baltimore, MD\",\n    \"pronouns\": \"she/her\",\n  \"states-lived\" : {\n    \"state1\" : \"Louisiana\",\n    \"state2\" : \"Texas\",\n    \"state3\" : \"Massachusetts\",\n    \"state4\" : \"Maryland\"\n  }\n}\nSome features about JSON objects:\n\nJSON objects are surrounded by curly braces {}\nJSON objects are written in key/value pairs\nKeys must be strings, and values must be a valid JSON data type (string, number, object, array, boolean)\nKeys and values are separated by a colon\nEach key/value pair is separated by a comma"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#overview-of-apis",
    "href": "posts/2023-12-05-gettingdata-api/index.html#overview-of-apis",
    "title": "Retrieving data from APIs with httr",
    "section": "Overview of APIs",
    "text": "Overview of APIs\nFrom AWS, API stands for Application Programming Interface.\n\n“Application” = any software with a distinct function\n“Interface” = a contract of service between two applications. This contract defines how the two communicate with each other using requests and responses.\n\nThe API documentation contains information on how developers are to structure those requests and responses.\n\n\n\n\n\n\nPurpose of APIs\n\n\n\nThe purpose of APIs is enable two software components to communicate with each other using a set of definitions and protocols.\nFor example, the weather bureau’s software system contains daily weather data. The weather app on your phone “talks” to this system via APIs and shows you daily weather updates on your phone.\n\n\n\nHow do APIs work?\nTo understand how APIs work, two terms that are important are\n\nclient. This is the application sending the request.\nserver. This is the application sending the response.\n\nSo in the weather example, the bureau’s weather database is the server, and the mobile app is the client.\n\n\nFour types of API architectures\nThere are four different ways that APIs can work depending on when and why they were created.\n\nSOAP APIs. These APIs use Simple Object Access Protocol. Client and server exchange messages using XML. This is a less flexible API that was more popular in the past.\nRPC APIs. These APIs are called Remote Procedure Calls. The client completes a function (or procedure) on the server, and the server sends the output back to the client.\nWebsocket APIs. Websocket API is another modern web API development that uses JSON objects to pass data. A WebSocket API supports two-way communication between client apps and the server. The server can send callback messages to connected clients, making it more efficient than REST API.\nREST APIs. REST stands for Representational State Transfer (and are the most popular and flexible APIs). The client sends requests to the server as data. The server uses this client input to start internal functions and returns output data back to the client. REST defines a set of functions like GET, PUT, DELETE, etc. that clients can use to access server data. Clients and servers exchange data using HTTP.\n\nThe main feature of REST API is statelessness (i.e. servers do not save client data between requests). Client requests to the server are similar to URLs you type in your browser to visit a website. The response from the server is plain data, without the typical graphical rendering of a web page.\n\n\nHow to use an API?\nThe basic steps to using an API are:\n\nObtaining an API key. This is done by creating a verified account with the API provider.\nSet up an HTTP API client. This tool allows you to structure API requests easily using the API keys received. Here, we will use the GET() function from the httr package.\nIf you don’t have an API client, you can try to structure the request yourself in your browser by referring to the API documentation.\nOnce you are comfortable with the new API syntax, you can start using it in your code.\n\n\n\nWhere can I find new APIs?\nNew web APIs can be found on API marketplaces and API directories, such as:\n\nRapid API – One of the largest global API markets (10k+ public APIs). Users to test APIs directly on the platform before committing to purchase.\nPublic REST APIs – Groups REST APIs into categories, making it easier to browse and find the right one to meet your needs.\nAPIForThat and APIList – Both these websites have lists of 500+ web APIs, along with in-depth information on how to use them."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#access-the-api-from-r",
    "href": "posts/2023-12-05-gettingdata-api/index.html#access-the-api-from-r",
    "title": "Retrieving data from APIs with httr",
    "section": "Access the API from R",
    "text": "Access the API from R\nThere are packages for many programming languages that provide convenient access for communicating with the GitHub API, but there are no such packages (that I’m aware of) for accessing the API from R.\nThis means we can only access the API directly, e.g. by using the jsonlite package to fetch the data and convert it to an R list or data.frame.\nSpecifically, we will use the jsonlite::fromJSON() function to convert from a JSON object to a data frame.\nThe JSON file is located at https://api.github.com/users/stephaniehicks/repos\n\ngithub_url = \"https://api.github.com/users/stephaniehicks/repos\"\n\nlibrary(jsonlite)\nlibrary(tidyverse)\njsonData &lt;- as_tibble(fromJSON(github_url))\nglimpse(jsonData)\n\nRows: 30\nColumns: 79\n$ id                          &lt;int&gt; 160194123, 132884754, 647539937, 225501707…\n$ node_id                     &lt;chr&gt; \"MDEwOlJlcG9zaXRvcnkxNjAxOTQxMjM=\", \"MDEwO…\n$ name                        &lt;chr&gt; \"2018-bioinfosummer-scrnaseq\", \"advdatasci…\n$ full_name                   &lt;chr&gt; \"stephaniehicks/2018-bioinfosummer-scrnase…\n$ private                     &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ owner                       &lt;df[,18]&gt; &lt;data.frame[26 x 18]&gt;\n$ html_url                    &lt;chr&gt; \"https://github.com/stephaniehicks/201…\n$ description                 &lt;chr&gt; NA, NA, \"Repo to share code for the atlas-…\n$ fork                        &lt;lgl&gt; FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FAL…\n$ url                         &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ forks_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ keys_url                    &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ collaborators_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ teams_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ hooks_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issue_events_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ events_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ assignees_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ branches_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ tags_url                    &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ blobs_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_tags_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_refs_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ trees_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ statuses_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ languages_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ stargazers_url              &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ contributors_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ subscribers_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ subscription_url            &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ commits_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ git_commits_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ comments_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issue_comment_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ contents_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ compare_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ merges_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ archive_url                 &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ downloads_url               &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ issues_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ pulls_url                   &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ milestones_url              &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ notifications_url           &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ labels_url                  &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ releases_url                &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ deployments_url             &lt;chr&gt; \"https://api.github.com/repos/stephaniehic…\n$ created_at                  &lt;chr&gt; \"2018-12-03T13:20:45Z\", \"2018-05-10T10:22:…\n$ updated_at                  &lt;chr&gt; \"2019-08-08T02:18:17Z\", \"2018-05-10T10:22:…\n$ pushed_at                   &lt;chr&gt; \"2018-12-05T17:07:09Z\", \"2017-12-18T17:18:…\n$ git_url                     &lt;chr&gt; \"git://github.com/stephaniehicks/2018-bioi…\n$ ssh_url                     &lt;chr&gt; \"git@github.com:stephaniehicks/2018-bioinf…\n$ clone_url                   &lt;chr&gt; \"https://github.com/stephaniehicks/2018-bi…\n$ svn_url                     &lt;chr&gt; \"https://github.com/stephaniehicks/2018-bi…\n$ homepage                    &lt;chr&gt; NA, NA, NA, NA, NA, \"\", NA, NA, NA, NA, NA…\n$ size                        &lt;int&gt; 60296, 172353, 8858, 121, 675, 26688, 20, …\n$ stargazers_count            &lt;int&gt; 4, 0, 1, 1, 0, 0, 1, 8, 0, 1, 0, 14, 3, 0,…\n$ watchers_count              &lt;int&gt; 4, 0, 1, 1, 0, 0, 1, 8, 0, 1, 0, 14, 3, 0,…\n$ language                    &lt;chr&gt; \"TeX\", \"HTML\", \"R\", NA, NA, \"R\", \"R\", \"Jup…\n$ has_issues                  &lt;lgl&gt; TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRU…\n$ has_projects                &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_downloads               &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_wiki                    &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_pages                   &lt;lgl&gt; TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ has_discussions             &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ forks_count                 &lt;int&gt; 4, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 4, 1, 1, …\n$ mirror_url                  &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ archived                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ disabled                    &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ open_issues_count           &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ license                     &lt;df[,5]&gt; &lt;data.frame[26 x 5]&gt;\n$ allow_forking               &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ is_template                 &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ web_commit_signoff_required &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ topics                      &lt;list&gt; &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;, &lt;&gt;…\n$ visibility                  &lt;chr&gt; \"public\", \"public\", \"public\", \"public\", \"p…\n$ forks                       &lt;int&gt; 4, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 4, 1, 1,…\n$ open_issues                 &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ watchers                    &lt;int&gt; 4, 0, 1, 1, 0, 0, 1, 8, 0, 1, 0, 14, 3, 0,…\n$ default_branch              &lt;chr&gt; \"master\", \"master\", \"main\", \"master\", \"mas…\n\n\nThe function fromJSON() has now converted the JSON file into a data frame.\nHowever, from here, we see that there are only 30 rows (or 30 repositories). If you look on my github page, you can see there are more than 30 repositories.\n\nhttps://github.com/stephaniehicks?tab=repositories\n\n\n\n\n\n\n\nAPIs limit info from users\n\n\n\nWhat’s happening is called pagination.\nAt a high-level, the API is limiting the amount of items a user gets and splitting it into pages.\nFormally, pagination is the process of splitting the contents or a section of a website into discrete pages. Users tend to get lost when there’s bunch of data and with pagination splitting they can concentrate on a particular amount of content. Hierarchy and paginated structure improve the readability score of the content.\nIn this use case Github api splits the result into 30 items per resonse, depends on the request\n\n\nSolution: You should explicitly specify in your request how many items you would like to receive from server pagination engine, using formula for Github pagination api:\n?page=1&per_page=&lt;numberOfItemsYouSpecify&gt;\"\nYou can read more about pagination here:\n\nhttps://docs.github.com/en/rest/guides/using-pagination-in-the-rest-api\n\n\n\n\n\n\n\nExample\n\n\n\nHere we can visit this website:\n\nhttps://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000\n\nAnd see there are more than 30 repos. Let’s read it into R.\n\ngithub_url = \"https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000\"\n\njsonDataAll &lt;- as_tibble(fromJSON(github_url))\ndim(jsonDataAll)\n\n[1] 90 79\n\n\nWe now get all the public repositories! yay!"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#using-api-keys",
    "href": "posts/2023-12-05-gettingdata-api/index.html#using-api-keys",
    "title": "Retrieving data from APIs with httr",
    "section": "Using API keys",
    "text": "Using API keys\nAuthenticating with the GitHub API via an API key allows you to send much more requests to the API.\nAPI access keys for the GitHub API are called personal access tokens (PAT) and the documentation explains how to generate a PAT once you have logged into your GitHub account.\n\n\n\n\n\n\nWhere to store API keys\n\n\n\nFirst, please be careful with your PATs and never publish them.\nIf you want guidance on where you should store them, I like this post:\n\nhttps://www.r-bloggers.com/2015/11/how-to-store-and-use-webservice-keys-and-authentication-details-with-r/\n\nPersonally, I keep mine in my .Renviron file which looks something like this on the inside:\nGITHUB_API_KEY = &lt;add my GitHub API key here&gt; \nCENSUS_API_KEY = &lt;add my tidycensus API key here&gt; \nOPENFDA_API_KEY = &lt;add my openFDA API key here&gt; \nIf you do not have an .Renviron file in your home directory, you can make one:\ncd ~\ntouch .Renviron\n\n\nAssuming you have created and stored an API key in the .Renviron file in your home directory, you can fetch it with the Sys.getenv() function.\n\ngithub_key &lt;- Sys.getenv(\"GITHUB_API_KEY\")\n\nWe will use this in a little bit."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#access-api-with-httr-and-get",
    "href": "posts/2023-12-05-gettingdata-api/index.html#access-api-with-httr-and-get",
    "title": "Retrieving data from APIs with httr",
    "section": "Access API with httr and GET",
    "text": "Access API with httr and GET\nThere are a set of basic HTTP verbs that allow you access a set of endpoints.\nThe basic request patterns are:\n\nRetrieve a single item (GET)\nRetrieve a list of items (GET)\nCreate an item (POST)\nUpdate an item (PUT)\nDelete an item (DELETE)\n\nHere, we will use the GET() function from httr package (i.e. tools to work with URLs and HTTP) to retrieve a single JSON file.\nWe will also make this an authenticated HTTP response to the GitHub API using authenticate() from the httr package.\n\n\n\n\n\n\nExample\n\n\n\nLet’s start by using the GitHub API to learn information about myself (Stephanie Hicks)\n\ngithub_key &lt;- Sys.getenv(\"GITHUB_API_KEY\")\nresponse &lt;- GET('https://api.github.com/user', \n                authenticate(user = 'stephaniehicks', \n                             password = github_key))\nresponse\n\nResponse [https://api.github.com/user]\n  Date: 2023-11-24 10:21\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 1.76 kB\n{\n  \"login\": \"stephaniehicks\",\n  \"id\": 1452065,\n  \"node_id\": \"MDQ6VXNlcjE0NTIwNjU=\",\n  \"avatar_url\": \"https://avatars.githubusercontent.com/u/1452065?v=4\",\n  \"gravatar_id\": \"\",\n  \"url\": \"https://api.github.com/users/stephaniehicks\",\n  \"html_url\": \"https://github.com/stephaniehicks\",\n  \"followers_url\": \"https://api.github.com/users/stephaniehicks/followers\",\n  \"following_url\": \"https://api.github.com/users/stephaniehicks/following{/ot...\n...\n\n\nWe see the response we got is a JSON file.\n\n\nNext we extract / retrieve the contents from the raw JSON output using the content() function from the httr package. If you use the argument as = 'text', it extracts the contents as a character vector.\n\naccount_details &lt;- fromJSON(httr::content(response, as = 'text'))\naccount_details[1:30]\n\n$login\n[1] \"stephaniehicks\"\n\n$id\n[1] 1452065\n\n$node_id\n[1] \"MDQ6VXNlcjE0NTIwNjU=\"\n\n$avatar_url\n[1] \"https://avatars.githubusercontent.com/u/1452065?v=4\"\n\n$gravatar_id\n[1] \"\"\n\n$url\n[1] \"https://api.github.com/users/stephaniehicks\"\n\n$html_url\n[1] \"https://github.com/stephaniehicks\"\n\n$followers_url\n[1] \"https://api.github.com/users/stephaniehicks/followers\"\n\n$following_url\n[1] \"https://api.github.com/users/stephaniehicks/following{/other_user}\"\n\n$gists_url\n[1] \"https://api.github.com/users/stephaniehicks/gists{/gist_id}\"\n\n$starred_url\n[1] \"https://api.github.com/users/stephaniehicks/starred{/owner}{/repo}\"\n\n$subscriptions_url\n[1] \"https://api.github.com/users/stephaniehicks/subscriptions\"\n\n$organizations_url\n[1] \"https://api.github.com/users/stephaniehicks/orgs\"\n\n$repos_url\n[1] \"https://api.github.com/users/stephaniehicks/repos\"\n\n$events_url\n[1] \"https://api.github.com/users/stephaniehicks/events{/privacy}\"\n\n$received_events_url\n[1] \"https://api.github.com/users/stephaniehicks/received_events\"\n\n$type\n[1] \"User\"\n\n$site_admin\n[1] FALSE\n\n$name\n[1] \"Stephanie Hicks\"\n\n$company\n[1] \"Johns Hopkins\"\n\n$blog\n[1] \"http://www.stephaniehicks.com\"\n\n$location\n[1] \"Baltimore, MD\"\n\n$email\nNULL\n\n$hireable\nNULL\n\n$bio\n[1] \"Associate Prof at Johns Hopkins Biostatistics\"\n\n$twitter_username\n[1] \"stephaniehicks\"\n\n$public_repos\n[1] 90\n\n$public_gists\n[1] 8\n\n$followers\n[1] 275\n\n$following\n[1] 18\n\n\nNext, let’s perform the same request we did above about my 85 repositories, but instead of reading in the JSON file from the web, we use an authenticated GET() response:\n\nresponse &lt;- GET('https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000',\n                authenticate('stephaniehicks', github_key))\nrepo_details &lt;- as_tibble(fromJSON(httr::content(response, as = 'text')))\nrepo_details\n\n# A tibble: 90 × 80\n       id node_id name  full_name private owner$login html_url description fork \n    &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;     &lt;lgl&gt;   &lt;chr&gt;       &lt;chr&gt;    &lt;chr&gt;       &lt;lgl&gt;\n 1 1.60e8 MDEwOl… 2018… stephani… FALSE   stephanieh… https:/… &lt;NA&gt;        FALSE\n 2 1.33e8 MDEwOl… advd… stephani… FALSE   stephanieh… https:/… &lt;NA&gt;        TRUE \n 3 6.48e8 R_kgDO… atla… stephani… FALSE   stephanieh… https:/… Repo to sh… FALSE\n 4 2.26e8 MDEwOl… Awes… stephani… FALSE   stephanieh… https:/… A curated … TRUE \n 5 6.38e7 MDEwOl… awes… stephani… FALSE   stephanieh… https:/… List of so… TRUE \n 6 1.66e7 MDEwOl… Back… stephani… FALSE   stephanieh… https:/… Gene expre… FALSE\n 7 2.88e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… &lt;NA&gt;        FALSE\n 8 1.69e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… Benchmarki… FALSE\n 9 1.40e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… Repository… FALSE\n10 1.78e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… Data and B… FALSE\n# ℹ 80 more rows\n# ℹ 88 more variables: owner$id &lt;int&gt;, $node_id &lt;chr&gt;, $avatar_url &lt;chr&gt;,\n#   $gravatar_id &lt;chr&gt;, $url &lt;chr&gt;, $html_url &lt;chr&gt;, $followers_url &lt;chr&gt;,\n#   $following_url &lt;chr&gt;, $gists_url &lt;chr&gt;, $starred_url &lt;chr&gt;,\n#   $subscriptions_url &lt;chr&gt;, $organizations_url &lt;chr&gt;, $repos_url &lt;chr&gt;,\n#   $events_url &lt;chr&gt;, $received_events_url &lt;chr&gt;, $type &lt;chr&gt;,\n#   $site_admin &lt;lgl&gt;, url &lt;chr&gt;, forks_url &lt;chr&gt;, keys_url &lt;chr&gt;, …"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#a-bit-of-eda-fun",
    "href": "posts/2023-12-05-gettingdata-api/index.html#a-bit-of-eda-fun",
    "title": "Retrieving data from APIs with httr",
    "section": "A bit of EDA fun",
    "text": "A bit of EDA fun\nLet’s have a bit of fun and explore some questions:\n\nHow many have forks? How many forks?\n\n\ntable(repo_details$forks)\n\n\n 0  1  2  3  4  5  6  7  8  9 11 22 \n61 10  4  2  6  1  1  1  1  1  1  1 \n\n\nWhat’s the most popular language?\n\ntable(repo_details$language)\n\n\n             CSS             HTML       JavaScript Jupyter Notebook \n               1               20                7                1 \n        Makefile             Perl                R             Ruby \n               1                1               29                3 \n           Shell              TeX \n               2                5 \n\n\nTo find out how many repos that I have with open issues, we can just create a table:\n\n# how many repos have open issues? \ntable(repo_details$open_issues_count)\n\n\n 0  1  2 \n83  6  1 \n\n\nWhew! Not as many as I thought.\n\n\n\n\n\n\nMore about GET\n\n\n\nYou can use the query argument to specify details about the response.\nLet’s look how many open issues there are in the dplyr package in the tidyverse\n\nreq &lt;- GET(\"https://api.github.com/repos/tidyverse/dplyr/issues\", \n           query = list(state = \"open\", per_page = 100, page = 1))\ndplyr_details &lt;- as_tibble(fromJSON(httr::content(req, as = 'text')))\ndplyr_details\n\n# A tibble: 50 × 30\n   url         repository_url labels_url comments_url events_url html_url     id\n   &lt;chr&gt;       &lt;chr&gt;          &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;      &lt;chr&gt;     &lt;int&gt;\n 1 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.01e9\n 2 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.00e9\n 3 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.99e9\n 4 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.98e9\n 5 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.98e9\n 6 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.96e9\n 7 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.95e9\n 8 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.94e9\n 9 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.92e9\n10 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.87e9\n# ℹ 40 more rows\n# ℹ 23 more variables: node_id &lt;chr&gt;, number &lt;int&gt;, title &lt;chr&gt;,\n#   user &lt;df[,18]&gt;, labels &lt;list&gt;, state &lt;chr&gt;, locked &lt;lgl&gt;,\n#   assignee &lt;df[,18]&gt;, assignees &lt;list&gt;, milestone &lt;lgl&gt;, comments &lt;int&gt;,\n#   created_at &lt;chr&gt;, updated_at &lt;chr&gt;, closed_at &lt;lgl&gt;,\n#   author_association &lt;chr&gt;, active_lock_reason &lt;chr&gt;, body &lt;chr&gt;,\n#   reactions &lt;df[,10]&gt;, timeline_url &lt;chr&gt;, performed_via_github_app &lt;lgl&gt;, …"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#other-examples-with-github-api",
    "href": "posts/2023-12-05-gettingdata-api/index.html#other-examples-with-github-api",
    "title": "Retrieving data from APIs with httr",
    "section": "Other examples with GitHub API",
    "text": "Other examples with GitHub API\nFinally, I will leave you with a few other examples of using GitHub API:\n\nHow long does it take to close a GitHub Issue in the dplyr package?\nHow to retrieve all commits for a branch\nGetting my GitHub Activity"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#register-for-an-api-key",
    "href": "posts/2023-12-05-gettingdata-api/index.html#register-for-an-api-key",
    "title": "Retrieving data from APIs with httr",
    "section": "Register for an API Key",
    "text": "Register for an API Key\nFirst, you need to register for an API key here\n\nhttps://open.fda.gov/apis/authentication/\n\nYou should also store the API key in your .Renviron like above for the GitHub API key."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#building-the-url-for-get",
    "href": "posts/2023-12-05-gettingdata-api/index.html#building-the-url-for-get",
    "title": "Retrieving data from APIs with httr",
    "section": "Building the URL for GET",
    "text": "Building the URL for GET\nFirst, we will request a summarized set of counts around food recalls either voluntary by a firm or mandated by the FDA.\nThe URL we want is the following\nhttps://api.fda.gov/food/enforcement.json?api_key=&lt;your_API_key_here&gt;&count=voluntary_mandated.exact\nLet’s build up the URL.\n\nThe first is the base URL: https://api.fda.gov/food/enforcement.json. This part of the URL will be the same for all our calls to the food enforcement API (but is different if you want to investigate e.g. patient responses from drugs).\nNext, ?apiKey=&lt;your_API_key_here&gt; is how I use my authorization token, which tells the openFDA servers that I am allowed to ask for this data.\nFinally, we want to return a set of summarized counts for a specific field (&count=voluntary_mandated.exact)\n\nNow that we have dissected the anatomy of an API, you can see how easy it is to build them!\nBasically anybody with an internet connection, an authorization token, and who knows the grammar of the API can access it. Most APIs are published with extensive documentation to help you understand the available options and parameters."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#calling-an-api-with-get",
    "href": "posts/2023-12-05-gettingdata-api/index.html#calling-an-api-with-get",
    "title": "Retrieving data from APIs with httr",
    "section": "Calling an API with GET",
    "text": "Calling an API with GET\nLet’s join the URL together:\n\n## extract my API from `.Renviron`\nopenFDA_key &lt;- Sys.getenv(\"OPENFDA_API_KEY\")\n\n## build the URL\nbase &lt;- 'https://api.fda.gov/food/enforcement.json?api_key='\nquery &lt;- '&count=voluntary_mandated.exact'\n\n## put it all together\nAPI_URL &lt;- paste0(base, openFDA_key, query)\n\nNow we have the entire URL stored in a simple R object called API_URL.\nWe can now use the URL to call the API, and we will store the returned data in an object called raw_data:\n\nraw_data &lt;- GET(API_URL)\nraw_data\n\nResponse [https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact]\n  Date: 2023-11-24 10:21\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 711 B\n{\n  \"meta\": {\n    \"disclaimer\": \"Do not rely on openFDA to make decisions regarding medical...\n    \"terms\": \"https://open.fda.gov/terms/\",\n    \"license\": \"https://open.fda.gov/license/\",\n    \"last_updated\": \"2023-11-22\"\n  },\n  \"results\": [\n    {\n      \"term\": \"Voluntary: Firm initiated\",\n...\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nWe can see status element of the list. Traditionally, a status of “200” means that the API call was successful, and other codes are used to indicate errors. You can troubleshoot those error codes using the API documentation.\n\n\nNext, we can inspect the object and we see that it is a list.\n\nstr(raw_data)\n\nList of 10\n $ url        : chr \"https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact\"\n $ status_code: int 200\n $ headers    :List of 22\n  ..$ date                            : chr \"Fri, 24 Nov 2023 10:21:51 GMT\"\n  ..$ content-type                    : chr \"application/json; charset=utf-8\"\n  ..$ vary                            : chr \"Accept-Encoding\"\n  ..$ access-control-allow-credentials: chr \"true\"\n  ..$ access-control-allow-origin     : chr \"*\"\n  ..$ age                             : chr \"0\"\n  ..$ cache-control                   : chr \"no-cache, no-store, must-revalidate\"\n  ..$ content-security-policy         : chr \"default-src 'none'\"\n  ..$ etag                            : chr \"W/\\\"2c7-D4yYChONTPyF2qQYL1Qita83Uu4\\\"\"\n  ..$ strict-transport-security       : chr \"max-age=31536000;\"\n  ..$ strict-transport-security       : chr \"max-age=31536000; preload\"\n  ..$ vary                            : chr \"Accept-Encoding\"\n  ..$ via                             : chr \"https/1.1 api-umbrella (ApacheTrafficServer [cMsSf ])\"\n  ..$ x-api-umbrella-request-id       : chr \"cc03cq16o9mdgfjlqf30\"\n  ..$ x-cache                         : chr \"MISS\"\n  ..$ x-content-type-options          : chr \"nosniff\"\n  ..$ x-ratelimit-limit               : chr \"240\"\n  ..$ x-ratelimit-remaining           : chr \"239\"\n  ..$ x-vcap-request-id               : chr \"d6a63001-2511-441a-4dab-58c1ab363d6d\"\n  ..$ x-xss-protection                : chr \"1; mode=block\"\n  ..$ x-frame-options                 : chr \"deny\"\n  ..$ content-encoding                : chr \"gzip\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ all_headers:List of 1\n  ..$ :List of 3\n  .. ..$ status : int 200\n  .. ..$ version: chr \"HTTP/2\"\n  .. ..$ headers:List of 22\n  .. .. ..$ date                            : chr \"Fri, 24 Nov 2023 10:21:51 GMT\"\n  .. .. ..$ content-type                    : chr \"application/json; charset=utf-8\"\n  .. .. ..$ vary                            : chr \"Accept-Encoding\"\n  .. .. ..$ access-control-allow-credentials: chr \"true\"\n  .. .. ..$ access-control-allow-origin     : chr \"*\"\n  .. .. ..$ age                             : chr \"0\"\n  .. .. ..$ cache-control                   : chr \"no-cache, no-store, must-revalidate\"\n  .. .. ..$ content-security-policy         : chr \"default-src 'none'\"\n  .. .. ..$ etag                            : chr \"W/\\\"2c7-D4yYChONTPyF2qQYL1Qita83Uu4\\\"\"\n  .. .. ..$ strict-transport-security       : chr \"max-age=31536000;\"\n  .. .. ..$ strict-transport-security       : chr \"max-age=31536000; preload\"\n  .. .. ..$ vary                            : chr \"Accept-Encoding\"\n  .. .. ..$ via                             : chr \"https/1.1 api-umbrella (ApacheTrafficServer [cMsSf ])\"\n  .. .. ..$ x-api-umbrella-request-id       : chr \"cc03cq16o9mdgfjlqf30\"\n  .. .. ..$ x-cache                         : chr \"MISS\"\n  .. .. ..$ x-content-type-options          : chr \"nosniff\"\n  .. .. ..$ x-ratelimit-limit               : chr \"240\"\n  .. .. ..$ x-ratelimit-remaining           : chr \"239\"\n  .. .. ..$ x-vcap-request-id               : chr \"d6a63001-2511-441a-4dab-58c1ab363d6d\"\n  .. .. ..$ x-xss-protection                : chr \"1; mode=block\"\n  .. .. ..$ x-frame-options                 : chr \"deny\"\n  .. .. ..$ content-encoding                : chr \"gzip\"\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ cookies    :'data.frame':    0 obs. of  7 variables:\n  ..$ domain    : logi(0) \n  ..$ flag      : logi(0) \n  ..$ path      : logi(0) \n  ..$ secure    : logi(0) \n  ..$ expiration: 'POSIXct' num(0) \n  ..$ name      : logi(0) \n  ..$ value     : logi(0) \n $ content    : raw [1:711] 7b 0a 20 20 ...\n $ date       : POSIXct[1:1], format: \"2023-11-24 10:21:51\"\n $ times      : Named num [1:6] 0 0.062 0.137 0.218 0.386 ...\n  ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n $ request    :List of 7\n  ..$ method    : chr \"GET\"\n  ..$ url       : chr \"https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact\"\n  ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. ..- attr(*, \"names\")= chr \"Accept\"\n  ..$ fields    : NULL\n  ..$ options   :List of 2\n  .. ..$ useragent: chr \"libcurl/8.1.2 r-curl/5.1.0 httr/1.4.7\"\n  .. ..$ httpget  : logi TRUE\n  ..$ auth_token: NULL\n  ..$ output    : list()\n  .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  ..- attr(*, \"class\")= chr \"request\"\n $ handle     :Class 'curl_handle' &lt;externalptr&gt; \n - attr(*, \"class\")= chr \"response\"\n\n\nOne of the elements is content and we can inspect that\n\nstr(raw_data$content)\n\n raw [1:711] 7b 0a 20 20 ...\n\n\nWe see the actual data have been stored as raw vectors (or raw bytes), which need to be converted to character vectors. This is not in a useable format yet."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#converting-json-to-a-data.frame",
    "href": "posts/2023-12-05-gettingdata-api/index.html#converting-json-to-a-data.frame",
    "title": "Retrieving data from APIs with httr",
    "section": "Converting JSON to a data.frame",
    "text": "Converting JSON to a data.frame\nThere is a function in base R rawTo_Char() that converts raw bytes to characters\n\nopenFDA_data &lt;- fromJSON(rawToChar(raw_data$content), flatten = TRUE)\n\nThis converts the raw data into a list.\n\n\n\n\n\n\nNote\n\n\n\nWe can also do this with httr::content (as above) and just define the encoding for the character set.\n\nopenFDA_data &lt;- fromJSON(httr::content(raw_data, \n                                       as = 'text', \n                                       encoding =  \"UTF-8\"))\nstr(openFDA_data)\n\nList of 2\n $ meta   :List of 4\n  ..$ disclaimer  : chr \"Do not rely on openFDA to make decisions regarding medical care. While we make every effort to ensure that data\"| __truncated__\n  ..$ terms       : chr \"https://open.fda.gov/terms/\"\n  ..$ license     : chr \"https://open.fda.gov/license/\"\n  ..$ last_updated: chr \"2023-11-22\"\n $ results:'data.frame':    4 obs. of  2 variables:\n  ..$ term : chr [1:4] \"Voluntary: Firm initiated\" \"Voluntary: Firm Initiated\" \"FDA Mandated\" \"\"\n  ..$ count: int [1:4] 24217 563 397 6\n\n\n\n\nNow that it is in a list format, you can see that it actually contains several data frames!\nYou can use this data right away if you are already familiar with lists in R, or you can extract the data frames into separate objects, like this:\n\nts_df &lt;- openFDA_data$results\nts_df\n\n                       term count\n1 Voluntary: Firm initiated 24217\n2 Voluntary: Firm Initiated   563\n3              FDA Mandated   397\n4                               6\n\n\nWe could wrangle and visualize the data from here."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#other-good-r-packages-to-know-about",
    "href": "posts/2023-12-05-gettingdata-api/index.html#other-good-r-packages-to-know-about",
    "title": "Retrieving data from APIs with httr",
    "section": "Other good R packages to know about",
    "text": "Other good R packages to know about\n\ngooglesheets4 to interact with Google Sheets in R\ngoogledrive to interact with files on your Google Drive"
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#final-questions",
    "href": "posts/2023-12-05-gettingdata-api/index.html#final-questions",
    "title": "Retrieving data from APIs with httr",
    "section": "Final Questions",
    "text": "Final Questions\nHere are some post-lecture questions to help you think about the material discussed.\n\n\n\n\n\n\nQuestions\n\n\n\n\nUsing the GitHub API, access the repository information and ask how many open github issues you have?\nPick another API that we have not discussed here and use httr to retreive data from it."
  },
  {
    "objectID": "posts/2023-12-05-gettingdata-api/index.html#additional-resources",
    "href": "posts/2023-12-05-gettingdata-api/index.html#additional-resources",
    "title": "Retrieving data from APIs with httr",
    "section": "Additional Resources",
    "text": "Additional Resources\n\n\n\n\n\n\nTip\n\n\n\n\nhttps://jeroen.cran.dev/jsonlite\nhttps://httr.r-lib.org"
  },
  {
    "objectID": "posts/2023-11-30-pkgdown-pkg-website/index.html",
    "href": "posts/2023-11-30-pkgdown-pkg-website/index.html",
    "title": "Package development with pkgdown",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://pkgdown.r-lib.org/articles/pkgdown.html\n\n\n\n\n\n\nBefore starting you must install the additional package:\n\npkgdown - the R package that helps you to build a package website with little efforts\nusethis - an automation package that simplifies project creation and setup\n\nYou can do this by calling\n\ninstall.packages(c(\"usethis\", \"pkgdown\"))\n\nor use the “Install Packages…” option from the “Tools” menu in RStudio.\nYou also need to have a GitHub account and set up your access from your local computer to GitHub.com. If you forget, please re-visit your previous lecture.\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://pkgdown.r-lib.org/index.html\nhttps://bookdown.org/yihui/rmarkdown/pkgdown-components.html"
  },
  {
    "objectID": "posts/2023-11-30-pkgdown-pkg-website/index.html#live-demonstration",
    "href": "posts/2023-11-30-pkgdown-pkg-website/index.html#live-demonstration",
    "title": "Package development with pkgdown",
    "section": "Live demonstration",
    "text": "Live demonstration\nWhile the pkgdown website provides a comprehensive walkthrough for those who set up their GitHub access using personal access token, it is slightly tricky for those whose access is set up with SSH. During this lecture, we live demonstrate how to deploy the website, specifically for SSH GitHub access.\n\n\n\n\n\n\nDid you try pkgdown::deploy_to_branch()?\n\n\n\nIf you run into problem when running usethis::use_pkgdown_github_pages() and get stuck, you should try to understand what the function does by reading its manual ?usethis::use_pkgdown_github_pages(). Is it possible to create the necessary gh_pages using pkgdown::deploy_to_branch()? Don’t forget to set up the GitHub Action by calling usethis::use_github_action(\"pkgdown\"). Now you should be able to find access your website via github_account_name.github.io/pkg_name"
  },
  {
    "objectID": "posts/2023-11-30-pkgdown-pkg-website/index.html#website-customization",
    "href": "posts/2023-11-30-pkgdown-pkg-website/index.html#website-customization",
    "title": "Package development with pkgdown",
    "section": "Website customization",
    "text": "Website customization\nThere are a lot of customization possible. Nevertheless, there is no point-and-click system for it. You need to manually edit _pkgdown.yml following certain syntax. Please refer to https://pkgdown.r-lib.org/articles/customise.html."
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html",
    "href": "posts/2023-11-21-r-pkg-dev/index.html",
    "title": "Building R packages",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://r-pkgs.org\nhttps://stat545.com/package-overview\n\n\n\n\n\n\nBefore starting you must install two additional packages:\n\ndevtools - this provides many additional tools for building packages\nroxygen2 - this provides tools for writing documentation\n\nYou can do this by calling\n\ninstall.packages(c(\"devtools\", \"roxygen2\"))\n\nor use the “Install Packages…” option from the “Tools” menu in RStudio.\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://rdpeng.github.io/Biostat776/lecture-building-r-packages"
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#create-a-new-r-package-project",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#create-a-new-r-package-project",
    "title": "Building R packages",
    "section": "Create a New R Package Project",
    "text": "Create a New R Package Project\nCreating a new R packages begins with creating a new RStudio project.\n\n\n\n\n\nA screenshot of starting a New Project in R\n\n\n\n\nYou should choose New Directory as this will be a brand new project (not an existing project).\n\n\n\n\n\nA screenshot of starting a New Directory for a New Project in R\n\n\n\n\nNext, you should choose the “Project Type” as R Package using devtools (you may need to scroll down a little in that menu).\n\n\n\n\n\nCreate a R package using devtools\n\n\n\n\nFinally, you should specify the name of your package. For this example, we will use greetings as the name of the package. Also you should double check the name of the sub-directory listed under “Create project as subdirectory of” is a directory that you can find.\n\n\n\n\n\n\nNote\n\n\n\nThe name of this directory should not have any spaces in its name.\n\n\n\n\n\n\n\nPackage name\n\n\n\n\nClick “Create Project” and allow R and RStudio to restart. You should get a brand new session. You will also see a window with a series of tabs. One of those tabs will be called Build and that will be important as we build our package.\n\n\n\n\n\nBuild menu"
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#configure-build-tools",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#configure-build-tools",
    "title": "Building R packages",
    "section": "Configure Build Tools",
    "text": "Configure Build Tools\nThe next step after creating a new project is to configure your build tools. Click on the Build tab and then More and then Configure Build Tools….\n\n\n\n\n\nConfigure Build tools\n\n\n\n\nIn the next screen, you should make sure that the check box for Generate documentation with Roxygen is checked. Then click the Configure… button.\n\n\n\n\n\nClick the Configure button\n\n\n\n\nIn the next menu, make sure to check the check box for Install and Restart.\n\n\n\n\n\nCheck box for Install and Restart\n\n\n\n\nThen click “OK” and then “OK” again to exit the options menu."
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#r-package-files",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#r-package-files",
    "title": "Building R packages",
    "section": "R Package Files",
    "text": "R Package Files\nIn this session, there will be the following files listed in the file browser.\n\n\n\n\n\nFiles are listed in the File browser\n\n\n\n\nThe files we will focus on here are\n\nthe DESCRIPTION file; and\nany files in the R sub-directory. This package will only have one R script in the R sub-directory.\n\nThere is no need to worry about the other files for now."
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#add-a-r-script-file",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#add-a-r-script-file",
    "title": "Building R packages",
    "section": "Add a R Script file",
    "text": "Add a R Script file\nFirst, create an R script in which the R code will go. You can do this by clicking on File &gt; New File &gt; R Script.\n\n\n\n\n\nSaving a new R Script file called hello.R\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nMake sure that your R script is saved inside the R/ sub-directory.\n\n\n\n\n\n\n\nR Script file must be in the R/ sub-directory\n\n\n\n\nNext, once you have your R Script created, you can start to write the function and the documentation.\n\n\n\n\n\n\nNote\n\n\n\nThe idea is that when you write a function in a R package, just above the function is the documentation. The function is written in the usual way and the documentation is written using a special style."
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#documentation",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#documentation",
    "title": "Building R packages",
    "section": "Documentation",
    "text": "Documentation\nLet’s start with the documentation. Here is the documentation for the hello() function.\n#' Print a Greeting\n#'\n#' Print a greeting for a custom name\n#'\n#' @details This function make a plot with a greeting to the name passed as an argument to the function\n#' \n#' @param name character, name of person to whom greeting should be directed\n#'\n#' @return nothing useful is returned.\n#'\n#' @import ggplot2\n#' @export\n#'\n#' @examples\n#' hello(\"Chris\")\n#'\nWe will take each line of documentation in order:\n\nThe first line is a short title for the function\nThe next line is the “description” line and should be a slightly longer description of what the function does. Generally, this line is one sentence.\nThis line contains the first Roxygen directive, which is @details. This directive indicates that the text that comes afterwards has detailed information about the function.\nThe next Roxygen directive is the @param directive. This indicates the name of the parameter that the function will accept. In this case, this is the name to which the greeting will be directed.\nThe @return directive indicates what the function returns to the user. This function does not return anything useful, but it is still useful to indicate that.\nThis function requires the ggplot() function and associated plotting functions. Therefore we need to use the @import directive to indicate that we need to import all of the functions in the ggplot2 package.\nWe want to indicate with the @export directive that this function should be visible to the user (i.e. we want the user to call this function). Therefore, the function should be exported to the user. More complex packages may have many functions and not all of them will be functions that the user will need to call. In addition, any function that is exported is required to have documentation.\nUnder the @examples directive, you can put R code that demonstrates how to call the function. Here, we provide a simple example of how to use the hello() function.\n\nOnce the documentation is written, we can write the code for the function itself. The complete R script file looks as follows.\n#' Print a Greeting\n#'\n#' Print a greeting for a custom name\n#'\n#' @details This function make a plot with a greeting to the name passed as an argument to the function\n\n#' @param name character, name of person to whom greeting should be directed\n#'\n#' @return nothing useful is returned.\n#'\n#' @import ggplot2\n#' @export\n#'\n#' @examples\n#' hello(\"Chris\")\n#'\nhello &lt;- function(name) {\n        message &lt;- paste0(\"Hello, \", name, \"!\")\n        ggplot() +\n                geom_text(aes(0, 0), label = message, size = 4) +\n                theme_minimal()\n\n}\n\n\n\n\n\n\nNote\n\n\n\nIn the function we do not actually plot any data. We just use the ggplot() function to setup a plot window so that we can add the message using geom_text()."
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#editing-the-description-file",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#editing-the-description-file",
    "title": "Building R packages",
    "section": "Editing the DESCRIPTION file",
    "text": "Editing the DESCRIPTION file\nAfter writing the code and documentation we need to edit the DESCRIPTION file for the package. This contains metadata about the package. Here is the final DESCRIPTION file for the package.\nPackage: greetings\nTitle: Displays a greeting plot\nVersion: 0.0.0.9000\nAuthors@R: \n    person(given = \"Stephanie\",\n           family = \"Hicks\",\n           role = c(\"aut\", \"cre\"),\n           email = \"shicks19@jhu.edu\", \n           comment = c(ORCID = \"0000-0002-5682-5998\"))\nDescription: This package displays a nice greeting for a custom name.\nImports: ggplot2\nLicense: GPL (&gt;= 3)\nEncoding: UTF-8\nLazyData: true\nRoxygen: list(markdown = TRUE)\nRoxygenNote: 7.2.1\nWe can go through each field one at time:\n\nPackage is just the name of the package. In this case it is greetings.\nTitle is a short description of the package.\nVersion is the version number. This is the first version so we use 1.0.\nAuthors@R indicates the author of the package (this is you!). This package only has one author but packages can have multiple authors. Look at the help file for person() to see how this is specified.\nDescription provides a multi-sentence description of what the package does.\nImports is only needed because the package imports the functions from the ggplot2 package. You will need to add this line explicitly to the DESCRIPTION file.\nLicense indicates the legal license for the package. This should be an open source license and we use the GNU General Public License Version 3 here. You can read more about R package licenses. Every R package must have a license.\n\nThe remaining fields are auto-generated by RStudio and you don’t need to worry about them for now."
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#within-rstudio",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#within-rstudio",
    "title": "Building R packages",
    "section": "Within RStudio",
    "text": "Within RStudio\nIn the Build tab, click the button labeled Install and Restart.\n\n\n\n\n\n\nNote\n\n\n\nOn more recent versions of RStudio, it might just stay “Install”, not “Install and Restart”.\n\n\n\n\n\n\n\nClick the Build tab to install and restart\n\n\n\n\nClicking this button will\n\nBuild the R package\nInstall the R package on your system\nRestart the R session\nLoad your package using the library() function.\n\nOnce this is done, you can call the hello() function and see the results.\n\n\n\n\n\nNow you can load and use the hello() function"
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#build-source-package",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#build-source-package",
    "title": "Building R packages",
    "section": "Build Source Package",
    "text": "Build Source Package\nOnce the package is completed, you must build a source package so that it can be distributed to others. This can be done in the Build menu and clicking Build source package.\n\n\n\n\n\nBuild the source package\n\n\n\n\nThis will produce a file with a .tar.gz extension. This is the package source file.\nYou should see a screen that looks something like this.\n\n\n\n\n\nSource file is built (file ends in a .tar.gz)\n\n\n\n\nOnce your package is built, you can send to others and they will be able to install it. The package source file would also be the file that would be uploaded to CRAN if you were submitting a package to CRAN.\n\n\n\n\n\n\nPro-tip\n\n\n\nIf you are interested, you can also use the usethis package to create, build, document, and install a R package:\n\nhttps://usethis.r-lib.org\n\nFWIW, this is how I create R packages."
  },
  {
    "objectID": "posts/2023-11-21-r-pkg-dev/index.html#install-from-github",
    "href": "posts/2023-11-21-r-pkg-dev/index.html#install-from-github",
    "title": "Building R packages",
    "section": "Install from GitHub",
    "text": "Install from GitHub\nYou can also install an R package that’s available on GitHub. For example, here is the greetings package on my personal GitHub page - https://github.com/stephaniehicks/greetings\nTo install this, we can use the remotes::install_github(repo=\"username/repo\") function:\n\nremotes::install_github(repo = \"stephaniehicks/greetings\")"
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html",
    "href": "posts/2023-11-14-oop-part-1/index.html",
    "title": "Object Oriented Programming",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://adv-r.hadley.nz/oo\nhttps://adv-r.hadley.nz/base-types\nhttps://adv-r.hadley.nz/s3\nhttps://adv-r.hadley.nz/s4\n\n\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://rdpeng.github.io/Biostat776/lecture-object-oriented-programming\nhttps://adv-r.hadley.nz/oo\nhttps://www.educative.io/blog/object-oriented-programming"
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#oop-in-r",
    "href": "posts/2023-11-14-oop-part-1/index.html#oop-in-r",
    "title": "Object Oriented Programming",
    "section": "OOP in R",
    "text": "OOP in R\nBase R has three object oriented systems, because the roots of R date back to 1976, when the idea of object orientated programming was barely four years old.\nNew object oriented paradigms were added to R as they were invented, and they exist in their own R packages.\n\n\n\n\n\n\nWhy is OOP hard in R?\n\n\n\nOOP is a little more challenging in R than in other languages because:\n\nThere are multiple OOP systems to choose from. Here, I will focus on the following three: S3, R6, and S4.\n\n\nS3 and S4 are provided by base R (two older OOP languages).\nR6 is provided by the R6 package, and is similar to the\nReference Classes, or RC for short, from base R. Programmers who are already familiar with object oriented programming will feel at home using RC.\n\n\nThere is disagreement about the relative importance of the OOP systems. Hadley Wickham thinks S3 is most important, followed by R6, then S4. Others believe that S4 is most important (e.g. Bioconductor community), followed by RC, and that S3 should be avoided. This means that different R communities use different systems.\nS3 and S4 use generic function OOP which is rather different from the encapsulated OOP used by most languages popular today (the exception is Julia which also uses generic function OOP) (more on these later). Basically, while the underlying ideas of OOP are the same across languages, their expressions are rather different. This means that you can not immediately transfer your existing OOP skills to R.\n\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nGenerally in R, functional programming is much more important than object-oriented programming, because you typically solve complex problems by decomposing them into simple functions, not simple objects.\n\n\nThis lesson focuses on the mechanics of OOP, not its effective use, and it may be challenging to fully understand if you have not done object-oriented programming before."
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#sloop",
    "href": "posts/2023-11-14-oop-part-1/index.html#sloop",
    "title": "Object Oriented Programming",
    "section": "sloop",
    "text": "sloop\nBefore we go on I want to introduce the sloop package:\n\nlibrary(sloop)\n\nThe sloop package (think “sail the seas of OOP”) provides a number of helpers that fill in missing pieces in base R. The first of these is sloop::otype(). It makes it easy to figure out the OOP system used by a wild-caught object:\n\notype(1:10)\n\n[1] \"base\"\n\n\n\nlibrary(palmerpenguins)\notype(penguins)\n\n[1] \"S3\"\n\n\n\nmle_obj &lt;- stats4::mle(function(x = 1) (x - 2) ^ 2)\notype(mle_obj)\n\n[1] \"S4\""
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#oop-systems",
    "href": "posts/2023-11-14-oop-part-1/index.html#oop-systems",
    "title": "Object Oriented Programming",
    "section": "OOP systems",
    "text": "OOP systems\nDifferent people use OOP terms in different ways, so this section provides a quick overview of important vocabulary. The explanations are necessarily compressed, but we will come back to these ideas multiple times.\nThe main reason to use OOP is polymorphism (literally: many shapes).\n\nPolymorphism means that a developer can consider a function’s interface separately from its implementation, making it possible to use the same function form for different types of input.\nThis is closely related to the idea of encapsulation: the user doesn’t need to worry about details of an object because they are encapsulated behind a standard interface.\n\nTo be concrete, polymorphism is what allows summary() to produce different outputs for numeric and factor variables:\n\nsummary(penguins$bill_length_mm)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n  32.10   39.23   44.45   43.92   48.50   59.60       2 \n\nsummary(penguins$species)\n\n   Adelie Chinstrap    Gentoo \n      152        68       124 \n\n\nYou could imagine summary() containing a series of if-else statements, but that would mean only the original author could add new implementations. An OOP system makes it possible for any developer to extend the interface with implementations for new types of input.\nTo be more precise, OO systems call the type of an object its class, and an implementation for a specific class is called a method. Roughly speaking,\n\na class defines what an object is and\nmethods describe what that object can do\n\nThe class defines the fields (or attributes), the data possessed by every instance of that class. Classes are organised in a hierarchy so that if a method does not exist for one class, its parent’s method is used, and the child is said to inherit behavior.\n\n\n\n\n\n\nExample\n\n\n\n\nAn ordered factor inherits from a regular factor.\nA generalized linear model inherits from a linear model.\n\n\n\nThe process of finding the correct method given a class is called method dispatch.\n\n\n\n\n\n\nTwo paradigms of OOP\n\n\n\nThe two main paradigms of OOP differ in how methods and classes are related. We will call these paradigms encapsulated and functional:\n\nIn encapsulated OOP, methods belong to objects or classes, and method calls typically look like object.method(arg1, arg2). This is called encapsulated because the object encapsulates both data (with fields) and behavior (with methods), and is the paradigm found in most popular languages.\nIn functional OOP, methods belong to generic functions, and method calls look like ordinary function calls: generic(object, arg2, arg3). This is called functional because from the outside it looks like a regular function call, and internally the components are also functions.\n\n\n\nWith this terminology in hand, we can now talk precisely about the different OO systems available in R."
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#oop-principles",
    "href": "posts/2023-11-14-oop-part-1/index.html#oop-principles",
    "title": "Object Oriented Programming",
    "section": "OOP principles",
    "text": "OOP principles\nOk let’s talk more about some OOP principles. The first is is the idea of a class and an object.\nThe world is made up of physical objects - the chair you are sitting in, the clock next to your bed, the bus you ride every day, etc. Just like the world is full of physical objects, your programs can be made of objects as well.\nA class is a blueprint for an object: it describes the parts of an object, how to make an object, and what the object is able to do.\n\n\n\n\n\n\nExample\n\n\n\nIf you were to think about a class for a bus (as in the public buses that roam the roads), this class would describe attributes for the bus like\n\nthe number of seats on the bus\nthe number of windows\nthe color of the bus\nthe top speed of the bus\nthe maximum distance the bus can drive on one tank of gas\n\n\n\nA method is a function that is associated with a class to perform an action.\n\n\n\n\n\n\nExample\n\n\n\nBuses, in general, can perform the same actions, and these actions are also described in the class:\n\na bus can open and close its doors\nthe bus can steer\nthe accelerator or the brake can be used to slow down or speed up the bus\n\n\n\nA constructor is a method to specify attributes of the class to create a object with the specific attributes that we specified.\n\n\n\n\n\n\nExample\n\n\n\nWe will use the bus class in order to create individual bus objects.\nTo do this, we will create a constructor method for the bus class to return an individual bus object with the attributes that we specified.\n\n\nIf we want to make a new class that has all the same attributes and methods as an existing class, but also has additional attributes, we do not want to rewrite the entire class, but rather we want to define a new class that inherits from the original class.\n\n\n\n\n\n\nExample\n\n\n\nImagine that after making the bus class you might want to make a special kind of class for a party bus.\nThe party_bus class has all of the same attributes and methods as our bus class, but they also has additional attributes and methods like\n\nthe number of refrigerators\nwindow blinds that can be opened and closed\nsmoke machines that can be turned on and off\n\n\n\nIn this framework of inheritance, we talk about the bus class as the super-class of the party bus, and the party bus is the sub-class of the bus.\nWhat this relationship means is that the party bus has all of the same attributes and methods as the bus class plus additional attributes and methods."
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#oop-in-r-v2",
    "href": "posts/2023-11-14-oop-part-1/index.html#oop-in-r-v2",
    "title": "Object Oriented Programming",
    "section": "OOP in R (v2)",
    "text": "OOP in R (v2)\nBase R provides three OOP systems: S3, S4, and reference classes (RC):\n\nS3 is R’s first OOP system, and is described in Statistical Models in S. S3 is an informal implementation of functional OOP and relies on common conventions rather than ironclad guarantees. This makes it easy to get started with, providing a low cost way of solving many simple problems.\nS4 is a formal and rigorous rewrite of S3, and was introduced in Programming with Data. It requires more upfront work than S3, but in return provides more guarantees and greater encapsulation. S4 is implemented in the base methods package, which is always installed with R.\n\n\n\n\n\n\n\nPro-tip\n\n\n\nYou might wonder if S1 and S2 exist. They don’t: S3 and S4 were named according to the versions of S that they accompanied. The first two versions of S didn’t have any OOP framework.\n\n\n\nRC implements encapsulated OO. RC objects are a special type of S4 objects that are also mutable (i.e., instead of using R’s usual copy-on-modify semantics, they can be modified in place). This makes them harder to reason about, but allows them to solve problems that are difficult to solve in the functional OOP style of S3 and S4."
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#base-types",
    "href": "posts/2023-11-14-oop-part-1/index.html#base-types",
    "title": "Object Oriented Programming",
    "section": "Base types",
    "text": "Base types\nWhile only OO objects have a class attribute, every object has a base type:\n\ntypeof(1:10)\n\n[1] \"integer\"\n\ntypeof(mtcars)\n\n[1] \"list\"\n\n\nBase types do not form an OOP system because functions that behave differently for different base types are primarily written in C code that uses switch statements.\nThis means that only the R-core team can create new types, and creating a new type is a lot of work because every switch statement needs to be modified to handle a new case. As a consequence, new base types are rarely added.\n\n\n\n\n\n\nPro-tip\n\n\n\nIn total, there are 25 different base types.\n\n\nHere are some more base types we have already learned about:\n\ntypeof(NULL)\n\n[1] \"NULL\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(1i)\n\n[1] \"complex\""
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#oo-objects",
    "href": "posts/2023-11-14-oop-part-1/index.html#oo-objects",
    "title": "Object Oriented Programming",
    "section": "OO objects",
    "text": "OO objects\nAt a high-level, an S3 object is a base type with at least a class attribute.\n\n\n\n\n\n\nExample\n\n\n\nTake the factor. Its base type is the integer vector, it has a class attribute of “factor”, and a levels attribute that stores the possible levels:\n\nf &lt;- factor(c(\"a\", \"b\", \"c\"))\ntypeof(f)\n\n[1] \"integer\"\n\nattributes(f)\n\n$levels\n[1] \"a\" \"b\" \"c\"\n\n$class\n[1] \"factor\"\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s consider the penguins data frame.\n\nWhat is it’s base type?\nWhat is it’s class attribute?\nWhat other attributes does it have?\n\n\n## try it here\n\n\n\nCool. Let’s try creating a new class in the S3 system.\nIn the S3 system you can arbitrarily assign a class to any object. Class assignments can be made using the structure() function, or you can assign the class using class() and &lt;-:\n\nspecial_num_1 &lt;- structure(1, class = \"special_number\")\nspecial_num_1\n\n[1] 1\nattr(,\"class\")\n[1] \"special_number\"\n\nclass(special_num_1)\n\n[1] \"special_number\"\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s assign the number 2 to special_num_2 and look at the class of special_num_2.\n\n### try it here\n\nWhat’s happened here?\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nNext, let’s assign “special_number” to the class of special_num_2.\n\nclass(special_num_2) &lt;- \"special_number\"\nclass(special_num_2)\nspecial_num_2\n\nWhat’s happening here?\n\n\nAs crazy as this is, it is completely legal R code, but if you want to have a better behaved S3 class you should create a constructor which returns an S3 object.\n\nCreate a constructor called shape_s3()\n\n\n\n\n\n\nExample\n\n\n\nConsider the shape_s3() function below, which is a constructor that returns a shape_S3 object:\n\nshape_s3 &lt;- function(side_lengths){\n  structure(list(side_lengths = side_lengths), class = \"shape_S3\")\n}\n\nsquare_4 &lt;- shape_s3(c(4, 4, 4, 4))\nclass(square_4)\n\n[1] \"shape_S3\"\n\ntriangle_3 &lt;- shape_s3(c(3, 3, 3))\nclass(triangle_3)\n\n[1] \"shape_S3\"\n\n\nWe have now made two shape_S3 objects: square_4 and triangle_3, which are both instantiations of the shape_S3 class.\n\n\nImagine that you wanted to create a method (or function) that would return TRUE if a shape_S3 object was a square, FALSE if a shape_S3 object was not a square, and NA if the object provided as an argument to the method was not a shape_S3 object.\nThis can be achieved using R’s generic methods system. A generic method can return different values based depending on the class of its input.\n\n\n\n\n\n\nExample\n\n\n\nFor example, mean() is a generic method that can find the average of a vector of number or it can find the “average day” from a vector of dates.\n\nmean(c(2, 3, 7))\n\n[1] 4\n\nmean(c(as.Date(\"2016-09-01\"), as.Date(\"2016-09-03\")))\n\n[1] \"2016-09-02\"\n\n\n\n\n\n\nCreate a generic method called is_square()\nNow, let’s create a generic method for identifying shape_S3 objects that are squares.\n\n\n\n\n\n\nStep 1: use UseMethod()\n\n\n\nFirst, the creation of every generic method uses the UseMethod() function in the following way with only slight variations:\n[name of method] &lt;- function(x) UseMethod(\"[name of method]\")\nLet’s call this method is_square:\n\nis_square &lt;- function(x) UseMethod(\"is_square\")\n\n\n\n\n\n\n\n\n\nStep 2: Define what’s inside the method\n\n\n\nNext, we add the actual definition for the function to detect whether or not a shape is a square by specifying is_square.shape_S3.\nBy putting a dot (.) and then the name of the class after is_square, we can create a method that associates is_square with the shape_S3 class:\n\nis_square.shape_S3 &lt;- function(x){\n  length(x$side_lengths) == 4 &&\n    x$side_lengths[1] == x$side_lengths[2] &&\n    x$side_lengths[2] == x$side_lengths[3] &&\n    x$side_lengths[3] == x$side_lengths[4]\n}\n\nis_square(square_4)\n\n[1] TRUE\n\nis_square(triangle_3)\n\n[1] FALSE\n\n\n\n\nSeems to be working well!\nWe also want is_square() to return NA when its argument is not a shape_S3.\nWe can specify is_square.default as a last resort if there is not method associated with the object passed to is_square().\n\nis_square.default &lt;- function(x){\n  NA\n}\n\nis_square(\"square\")\n\n[1] NA\n\nis_square(c(1, 1, 1, 1))\n\n[1] NA\n\n\nLet’s try printing square_4:\n\nprint(square_4)\n\n$side_lengths\n[1] 4 4 4 4\n\nattr(,\"class\")\n[1] \"shape_S3\"\n\n\nDoesn’t that look ugly?\n\n\nCreate a generic method print() for shape_S3 class\nLucky for us print() is a generic method, so we can specify a print method for the shape_S3 class:\n\nprint.shape_S3 &lt;- function(x){\n  if(length(x$side_lengths) == 3){\n    paste(\"A triangle with side lengths of\", x$side_lengths[1], \n          x$side_lengths[2], \"and\", x$side_lengths[3])\n  } else if(length(x$side_lengths) == 4) {\n    if(is_square(x)){\n      paste(\"A square with four sides of length\", x$side_lengths[1])\n    } else {\n      paste(\"A quadrilateral with side lengths of\", x$side_lengths[1],\n            x$side_lengths[2], x$side_lengths[3], \"and\", x$side_lengths[4])\n    }\n  } else {\n    paste(\"A shape with\", length(x$side_lengths), \"sides.\")\n  }\n}\n\nprint(square_4)\n\n[1] \"A square with four sides of length 4\"\n\nprint(triangle_3)\n\n[1] \"A triangle with side lengths of 3 3 and 3\"\n\nprint(shape_s3(c(10, 10, 20, 20, 15)))\n\n[1] \"A shape with 5 sides.\"\n\nprint(shape_s3(c(2, 3, 4, 5)))\n\n[1] \"A quadrilateral with side lengths of 2 3 4 and 5\"\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nSince printing an object to the console is one of the most common things to do in R, nearly every class has an associated print method!\nTo see all of the methods associated with a generic like print() use the methods() function:\n\nlength(methods(print))\n\n[1] 263\n\nhead(methods(print), 10)\n\n [1] \"print.acf\"               \"print.activeConcordance\"\n [3] \"print.AES\"               \"print.anova\"            \n [5] \"print.aov\"               \"print.aovlist\"          \n [7] \"print.ar\"                \"print.Arima\"            \n [9] \"print.arima0\"            \"print.AsIs\"             \n\n\n\n\n\n\nInheritance\nOne last note on S3 with regard to inheritance.\nIn the previous section we discussed how a sub-class can inherit attributes and methods from a super-class.\nSince you can assign any class to an object in S3, you can specify a super class for an object the same way you would specify a class for an object:\n\nclass(square_4)\n\n[1] \"shape_S3\"\n\nclass(square_4) &lt;- c(\"shape_S3\", \"square\")\nclass(square_4)\n\n[1] \"shape_S3\" \"square\"  \n\n\nTo check if an object is a sub-class of a specified class you can use the inherits() function:\n\ninherits(square_4, \"square\")\n\n[1] TRUE"
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#example-s3-classmethods-for-polygons",
    "href": "posts/2023-11-14-oop-part-1/index.html#example-s3-classmethods-for-polygons",
    "title": "Object Oriented Programming",
    "section": "Example: S3 Class/Methods for Polygons",
    "text": "Example: S3 Class/Methods for Polygons\nThe S3 system doesn’t have a formal way to define a class but typically, we use a list to define the class and elements of the list serve as data elements.\nHere is our definition of a polygon represented using Cartesian coordinates.\n\nThe class contains an element called xcoord and ycoord for the x- and y-coordinates, respectively.\nThe make_poly() function is the “constructor” function for polygon objects. It takes as arguments a numeric vector of x-coordinates and a corresponding numeric vector of y-coordinates.\n\n\n## Constructor function for polygon objects\n## x a numeric vector of x coordinates\n## y a numeric vector of y coordinates\nmake_poly &lt;- function(x, y) {\n        if(length(x) != length(y))\n                stop(\"'x' and 'y' should be the same length\")\n        \n        ## Create the \"polygon\" object \n        object &lt;- list(xcoord = x, ycoord = y)\n        \n        ## Set the class name\n        class(object) &lt;- \"polygon\"\n        object\n}\n\nNow that we have a class definition, we can develop some methods for operating on objects from that class.\nThe first method that we will define is the print() method. The print() method should just show some simple information about the object and should not be too verbose—just enough information that the user knows what the object is.\nHere the print() method just shows the user how many vertices the polygon has.\nIt is a convention for print() methods to return the object x invisibly using the invisible() function.\n\n## Print method for polygon objects\n## x an object of class \"polygon\"\n\nprint.polygon &lt;- function(x, ...) {\n        cat(\"a polygon with\", length(x$xcoord), \n            \"vertices\\n\")\n        invisible(x)\n}\n\n\n\n\n\n\n\nPro-tip\n\n\n\nThe invisible() function is useful when it is desired to have functions return values which can be assigned, but which do not print when they are not assigned.\n\n\n\n\n\n\n\n\nExample\n\n\n\nThese functions both return their argument\n\nf1 &lt;- function(x) x\nf2 &lt;- function(x) invisible(x)\n\nf1(1)  # prints\n\n[1] 1\n\nf2(1)  # does not print\n\nHowever, when you assign the f2() function to an object, it does return the value\n\nz &lt;- f2(1)\nz\n\n[1] 1\n\n\n\n\nNext is the summary() method.\nThe summary() method typically shows a bit more information and may even do some calculations, but does not print something. The general strategy of summary() methods is\n\nThe summary() method returns an object of class \"summary_'class name'\"\nThere is a separate print() method for \"summary_'class name'\" objects.\n\nFor example, here is a summary() method for polygon objects that computes the ranges of the x- and y-coordinates.\n\n## object an object of class \"polygon\"\n\nsummary.polygon &lt;- function(object, ...) {\n        object &lt;- list(rng.x = range(object$xcoord),\n                       rng.y = range(object$ycoord))\n        class(object) &lt;- \"summary_polygon\"\n        object\n}\n\n\n\n\n\n\n\nNote\n\n\n\nThe summary method simply returns an object of class summary_polygon.\n\n\nNow the corresponding print() method for summary.polygon objects:\n\n## Note: x an object of class \"summary_polygon\"\nprint.summary_polygon &lt;- function(x, ...) {\n        cat(\"x:\", x$rng.x[1], \"--&gt;\", x$rng.x[2], \"\\n\")\n        cat(\"y:\", x$rng.y[1], \"--&gt;\", x$rng.y[2], \"\\n\")\n        invisible(x)\n}\n\nNow we can make use of our new polygon class and methods (summary() and print()).\n\n## Construct a new \"polygon\" object\nx &lt;- make_poly(1:4, c(1, 5, 2, 1))\nattributes(x)\n\n$names\n[1] \"xcoord\" \"ycoord\"\n\n$class\n[1] \"polygon\"\n\n\nWe can use the print() to see what the object is.\n\nprint(x)\n\na polygon with 4 vertices\n\n\nAnd we can use the summary() method to get a bit more information about the object.\n\nout &lt;- summary(x)\nclass(out)\n\n[1] \"summary_polygon\"\n\nprint(out)\n\nx: 1 --&gt; 4 \ny: 1 --&gt; 5 \n\n\nBecause of auto-printing we can just call the summary() method and let the results auto-print.\n\nsummary(x)\n\nx: 1 --&gt; 4 \ny: 1 --&gt; 5 \n\n\n\n\n\n\n\n\nWhat next?\n\n\n\nFrom here, we could build other methods for interacting with our polygon object.\nFor example, it may make sense to define a plot() method or maybe methods for intersecting two polygons together."
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#constructors-in-s4",
    "href": "posts/2023-11-14-oop-part-1/index.html#constructors-in-s4",
    "title": "Object Oriented Programming",
    "section": "Constructors in S4",
    "text": "Constructors in S4\n\nTo create a new class in S4 you need to use the setClass() function.\nYou need to specify two (or three arguments) for this function:\n\nClass which is the name of the class as a string\nslots, which is a named list of attributes for the class with the class of those attributes specified\n(optionally) contains, which includes the super-class of they class you are specifying (if there is a super-class)\n\n\nTake look at the class definition for a bus_S4 and a party_bus_S4 below:\n\nsetClass(Class = \"bus_S4\",\n         slots = list(n_seats = \"numeric\", \n                      top_speed = \"numeric\",\n                      current_speed = \"numeric\",\n                      brand = \"character\"))\nsetClass(Class = \"party_bus_S4\",\n         slots = list(n_subwoofers = \"numeric\",\n                      smoke_machine_on = \"logical\"),\n         contains = \"bus_S4\")\n\nNow that we have created the bus_S4 and the party_bus_S4 classes we can create bus objects using the new() function. The new() function’s arguments are the name of the class and values for each “slot” in our S4 object.\n\nmy_bus &lt;- new(\"bus_S4\", n_seats = 20, top_speed = 80, \n              current_speed = 0, brand = \"Volvo\")\nmy_bus\n\nAn object of class \"bus_S4\"\nSlot \"n_seats\":\n[1] 20\n\nSlot \"top_speed\":\n[1] 80\n\nSlot \"current_speed\":\n[1] 0\n\nSlot \"brand\":\n[1] \"Volvo\"\n\nmy_party_bus &lt;- new(\"party_bus_S4\", n_seats = 10, top_speed = 100,\n                    current_speed = 0, brand = \"Mercedes-Benz\", \n                    n_subwoofers = 2, smoke_machine_on = FALSE)\nmy_party_bus\n\nAn object of class \"party_bus_S4\"\nSlot \"n_subwoofers\":\n[1] 2\n\nSlot \"smoke_machine_on\":\n[1] FALSE\n\nSlot \"n_seats\":\n[1] 10\n\nSlot \"top_speed\":\n[1] 100\n\nSlot \"current_speed\":\n[1] 0\n\nSlot \"brand\":\n[1] \"Mercedes-Benz\"\n\n\nYou can use the @ operator to access the slots of an S4 object:\n\nmy_bus@n_seats\n\n[1] 20\n\nmy_party_bus@top_speed\n\n[1] 100\n\n\nThis is essentially the same as using the $ operator with a list or an environment."
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#methods-in-s4",
    "href": "posts/2023-11-14-oop-part-1/index.html#methods-in-s4",
    "title": "Object Oriented Programming",
    "section": "Methods in S4",
    "text": "Methods in S4\nS4 classes use a generic method system that is similar to S3 classes. In order to implement a new generic method you need to use the setGeneric() function and the standardGeneric() function in the following way:\nsetGeneric(\"new_generic\", function(x){\n  standardGeneric(\"new_generic\")\n})\nLet’s create a generic function called is_bus_moving() to see if a bus_S4 object is in motion:\n\nsetGeneric(\"is_bus_moving\", function(x){\n  standardGeneric(\"is_bus_moving\")\n})\n\n[1] \"is_bus_moving\"\n\n\nNow, we need to actually define the function, which we can to with setMethod().\nThe setMethod() functions takes as arguments\n\nthe name of the method as a string (or f)\nthe method signature (signature), which specifies the class of each argument for the method\nthe function definition of the method\n\n\nsetMethod(f = \"is_bus_moving\",\n          signature = c(x = \"bus_S4\"),\n          definition = function(x){\n                          x@current_speed &gt; 0\n                      }\n          )\n\nis_bus_moving(my_bus)\n\n[1] FALSE\n\nmy_bus@current_speed &lt;- 1\nis_bus_moving(my_bus)\n\n[1] TRUE\n\n\nIn addition to creating your own generic methods, you can also create a method for your new class from an existing generic.\nFirst, use the setGeneric() function with the name of the existing method you want to use with your class, and then use the setMethod() function like in the previous example. Let’s make a print() method for the bus_S4 class:\n\nsetGeneric(\"print\")\n\n[1] \"print\"\n\nsetMethod(f = \"print\",\n          signature = c(x = \"bus_S4\"),\n          definition = function(x){\n            paste(\"This\", x@brand, \"bus is traveling at a speed of\", x@current_speed)\n          })\n\nprint(my_bus)\n\n[1] \"This Volvo bus is traveling at a speed of 1\"\n\nprint(my_party_bus)\n\n[1] \"This Mercedes-Benz bus is traveling at a speed of 0\""
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#background",
    "href": "posts/2023-11-14-oop-part-1/index.html#background",
    "title": "Object Oriented Programming",
    "section": "Background",
    "text": "Background\nContinuous glucose monitoring (CGM) is novel sensor modality which estimates blood glucose quasi-continuously over 2 weeks in free-living conditions. This facilitates real-time management and comprehensive characterization of glucose for persons with diabetes.\n\n\n\nCGM Device (Abbott Libre Pro)\n\n\n\n\n\nExample CGM Time-Series"
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#oop-for-cgm-data",
    "href": "posts/2023-11-14-oop-part-1/index.html#oop-for-cgm-data",
    "title": "Object Oriented Programming",
    "section": "OOP For CGM Data",
    "text": "OOP For CGM Data\nCGM is often collected with other biomarkers, demographic information, and follow-up indicators when used in epidemiological studies. OOP makes it possible to store these different data modalities together in an Object for each person and to standardize operations upon a person’s data.\n\nsimulated_CGM &lt;- as.numeric(arima.sim(model = list(ar = 0.8, ma = 0.5), n = 1440) + 80)\nsimulated_TS &lt;- seq(from = Sys.time(), length.out = 1440, by = 15*60)\ndemo &lt;- list(Age = 55, Gender = \"F\")\nbiomk &lt;- list(BMI = 25, HbA1c = 8.5)"
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#s3-constructor-for-cgm-object",
    "href": "posts/2023-11-14-oop-part-1/index.html#s3-constructor-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S3 Constructor for CGM Object",
    "text": "S3 Constructor for CGM Object\n\ncgm_s3 &lt;- function(CGM_data, CGM_datetimes, demographics, biomarkers){\n  structure(list(Data = CGM_data, Times = CGM_datetimes,\n                 Age = demographics$Age, Gender = demographics$Gender, \n                 BMI = biomarkers$BMI, HbA1c = biomarkers$BMI), class = \"cgm_S3\")\n}\n\ncgm_profile &lt;- cgm_s3(simulated_CGM, simulated_TS, demo, biomk)\nclass(cgm_profile)\n\n[1] \"cgm_S3\""
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#s3-methods-for-cgm-object",
    "href": "posts/2023-11-14-oop-part-1/index.html#s3-methods-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S3 Methods for CGM Object",
    "text": "S3 Methods for CGM Object\nWe may want to overwrite the generic “print” and “summary” methods, outputting a plot of the CGM data in the former case or returning a subset of pertinent information in the latter.\n\nprint.cgm_S3 &lt;- function(x, ...){\n  plot(x = x$Times, y = x$Data, type = \"l\", \n       xlab = \"Date-time\", ylab = \"Glucose (mg/dL)\")\n  invisible(x)\n}\n\nprint(cgm_profile)\n\n\n\n\n\nsummary.cgm_S3 &lt;- function(x, ...){\n  demo_string &lt;- paste0(\"Age: \", x$Age, \", Gender: \", x$Gender)\n  biomk_string &lt;- paste0(\"BMI: \", x$BMI, \", HbA1c: \", x$HbA1c)\n  cgm_string &lt;- paste0(\"Mean Glucose: \", round(mean(x$Data), 2), \", Std. Dev. Glucose: \", round(sd(x$Data), 2))\n  object &lt;- list(demographics = demo_string, \n                 biomarkers = biomk_string, \n                 cgm = cgm_string)\n  class(object) &lt;- \"summary_CGM\"\n  object\n}\n\nprint.summary_CGM &lt;- function(x, ...){\n  cat(paste(paste0(\"Demographics - \", x$demographics), \n            paste0(\"Biomarkers - \", x$biomarkers), \n            paste0(\"CGM Metrics - \", x$cgm), sep = \"\\n\"))\n  invisible(x)\n}\n\nsummary(cgm_profile)\n\nDemographics - Age: 55, Gender: F\nBiomarkers - BMI: 25, HbA1c: 25\nCGM Metrics - Mean Glucose: 80.05, Std. Dev. Glucose: 2.39\n\n\nWe may also wish to perform any range of standard operations upon the CGM time series data, like smoothing.\n\nsmooth &lt;- function(x) UseMethod(\"smooth\")\nsmooth.cgm_S3 &lt;- function(x){\n  smoothed_CGM &lt;- fitted(lm(x$Data ~ bs(x$Times, df = 12*14)))\n  x$Data &lt;- smoothed_CGM\n  return(x)\n}\n\nsmoothed_cgm_profile = smooth(cgm_profile)\nprint(smoothed_cgm_profile)"
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#s4-constructor-for-cgm-object",
    "href": "posts/2023-11-14-oop-part-1/index.html#s4-constructor-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S4 Constructor for CGM Object",
    "text": "S4 Constructor for CGM Object\n\nsetClass(Class = \"cgm_S4\", \n         slots = list(Data = \"numeric\", \n                      Times = \"POSIXct\", \n                      Age = \"numeric\", \n                      Gender = \"character\", \n                      BMI = \"numeric\", \n                      HbA1c = \"numeric\"))\n\ncgm_profile &lt;- new(\"cgm_S4\", Data = simulated_CGM, Times = simulated_TS,\n                   Age = demo$Age, Gender = demo$Gender, BMI = biomk$BMI, \n                   HbA1c = biomk$HbA1c)\n\nclass(cgm_profile)\n\n[1] \"cgm_S4\"\nattr(,\"package\")\n[1] \".GlobalEnv\""
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#s4-methods-for-cgm-object",
    "href": "posts/2023-11-14-oop-part-1/index.html#s4-methods-for-cgm-object",
    "title": "Object Oriented Programming",
    "section": "S4 Methods for CGM Object",
    "text": "S4 Methods for CGM Object\nWe can overwrite the generic “print” and “summary” methods to achieve the same functionality in S4.\n\nsetGeneric(\"print\")\n\n[1] \"print\"\n\nsetGeneric(\"summary\")\n\n[1] \"summary\"\n\nsetGeneric(\"smooth\", function(x){\n  standardGeneric(\"smooth\")\n})\n\n[1] \"smooth\"\n\n\n\nsetMethod(f = \"print\", \n          signature = c(x = \"cgm_S4\"), \n          definition = function(x){\n            plot(x = x@Times, y = x@Data, type = \"l\", \n            xlab = \"Date-time\", ylab = \"Glucose (mg/dL)\")\n            invisible(x)\n          })\n\nprint(cgm_profile)\n\n\n\n\n\nsetMethod(f = \"summary\", \n          signature = c(object = \"cgm_S4\"), \n          definition = function(object){\n            MG = round(mean(object@Data), 2)\n            SDG = round(sd(object@Data), 2)\n            \n            demo_string &lt;- paste0(\"Demographics - Age: \", object@Age, \", Gender: \", object@Gender)\n            biomk_string &lt;- paste0(\"Biomarkers - BMI: \", object@BMI, \", HbA1c: \", object@HbA1c)\n            cgm_string &lt;- paste0(\"CGM Metrics - Mean Glucose: \", MG, \", Std. Dev. Glucose: \", SDG)\n            cat(paste(demo_string, biomk_string, cgm_string, sep = \"\\n\"))\n            invisible(object)\n          })\n\nsummary(cgm_profile)\n\nDemographics - Age: 55, Gender: F\nBiomarkers - BMI: 25, HbA1c: 8.5\nCGM Metrics - Mean Glucose: 80.05, Std. Dev. Glucose: 2.39\n\n\n\nsetMethod(f = \"smooth\", \n          signature = c(x = \"cgm_S4\"), \n          definition = function(x){\n            smoothed_CGM &lt;- fitted(lm(x@Data ~ bs(x@Times, df = 12*14)))\n            x@Data &lt;- smoothed_CGM\n            x\n          })\n\nsmoothed_cgm_profile = smooth(cgm_profile)\nprint(smoothed_cgm_profile)"
  },
  {
    "objectID": "posts/2023-11-14-oop-part-1/index.html#rc-constructor-for-cgm-object-with-methods",
    "href": "posts/2023-11-14-oop-part-1/index.html#rc-constructor-for-cgm-object-with-methods",
    "title": "Object Oriented Programming",
    "section": "RC Constructor for CGM Object with Methods",
    "text": "RC Constructor for CGM Object with Methods\nAll of the same functionality can also be replicated using Reference Classes. This alternative framework might even be preferable for this application, as packaging methods with objects compartmentalizes functionality for easily-distributable and accessible software. The objects are also mutable, unlike S3 and S4, which is preferable for certain types of objects which should be fluid when used.\n\ncgm_RC &lt;- setRefClass(\"cgm_RC\", \n                      fields = list(Data = \"numeric\", \n                                    Times = \"POSIXct\", \n                                    Age = \"numeric\", \n                                    Gender = \"character\", \n                                    BMI = \"numeric\", \n                                    HbA1c = \"numeric\"), \n              methods = list(\n                  print = function(){\n                    plot(x = Times, y = Data, type = \"l\", \n                        xlab = \"Date-time\", ylab = \"Glucose (mg/dL)\")\n                    invisible(.self)\n                  },\n                  summmary = function(){\n                    MG = round(mean(Data), 2)\n                    SDG = round(sd(Data), 2)\n            \n                    demo_string &lt;- paste0(\"Demographics - Age: \", Age, \", Gender: \", Gender)\n                    biomk_string &lt;- paste0(\"Biomarkers - BMI: \", BMI, \", HbA1c: \", HbA1c)\n                    cgm_string &lt;- paste0(\"CGM Metrics - Mean Glucose: \", MG, \", Std. Dev. Glucose: \", SDG)\n                    cat(paste(demo_string, biomk_string, cgm_string, sep = \"\\n\"))\n                    invisible(.self)\n                  },\n                  smooth = function(){\n                    smoothed_CGM &lt;- fitted(lm(Data ~ bs(Times, df = 12*14)))\n                    Data &lt;&lt;- smoothed_CGM\n                  }\n                ))\n\ncgm_profile &lt;- cgm_RC$new(Data = simulated_CGM, Times = simulated_TS,\n                   Age = demo$Age, Gender = demo$Gender, BMI = biomk$BMI, \n                   HbA1c = biomk$HbA1c)\n\n\ncgm_profile$print()\n\n\n\n\n\ncgm_profile$summmary()\n\nDemographics - Age: 55, Gender: F\nBiomarkers - BMI: 25, HbA1c: 8.5\nCGM Metrics - Mean Glucose: 80.05, Std. Dev. Glucose: 2.39\n\n\n\ncgm_profile$smooth()\ncgm_profile$print()"
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html",
    "href": "posts/2023-11-07-version-control-part-1/index.html",
    "title": "Version control (Part 1)",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nSoftware Carpentry: Version Control with Git\n\n\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nSoftware Carpentry: Version Control with Git"
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#overview",
    "href": "posts/2023-11-07-version-control-part-1/index.html#overview",
    "title": "Version control (Part 1)",
    "section": "Overview",
    "text": "Overview\nFirst, a brief motivating example from Wolfman and Dracula. This story is from the Version Control with Git from Software Carpentry.\n\n[Source | Software Carpentry: Version Control with Git]\n\n\n\n\n\n\nThe story of Wolfman and Dracula\n\n\n\nWolfman and Dracula have been hired by Universal Missions (a space services spinoff from Euphoric State University) to investigate if it is possible to send their next planetary lander to Mars. They want to be able to work on the plans at the same time, but they have run into problems doing this in the past. If they take turns, each one will spend a lot of time waiting for the other to finish, but if they work on their own copies and email changes back and forth things will be lost, overwritten, or duplicated.\nA colleague suggests using version control to manage their work. Version control is better than mailing files back and forth:\n\nNothing that is committed to version control is ever lost, unless you work really, really hard at it. Since all old versions of files are saved, it’s always possible to go back in time to see exactly who wrote what on a particular day, or what version of a program was used to generate a particular set of results.\nAs we have this record of who made what changes when, we know who to ask if we have questions later on, and, if needed, revert to a previous version, much like the “undo” feature in an editor.\nWhen several people collaborate in the same project, it is possible to accidentally overlook or overwrite someone’s changes. The version control system automatically notifies users whenever there is a conflict between one person’s work and another’s.\n\n\n\nTeams are not the only ones to benefit from version control: lone researchers can benefit immensely. Keeping a record of what was changed, when, and why is extremely useful for all researchers if they ever need to come back to the project later on (e.g., a year later, when memory has faded).\nAnother way of thinking about this:\n\nVersion control is the lab notebook of the digital world. It is what professionals use to keep track of what they have done and to collaborate with other people. Every large software development project relies on it, and most programmers use it for their small jobs as well.\nIt is not just for software: books, papers, small data sets, and anything that changes over time or needs to be shared can and should be stored in a version control system."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#a-common-scenario",
    "href": "posts/2023-11-07-version-control-part-1/index.html#a-common-scenario",
    "title": "Version control (Part 1)",
    "section": "A common scenario",
    "text": "A common scenario\nWe have all been in this situation before: it seems unnecessary to have multiple nearly-identical versions of the same document. Some word processors let us deal with this a little better, such as Microsoft Word’s Track Changes or Google Docs’ version history.\n\n\n\n\n\nHow not to use GitHub [image from PhD Comics]\n\n\n\n\n[Source: PhD Comics]"
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#git",
    "href": "posts/2023-11-07-version-control-part-1/index.html#git",
    "title": "Version control (Part 1)",
    "section": "git",
    "text": "git\nGit is what one type of a version control system for file management. The main idea is that as you (and your collaborators) work on a project, the software tracks, and records any changes made by anyone.\n\nSimilar to the “track changes” features in Microsoft Word, but more rigorous, powerful, and scaled up to multiple files\nGreat for solo or collaborative work\nVersion control systems start with a base version of the document and then record changes you make each step of the way.\nFor example, two users can make independent sets of changes on the same document.\nUnless multiple users make changes to the same section of the document - a conflict - you can incorporate two sets of changes into the same base document.\nIt allows us to decide which changes will be made to the next version (each record of these changes is called a commit), and keeps useful metadata about them.\nThe complete history of commits for a particular project and their metadata make up a repository.\nRepositories can be kept in sync across different computers, facilitating collaboration among different people.\n\n\n\n\n\n\n\nTerminology\n\n\n\n\ncommit: a record of each set of changes in a document or file\nrepository: the complete history of commits for a particular project and their metadata\n\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nVersion control is like an unlimited ‘undo’.\nVersion control also allows many people to work in parallel."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#github",
    "href": "posts/2023-11-07-version-control-part-1/index.html#github",
    "title": "Version control (Part 1)",
    "section": "GitHub",
    "text": "GitHub\nGitHub is a hosting service on internet for git-aware folders and projects\n\nSimilar to the DropBox or Google, but more structured, powerful, and programmatic\nGreat for solo or collaborative work!\nTechnically GitHub is distinct from Git. However, GitHub is in some sense the interface and Git the underlying engine (a bit like RStudio and R).\n\nSince we will only be using Git through GitHub, I tend to not distinguish between the two. In the following, I refer to all of it as just GitHub. Note that other interfaces to Git exist, e.g., Bitbucket, but GitHub is the most widely used one.\n\n\n\n\n\n\nTip\n\n\n\nTo learn a bit more about Git/GitHub and why you might want to use it, read this article by Jenny Bryan.\nNote her explanation of what’s special with the README.md file on GitHub.\n\n\n\n\n\n\n\n\nWhat to (not) do\n\n\n\n\nGitHub is ideal if you have a project with a fair number of files, most of those files are text files (such as code, LaTeX, (R)markdown, etc.) and different people work on different parts of the project.\nGitHub is less useful if you have a lot of non-text files (e.g. Word or Powerpoint) and different team members might want to edit the same document at the same time. In that instance, a solution like Google Docs, Word+Dropbox, Word+Onedrive, etc. might be better.\n\n\n\n\n\n\n\n\n\nHow to use Git/GitHub\n\n\n\nGit and GitHub is fundamentally based on commands you type into the command line. Lots of online resources show you how to use the command line. This is the most powerful, and the way I almost always interact with git/GitHub. However, many folks find this the most confusing way to use git/GitHub. Alternatively, there are graphical interfaces.\n\nGitHub itself provides a grapical interface with basic functionality.\nRStudio also has Git/GitHub integration. Of course this only works for R project GitHub integration.\nThere are also third party GitHub clients with many advanced features, most of which you won’t need initially, but might eventually.\n\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nAs student, you can (and should) upgrade to the Pro version of GitHub for free (i.e. access to unlimited private repositories is one benefit), see the GitHub student developer pack on how to do this."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#getting-started",
    "href": "posts/2023-11-07-version-control-part-1/index.html#getting-started",
    "title": "Version control (Part 1)",
    "section": "Getting started",
    "text": "Getting started\nOne of my favorite resources for getting started with git/GitHub is the Happy Git with R from Jenny Bryan:\n\nhttps://happygitwithr.com\n\n\n\n\n\n\nA screenshot of the Happy Git with R online book from Jenny Bryan\n\n\n\n\nIt truly is one of the best resources out there for getting started with git/GitHub, especially with the integration to RStudio. Therefore, at this point, I will encourage all of you to go read through the online book.\nSome of you may only need to skim it, others will need to spend some time reading through it. Either way, I will bet that you won’t regret the time investment."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#using-gitgithub-in-our-course",
    "href": "posts/2023-11-07-version-control-part-1/index.html#using-gitgithub-in-our-course",
    "title": "Version control (Part 1)",
    "section": "Using git/GitHub in our course",
    "text": "Using git/GitHub in our course\nIn this course, you will use git/GitHub in the following ways:\n\nProjects 2-4 - You will use git locally (on your compute environment) to track your changes over time and, you will push your project solutions to a private GitHub repository on GitHub Classroom (i.e. you will use the command-line commands git add, git commit, git push, git pull, etc) .\n\nLearning these skills will be useful down the road if you ever work collaboratively on a project (i.e. writing code as a group). In this scenario, you will use the skills you have been practicing in your projects to work together as a team in a single GitHub repository."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#git-config",
    "href": "posts/2023-11-07-version-control-part-1/index.html#git-config",
    "title": "Version control (Part 1)",
    "section": "git config",
    "text": "git config\nWhen we use Git on a new computer for the first time, we need to configure a few things:\n\nour name and email address\nwhat our preferred text editor is\nand that we want to use these settings globally (i.e. for every project).\n\nOn a command line, Git commands are written as git verb options, where verb is what we actually want to do and options is additional optional information.\nHere is how to set up Git on a new laptop:\n$ git config --global user.name \"My Name\"\n$ git config --global user.email \"myemail@email.com\"\nThis user name and email will be associated with your subsequent Git activity after this lecture.\n\n\n\n\n\n\nImportant\n\n\n\nFor the lectures this week, we will be interacting with GitHub and so the email address used should be the same as the one used when setting up your GitHub account."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#git-config-settings",
    "href": "posts/2023-11-07-version-control-part-1/index.html#git-config-settings",
    "title": "Version control (Part 1)",
    "section": "git config settings",
    "text": "git config settings\nYou can check your settings at any time:\n$ git config --list\n\n\n\n\n\n\nGit Help and Manual\n\n\n\nIf you forget the options of a git command, you can type git &lt;command&gt; -h or access the corresponding Git manual by typing git &lt;command&gt; --help, e.g.:\n$ git config -h\n$ git config --help\nYou can press Q to exit the manual.\nYou can also get the list of available git commands and further resources of the Git manual typing:\n$ git help\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\nUse git config with the --global option to configure a user name, email address, editor, and other preferences once per machine.\n\n\n\nNote that we will omit the $ from shell commands shown from here onwards to make it easier to run them interactively in this tutorial."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#git-init",
    "href": "posts/2023-11-07-version-control-part-1/index.html#git-init",
    "title": "Version control (Part 1)",
    "section": "git init",
    "text": "git init\nOnce Git is configured, we can start using it.\nFirst, let’s create a new directory in the Desktop folder for our work and then change the current working directory to the newly created one:\ncd ~/Desktop\nmkdir planets\ncd planets\npwd\n/Users/stephaniehicks/Desktop/planets\nThen we tell Git to make planets a repository – a place where Git can store versions of our files:\ngit init\nNote that the creation of the planets directory and its initialization as a repository are completely separate processes.\nIf we use ls to show the directory’s contents, it appears that nothing has changed:\nls\nBut if we add the -a flag to show everything, we can see that Git has created a hidden directory within planets called .git:\nls -a\n.   ..  .git\nGit uses this special subdirectory to store all the information about the project, including the tracked files and sub-directories located within the project’s directory.\nIf we ever delete the .git subdirectory, we will lose the project’s history.\nNext, we will change the default branch to be called main. This might be the default branch depending on your settings and version of git.\ngit checkout -b main\nSwitched to a new branch 'main'"
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#git-status",
    "href": "posts/2023-11-07-version-control-part-1/index.html#git-status",
    "title": "Version control (Part 1)",
    "section": "git status",
    "text": "git status\nWe can check that everything is set up correctly by asking Git to tell us the status of our project:\ngit status\nOn branch main\n\nNo commits yet\n\nnothing to commit (create/copy files and use \"git add\" to track)\n\n\n\n\n\n\nCorrecting git init Mistakes\n\n\n\nSuppose you have created the Git repository in the wrong directory, or made some other mistake.\nYou can delete the git repository by simply deleting the .git directory, either in Finder / Windows Explorer or from the command line:\nrm -rf .git\nBut be careful! Running this command in the wrong directory will remove the entire Git history of a project you might want to keep. Therefore, always check your current directory using the command pwd.\n\n\n\n\n\n\n\n\nKey Points\n\n\n\n\ngit init initializes a repository.\nGit stores all of its repository data in the .git directory."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#git-add",
    "href": "posts/2023-11-07-version-control-part-1/index.html#git-add",
    "title": "Version control (Part 1)",
    "section": "git add",
    "text": "git add\nLet’s create a file called mars.txt that contains some notes about the Red Planet’s suitability as a base.\nWe will use touch to create the file, and then open it in TextEdit or Notepad. Alternatively, you can use a command-line text editor such as nano.\ntouch mars.txt\nNow, open the .txt file and type the text below into the mars.txt file:\nCold and dry, but everything is my favorite color\nLet’s first verify that the file was properly created by running the list command (ls):\nls\nmars.txt contains a single line, which we can see by running:\ncat mars.txt\nCold and dry, but everything is my favorite color\nIf we check the status of our project again, Git tells us that it’s noticed the new file:\ngit status\nOn branch main\n\nNo commits yet\n\nUntracked files:\n   (use \"git add &lt;file&gt;...\" to include in what will be committed)\n\n    mars.txt\n\nnothing added to commit but untracked files present (use \"git add\" to track)\nThe “untracked files” message means that there is a file in the directory that Git is not keeping track of. We can tell Git to track a file using git add:\ngit add mars.txt\nand then check that the right thing happened:\ngit status\nOn branch main\n\nNo commits yet\n\nChanges to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n\n    new file:   mars.txt"
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#git-commit",
    "href": "posts/2023-11-07-version-control-part-1/index.html#git-commit",
    "title": "Version control (Part 1)",
    "section": "git commit",
    "text": "git commit\nGit now knows that it is supposed to keep track of mars.txt, but it has not recorded these changes as a commit yet. To get it to do that, we need to run one more command:\ngit commit -m \"Start notes on Mars as a base\"\n[main (root-commit) ef11b6d] Start notes on Mars as a base\n 1 file changed, 1 insertion(+)\n create mode 100644 mars.txt\n\n\n\n\n\n\nNote\n\n\n\nWhen we run git commit,\n\nGit takes everything we have told it to save by using git add and stores a copy permanently inside the special .git directory.\nThis permanent copy is called a commit (or revision) and its short identifier is ef11b6d.\nYour commit may have another identifier.\n\n\n\n\n\n\n\n\n\ngit commit message\n\n\n\nWe use the -m flag (for “message”) to record a short, descriptive, and specific comment that will help us remember later on what we did and why.\nIf we just run git commit without the -m option, Git will launch nano (or whatever other editor is configured as core.editor) so that we can write a longer message.\n\n\nGood commit messages start with a brief (&lt;50 characters) statement about the changes made in the commit. Generally, the message should complete the sentence “If applied, this commit will”. If you want to go into more detail, add a blank line between the summary line and your additional notes. Use this additional space to explain why you made changes and/or what their impact will be.\nIf we run git status now:\ngit status\nOn branch main\nnothing to commit, working tree clean\nit tells us everything is up to date. If we want to know what we’ve done recently, we can ask Git to show us the project’s history using git log:\ngit log\ncommit ef11b6d0b1181bcf34bed85e7d60e663e8bbde93 (HEAD -&gt; main)\nAuthor: Stephanie Hicks &lt;stephaniechicks@gmail.com&gt;\nDate:   Sun Oct 29 22:12:47 2023 -0400\n\n    Start notes on Mars as a base\ngit log lists all commits made to a repository in reverse chronological order."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#adding-changes-to-a-file",
    "href": "posts/2023-11-07-version-control-part-1/index.html#adding-changes-to-a-file",
    "title": "Version control (Part 1)",
    "section": "Adding changes to a file",
    "text": "Adding changes to a file\nNow suppose we add more information to the file. (Again, we will edit with TextEdit / Notepad and then cat the file to show its contents.)\nPaste the following second line into the file:\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nWhen we run git status now, it tells us that a file it already knows about has been modified:\ngit status\nOn branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nThe last line is the key phrase: “no changes added to commit”. We have changed this file, but we have not told Git we will want to save those changes (which we do with git add) nor have we saved them (which we do with git commit).\nSo let’s do that now. It is good practice to always review our changes before saving them. We do this using git diff. This shows us the differences between the current state of the file and the most recently saved version:\ngit diff\ndiff --git a/mars.txt b/mars.txt\nindex bd9fd42..6967aea 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1 +1,2 @@\n Cold and dry, but everything is my favorite color\n+The two moons may be a problem for Wolfman\nThe output is cryptic because it is actually a series of commands for tools like editors and patch telling them how to reconstruct one file given the other.\nAfter reviewing our change, it’s time to commit it:\ngit commit -m \"Add concerns about effects of Mars' moons on Wolfman\"\nOn branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nWhoops: Git will no commit because we did not use git add first. Let’s fix that:\ngit add mars.txt\ngit commit -m \"Add concerns about effects of Mars' moons on Wolfman\"\n[main 5635827] Add concerns about effects of Mars' moons on Wolfman\n 1 file changed, 1 insertion(+)"
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#staging-area",
    "href": "posts/2023-11-07-version-control-part-1/index.html#staging-area",
    "title": "Version control (Part 1)",
    "section": "Staging area",
    "text": "Staging area\nGit insists that we add files to the set we want to commit before actually committing anything. This allows us to commit our changes in stages and capture changes in logical portions rather than only large batches.\nTo allow for this, Git has a special staging area where it keeps track of things that have been added but not yet committed.\n\n\n\n\n\n\nStaging Area\n\n\n\nIf you think of Git as taking snapshots of changes over the life of a project, git add specifies what will go in a snapshot (putting things in the staging area), and git commit then actually takes the snapshot, and makes a permanent record of it (as a commit).\nIf you do not have anything staged when you type git commit, Git will prompt you to use git commit -a or git commit --all, which will add all files. However, it’s almost always better to explicitly add things to the staging area, because you might commit changes you forgot you made.\nTry to stage things manually, or you might find yourself searching for “git undo commit” more than you would like!\n\n\nLet’s watch as our changes to a file move from our editor to the staging area and into long-term storage. First, we’ll add another line to the file:\ncat mars.txt\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\ngit diff\ndiff --git a/mars.txt b/mars.txt\nindex 6967aea..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,2 +1,3 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\nSo far, so good: we’ve added one line to the end of the file (shown with a + in the first column). Now let’s put that change in the staging area and see what git diff reports:\ngit add mars.txt\ngit diff\nThere is no output: as far as Git can tell, there’s no difference between what it’s been asked to save permanently and what’s currently in the directory. However, if we do this:\ngit diff --staged\ndiff --git a/mars.txt b/mars.txt\nindex 6967aea..b36abfd 100644\n--- a/mars.txt\n+++ b/mars.txt\n@@ -1,2 +1,3 @@\n Cold and dry, but everything is my favorite color\n The two moons may be a problem for Wolfman\n+But the Mummy will appreciate the lack of humidity\nit shows us the difference between the last committed change and what’s in the staging area. Let’s save our changes:\ngit commit -m \"Discuss concerns about Mars' climate for Mummy\"\n[main e86c8f6] Discuss concerns about Mars' climate for Mummy\n 1 file changed, 1 insertion(+)\ncheck our status:\ngit status\nOn branch main\nnothing to commit, working tree clean\nand look at the history of what we’ve done so far:\ngit log\ncommit e86c8f6fdb53a390a5dfea6f9f9052f05fd35baa (HEAD -&gt; main)\nAuthor: Stephanie Hicks &lt;stephaniechicks@gmail.com&gt;\nDate:   Sun Oct 29 23:27:34 2023 -0400\n\n    Discuss concerns about Mars' climate for Mummy\n\ncommit 563582798a711c58c0f23555c452685c71fd4c4e\nAuthor: Stephanie Hicks &lt;stephaniechicks@gmail.com&gt;\nDate:   Sun Oct 29 23:23:16 2023 -0400\n\n    Add concerns about effects of Mars' moons on Wolfman\n\ncommit ef11b6d0b1181bcf34bed85e7d60e663e8bbde93\nAuthor: Stephanie Hicks &lt;stephaniechicks@gmail.com&gt;\nDate:   Sun Oct 29 23:12:47 2023 -0400\n\n    Start notes on Mars as a base\n\n\n\n\n\n\nWord-based diffing\n\n\n\nSometimes, e.g. in the case of the text documents a line-wise diff is too coarse. That is where the --color-words option of git diff comes in very useful as it highlights the changed words using colors.\n\n\n\n\n\n\n\n\nPaging the Log\n\n\n\nIf the output of git log is too long to fit in your screen, Git splits it into pages.\nTo get out of the pager, press Q.\nTo move to the next page, press Spacebar."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#directories",
    "href": "posts/2023-11-07-version-control-part-1/index.html#directories",
    "title": "Version control (Part 1)",
    "section": "Directories",
    "text": "Directories\nTwo important facts you should know about directories in Git.\nFirst, Git does not track directories on their own, only files within them. Try it for yourself:\nmkdir spaceships\ngit status\ngit add spaceships\ngit status\nOn branch main\nnothing to commit, working tree clean\nNote, our newly created empty directory spaceships does not appear in the list of untracked files even if we explicitly add it (via git add) to our repository.\nSecond, if you create a directory in your Git repository and populate it with files, you can add all files in the directory at once by:\ngit add &lt;directory-with-files&gt;\nTry it for yourself:\ntouch spaceships/apollo-11 spaceships/sputnik-1\ngit status\ngit add spaceships\ngit status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        new file:   spaceships/apollo-11\n        new file:   spaceships/sputnik-1\nBefore moving on, we will commit these changes.\ngit commit -m \"Add some initial thoughts on spaceships\"\n[main ac23fe8] Add some initial thoughts on spaceships\n 2 files changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 spaceships/apollo-11\n create mode 100644 spaceships/sputnik-1\nTo recap, when we want to add changes to our repository, we first need to add the changed files to the staging area (git add) and then commit the staged changes to the repository (git commit).\nFor a visualization of this workflow, see the Software Carpentry: Version Control with Git page."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#exercises",
    "href": "posts/2023-11-07-version-control-part-1/index.html#exercises",
    "title": "Version control (Part 1)",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nChoosing a Commit Message\n\n\n\nWhich of the following commit messages would be most appropriate for the last commit made to mars.txt?\n\n“Changes”\n“Added line ‘But the Mummy will appreciate the lack of humidity’ to mars.txt”\n“Discuss effects of Mars’ climate on the Mummy”\n\n\n\n\n\n\n\n\n\nCommitting Changes to Git\n\n\n\nWhich command(s) below would save the changes of myfile.txt to my local Git repository?\ngit commit -m \"my recent changes\"\ngit init myfile.txt\ngit commit -m \"my recent changes\"\ngit add myfile.txt\ngit commit -m \"my recent changes\"\ngit commit -m myfile.txt \"my recent changes\"\n\n\nAdditional exercises are available on the Software Carpentry: Version Control with Git page.\n\n\n\n\n\n\nKey Points\n\n\n\n\ngit status shows the status of a repository.\nFiles can be stored in a project’s working directory (which users see), the staging area (where the next commit is being built up) and the local repository (where commits are permanently recorded).\ngit add puts files in the staging area.\ngit commit saves the staged content as a new commit in the local repository.\nWrite a commit message that accurately describes your changes."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#restoring-older-versions",
    "href": "posts/2023-11-07-version-control-part-1/index.html#restoring-older-versions",
    "title": "Version control (Part 1)",
    "section": "Restoring older versions",
    "text": "Restoring older versions\nAll right! So we can save changes to files and see what we’ve changed.\nNow, how can we restore older versions of things? Let’s suppose we change our mind about the last update to mars.txt.\ngit status now tells us that the file has been changed, but those changes have not been staged:\ngit status\nOn branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\n\n    modified:   mars.txt\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\nWe can put things back the way they were by using git checkout:\ngit checkout HEAD mars.txt\ncat mars.txt\nCold and dry, but everything is my favorite color\nThe two moons may be a problem for Wolfman\nBut the Mummy will appreciate the lack of humidity\nAs you might guess from its name, git checkout checks out (i.e., restores) an old version of a file. In this case, we are telling Git that we want to recover the version of the file recorded in HEAD, which is the last saved commit.\nIf we want to go back even further, we can use a commit identifier instead:\ngit checkout ef11b6d mars.txt\nUpdated 1 path from 3e62de1\ncat mars.txt\nCold and dry, but everything is my favorite color\ngit status\nOn branch main\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n        modified:   mars.txt\nNotice that the changes are currently in the staging area. Again, we can put things back the way they were by using git checkout:\ngit checkout HEAD mars.txt\nUpdated 1 path from aab57ac\n\n\n\n\n\n\nDon’t Lose Your HEAD\n\n\n\nAbove we used\ngit checkout ef11b6d mars.txt\nto revert mars.txt to its state after the commit ef11b6d.\nBut be careful! The command checkout has other important functionalities and Git will misunderstand your intentions if you are not accurate with the typing.\nFor example, if you forget mars.txt in the previous command.\ngit checkout ef11b6d\nNote: switching to 'ef11b6d'.\n\nYou are in 'detached HEAD' state. You can look around, make experimental\nchanges and commit them, and you can discard any commits you make in this\nstate without impacting any branches by switching back to a branch.\n\nIf you want to create a new branch to retain commits you create, you may\ndo so (now or later) by using -c with the switch command. Example:\n\n  git switch -c &lt;new-branch-name&gt;\n\nOr undo this operation with:\n\n  git switch -\n\nTurn off this advice by setting config variable advice.detachedHead to false\n\nHEAD is now at ef11b6d Start notes on Mars as a base\nThe “detached HEAD” state lets you look around without the repository without making any changes, so you shouldn’t make any changes in this state. After investigating your repository’s past state, reattach your HEAD with git checkout main.\ngit checkout main\nPrevious HEAD position was ef11b6d Start notes on Mars as a base\nSwitched to branch 'main'\n\n\n\n\n\n\n\n\nSequence of commits\n\n\n\nIt’s important to remember that we must use the commit number that identifies the state of the repository before the change we’re trying to undo. A common mistake is to use the number of the commit in which we made the change we’re trying to discard.\n\n\nFor some additional visualizations, see the Software Carpentry: Version Control with Git page.\n\n\n\n\n\n\nSimplifying the Common Case\n\n\n\nIf you read the output of git status carefully, you will see that it includes this hint:\n(use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)\nAs it says, git checkout without a version identifier restores files to the state saved in HEAD. The double dash -- is needed to separate the names of the files being recovered from the command itself: without it, Git would try to use the name of the file as the commit identifier.\n\n\nThe fact that files can be reverted one by one tends to change the way people organize their work. If everything is in one large document, it is hard (but not impossible) to undo changes to the introduction without also undoing changes made later to the conclusion. If the introduction and conclusion are stored in separate files, on the other hand, moving backward and forward in time becomes much easier."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#exercises-1",
    "href": "posts/2023-11-07-version-control-part-1/index.html#exercises-1",
    "title": "Version control (Part 1)",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nRecovering Older Versions of a File\n\n\n\nJennifer has made changes to the R script that she has been working on for weeks, and the modifications she made this morning “broke” the script and it no longer runs. She has spent ~ 1hr trying to fix it, with no luck…\nLuckily, she has been keeping track of her project’s versions using Git! Which commands below will let her recover the last committed version of her R script called data_cruncher.R?\n\ngit checkout HEAD\ngit checkout HEAD data_cruncher.R\ngit checkout HEAD~1 data_cruncher.R\ngit checkout &lt;unique ID of last commit&gt; data_cruncher.R\nBoth 2 and 4\n\n\n\n\n\n\n\n\n\nReverting a Commit\n\n\n\nJennifer is collaborating with colleagues on her R script. She realizes her last commit to the project’s repository contained an error, and wants to undo it. Jennifer wants to undo correctly so everyone in the project’s repository gets the correct change. The command git revert [erroneous commit ID] will create a new commit that reverses the erroneous commit.\nThe command git revert is different from git checkout [commit ID] because git checkout returns the files not yet committed within the local repository to a previous state, whereas git revert reverses changes committed to the local and project repositories.\nBelow are the right steps and explanations for Jennifer to use git revert, what is the missing command?\n\n________ # Look at the git history of the project to find the commit ID\nCopy the ID (the first few characters of the ID, e.g. 0b1d055).\ngit revert [commit ID]\nType in the new commit message.\nSave and close\n\n\n\n\n\n\n\n\n\nChecking Understanding of git diff\n\n\n\nConsider this command: git diff HEAD~9 mars.txt. What do you predict this command will do if you execute it? What happens when you do execute it? Why?\nTry another command, git diff [ID] mars.txt, where [ID] is replaced with the unique identifier for your most recent commit. What do you think will happen, and what does happen?\n\n\nAdditional exercises are available on the Software Carpentry: Version Control with Git page.\n\n\n\n\n\n\nKey Points\n\n\n\n\ngit diff displays differences between commits.\ngit checkout recovers old versions of files."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#exercises-2",
    "href": "posts/2023-11-07-version-control-part-1/index.html#exercises-2",
    "title": "Version control (Part 1)",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nIgnoring Nested Files\n\n\n\nGiven a directory structure that looks like:\nresults/data\nresults/plots\nHow would you ignore only results/plots and not results/data?\n\n\n\n\n\n\n\n\nIncluding Specific Files\n\n\n\nHow would you ignore all .dat files in your root directory except for final.dat?\nHint: Find out what ! (the exclamation point operator) does.\nThe exclamation point operator will include a previously excluded entry.\n\n\n\n\n\n\n\n\nIgnoring all data Files in a Directory\n\n\n\nAssuming you have an empty .gitignore file, and given a directory structure that looks like:\nresults/data/position/gps/a.dat\nresults/data/position/gps/b.dat\nresults/data/position/gps/c.dat\nresults/data/position/gps/info.txt\nresults/plots\nWhat’s the shortest .gitignore rule you could write to ignore all .dat files in result/data/position/gps? Do not ignore the info.txt.\n\n\n\n\n\n\n\n\nIgnoring all data Files in the repository\n\n\n\nLet us assume you have many .dat files in different subdirectories of your repository. For example, you might have:\nresults/a.dat\ndata/experiment_1/b.dat\ndata/experiment_2/c.dat\ndata/experiment_2/variation_1/d.dat\nHow do you ignore all the .dat files, without explicitly listing the names of the corresponding folders?\n\n\nAdditional exercises are available on the Software Carpentry: Version Control with Git page.\n\n\n\n\n\n\nKey Points\n\n\n\n\nThe .gitignore file tells Git what files to ignore."
  },
  {
    "objectID": "posts/2023-11-07-version-control-part-1/index.html#preparation-for-next-lesson",
    "href": "posts/2023-11-07-version-control-part-1/index.html#preparation-for-next-lesson",
    "title": "Version control (Part 1)",
    "section": "Preparation for next lesson",
    "text": "Preparation for next lesson\nIn the next lesson, we will learn how to use git remotes and GitHub. As preparation, you can sign up for a GitHub account if you do not already have one."
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html",
    "href": "posts/2023-10-31-command-line-part-1/index.html",
    "title": "Introduction to the command-line",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nSoftware Carpentry: The Unix Shell\nR Squared Academy\n\n\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nR Squared Academy\nSoftware Carpentry: The Unix Shell\nData Science at the Command line"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#the-shell",
    "href": "posts/2023-10-31-command-line-part-1/index.html#the-shell",
    "title": "Introduction to the command-line",
    "section": "The Shell",
    "text": "The Shell\nThe shell is a program (or environment) where users can type commands and the commands can be executed.\nAnother way of thinking about it is, a shell provides an interface between the user and the UNIX system.\n\n\n\n\n\n\nExample types of shells\n\n\n\n\nBash (Bourne Again SHell). The most popular Unix shell is Bash (the Bourne Again SHell — so-called because it’s derived from a shell written by Stephen Bourne). Bash is the default shell on most modern implementations of Unix and in most packages that provide Unix-like tools for Windows.\nZsh (Z SHell). Zsh is built on top of bash with some additional features including providing the user with more flexibility by providing various features such as plug-in support, better customization, theme support, spelling correction, etc. Zsh is the default shell for macOS and Kali Linux.\n\n\n\nThe grammar of a shell allows you to combine existing tools into powerful pipelines and handle large volumes of data automatically.\nBenefits:\n\nSequences of commands can be written into a script, improving the reproducibility of workflows.\nThe command line is often the easiest way to interact with remote machines and supercomputers.\nFamiliarity with the shell is near essential to run a variety of specialized tools and resources including high-performance computing systems.\n\nLet’s get started."
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#where-to-find-the-shell",
    "href": "posts/2023-10-31-command-line-part-1/index.html#where-to-find-the-shell",
    "title": "Introduction to the command-line",
    "section": "Where to find the shell",
    "text": "Where to find the shell\n\nIf you are using Windows, by default, Windows does not use bash, but instead you will need to install one of several Windows-specific tools (like Git for Windows or PowerShell) to allow this kind of text-based interaction with your operating system.\nIf you are using macOS, Apple calls the shell ‘Terminal’. There is an application you can open called ‘Terminal’ and it also appears in a tab next to the R console in the RStudio IDE.\n\n\n[Source]\n\n\n\n\n\n\nDemo\n\n\n\n\nLet’s open up the Terminal application and also show you where the Terminal is within RStudio.\nNext, let’s show how to open up multiple terminals and close all terminals.\n\n\n\n\n\n\n\n\n\nThe Unix shell setup\n\n\n\nYou can follow these directions for setting up your shell for Windows, macOS, and Linux operating systems:\n\nhttps://swcarpentry.github.io/shell-novice/index.html"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#opening-the-shell",
    "href": "posts/2023-10-31-command-line-part-1/index.html#opening-the-shell",
    "title": "Introduction to the command-line",
    "section": "Opening the shell",
    "text": "Opening the shell\nWhen the shell is first opened, you are presented with a prompt, indicating that the shell is waiting for input.\n\n\nBash\n\n$\n\n\n\nZsh\n\n%\n\nThe shell typically uses $ as the prompt, but may use a different symbol (for the purposes of the rest of the lecture, I will omit the $).\n\n\n\n\n\n\nImportant\n\n\n\n\nWhen typing commands in the shell, do not type the $, only the commands that follow it.\nAfter you type a command, you have to press the Enter key to execute it.\n\n\n\nThe prompt is followed by a text cursor, a character that indicates the position where your typing will appear."
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#shell-basics",
    "href": "posts/2023-10-31-command-line-part-1/index.html#shell-basics",
    "title": "Introduction to the command-line",
    "section": "Shell basics",
    "text": "Shell basics\nSo let’s try our first command, ls which is short for listing files. With R, we know how to do this with list.files() function in base R:\n\n```{r}\nlist.files()\n```\n\n [1] \"analysis.R\"           \"combined_names.txt\"   \"index.qmd\"           \n [4] \"index.rmarkdown\"      \"package_names.txt\"    \"r_release.txt\"       \n [7] \"release_names.txt\"    \"secret_directory\"     \"soccer_directory\"    \n[10] \"team_standings_3.csv\" \"team_standings.csv\"  \n\n\nThis command will list the contents of the current directory where the lecture is located. In RStudio, we can write a bash code block like this:\n```{bash}\nls\n```\nand the executed code block is this:\n\nls\n\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_directory\nsoccer_directory\nteam_standings.csv\nteam_standings_3.csv\n\n\n\n\n\n\n\n\nNote\n\n\n\nIf the shell can’t find a program whose name is the command you typed, it will print an error message such as:\n\nks\n\nError in running command bash\n\n\nThis might happen if the command was mis-typed or if the program corresponding to that command is not installed.\n\n\nNext, lets learn to display\n\nbasic information about the user\nthe current date & time\nthe calendar\nand clear the screen\n\n\n\n\n\n\n\n\n\nCommand\nDescription\nR command\n\n\n\n\nwhoami\nWho is the user?\nSys.info() / whoami::whoami()\n\n\ndate\nGet date, time and timezone\nSys.time()\n\n\ncal\nDisplay calendar\n\n\n\nclear\nClear the screen\nCtrl + L\n\n\n\nwhoami prints the user id (i.e. the name of the user who runs the command). Use it to verify the user as which you are logged into the system.\n\nwhoami\n\nstephaniehicks\n\n\ndate will display or change the value of the system’s time and date information.\n\ndate\n\nTue Oct 31 12:48:54 EDT 2023\n\n\ncal will display a formatted calendar and clear will clear all text on the screen and display a new prompt.\n\ncal\n\n    October 2023      \nSu Mo Tu We Th Fr Sa  \n 1  2  3  4  5  6  7  \n 8  9 10 11 12 13 14  \n15 16 17 18 19 20 21  \n22 23 24 25 26 27 28  \n29 30 _\b3_\b1              \n                      \n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nTo clear the R console and the shell, we use Ctrl + L."
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#getting-help",
    "href": "posts/2023-10-31-command-line-part-1/index.html#getting-help",
    "title": "Introduction to the command-line",
    "section": "Getting help",
    "text": "Getting help\nBefore we proceed further, let us learn to view the documentation/manual pages of the commands.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nnameofcommand -h\nFor some nameofcommand command (only for some commands)\n\n\nman nameofcommand\nDisplay manual pages (i.e. man) for the nameofcommand command\n\n\nwhatis\nSingle line description of a command\n\n\n\nman is used to view the system’s reference manual.\nman date \nDATE(1)                          General Commands Manual                          DATE(1)\n\nNAME\n     date – display or set date and time\n\nSYNOPSIS\n     date [-jnRu] [-r seconds | filename] [-v [+|-]val[ymwdHMS]] ... [+output_fmt]\n     date [-ju] [[[mm]dd]HH]MM[[cc]yy][.ss]\n     date [-jRu] -f input_fmt new_date [+output_fmt]\n     date [-jnu] [-I[FMT]] [-f input_fmt] [-r ...] [-v ...] [new_date]\n\nDESCRIPTION\n     When invoked without arguments, the date utility displays the current date and time.\n\n\n\n\n\n\nTry it out\n\n\n\nLet’s explore the manual pages of date in the command line to show you what that looks like.\n\nWe will figure out what is the argument to print the date since the Unix epoch or 00:00:00 UTC on 1 January 1970 as a function of the number of seconds.\nWe will figure out what is the argument to display the date in UTC.\n\n\n## try it out \n\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nFor most commands (but not all!), NAMEOFCOMMAND -h or NAMEOFCOMMAND --help will bring up a small guide to command options.\nFor example, python -h or python --help bring up:\nusage: python [option] ... [-c cmd | -m mod | file | -] [arg] ...\nOptions and arguments (and corresponding environment variables):\n-b     : issue warnings about str(bytes_instance), str(bytearray_instance)\n         and comparing bytes/bytearray with str. (-bb: issue errors)\n-B     : don't write .pyc files on import; also PYTHONDONTWRITEBYTECODE=x\n-c cmd : program passed in as string (terminates option list)\n-d     : turn on parser debugging output (for experts only, only works on\n         debug builds); also PYTHONDEBUG=x\n-E     : ignore PYTHON* environment variables (such as PYTHONPATH)\n-h     : print this help message and exit (also --help)\n-i     : inspect interactively after running script; forces a prompt even\n         if stdin does not appear to be a terminal; also PYTHONINSPECT=x"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#navigate-the-file-system",
    "href": "posts/2023-10-31-command-line-part-1/index.html#navigate-the-file-system",
    "title": "Introduction to the command-line",
    "section": "Navigate the file system",
    "text": "Navigate the file system\nNext, we will introduce commands that help us:\n\nnavigate between different folders/directories\nreturn current working directory\nlist all the files & folders in a directory\ncreate and delete directories\n\n\n\n\n\n\n\n\n\nCommand\nDescription\nR commands\n\n\n\n\npwd\nPrint working directory\nhere::here()\n\n\nls\nList directory contents\ndir() / list.files() / list.dirs()\n\n\ncd\nChange current working directory\nsetwd()\n\n\nmkdir\nCreate directory\ndir.create()\n\n\nrmdir\nRemove/delete directory\n\n\n\n\npwd displays the name and path of the present (or current) working directory (pwd).\n\npwd\n\n/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/posts/2023-10-31-command-line-part-1\n\n\nls displays information about files and directories in the current directory along with their associated metadata such as\n\nsize\nownership\nmodification date\n\nWith no options, it will list the files and directories in the current directory, sorted alphabetically.\n\nls\n\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_directory\nsoccer_directory\nteam_standings.csv\nteam_standings_3.csv\n\n\ncd (change directory) changes the current working directory. It is among the most used commands as it allows the user to move around the file system.\n\ncd .. \nls\n\n2023-10-26-build-website\n2023-10-31-command-line-part-1\n2023-11-02-command-line-part-2\n2023-11-07-version-control-part-1\n2023-11-09-version-control-part-2\n2023-11-14-oop-part-1\n2023-11-16-oop-part-2\n2023-11-28-purrr-fun-programming\n2023-11-30-pkgdown-pkg-website\n2023-11-30-targets-proj-workflows\n2023-12-05-gettingdata-api\n2023-12-07-relational-databases\n_metadata.yml\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe cd .. means to change to the directory that is one level up.\n\n\nmkdir will create new directory.\nIt will allow you to set file mode (permissions associated with the directory) i.e. who can open/modify/delete the directory.\nIt will give you a warning if a folder already exists.\n\nmkdir secret_directory\nls\n\nmkdir: secret_directory: File exists\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_directory\nsoccer_directory\nteam_standings.csv\nteam_standings_3.csv\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nPressing tab at any time within the shell will prompt it to attempt to either\n\nauto-complete the name of the command you are searching for\nauto-complete the line based on the files or sub-directories in the current directory.\n\nWhere two or more files have the same characters, the auto-complete will only fill up to the first point of difference, after which we can add more characters, and try using tab again.\n\n\nrmdir will remove empty directories from the file system. It can be used to remove multiple empty directories as well.\nIf the directory is not empty, rmdir will not remove it and instead display a warning that the directory is not empty.\n\nrmdir secret_directory\nls\n\nrmdir: secret_directory: Directory not empty\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_directory\nsoccer_directory\nteam_standings.csv\nteam_standings_3.csv"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#change-working-directory",
    "href": "posts/2023-10-31-command-line-part-1/index.html#change-working-directory",
    "title": "Introduction to the command-line",
    "section": "Change working directory",
    "text": "Change working directory\nLet us focus a bit more on changing working directory. The below table shows commands for changing working directory to\n\nup one level\nprevious working directory\nhome directory\nand root directory\n\n\n\n\nCommand\nDescription\n\n\n\n\ncd .\nNavigate into directory\n\n\ncd ..\nGo up one level\n\n\ncd -\nGo to previous working directory\n\n\ncd ~\nChange directory to home directory\n\n\ncd /\nChange directory to root directory\n\n\n\n\ncd ..\nls \n\n2023-10-26-build-website\n2023-10-31-command-line-part-1\n2023-11-02-command-line-part-2\n2023-11-07-version-control-part-1\n2023-11-09-version-control-part-2\n2023-11-14-oop-part-1\n2023-11-16-oop-part-2\n2023-11-28-purrr-fun-programming\n2023-11-30-pkgdown-pkg-website\n2023-11-30-targets-proj-workflows\n2023-12-05-gettingdata-api\n2023-12-07-relational-databases\n_metadata.yml\n\n\nThis is a list of top-level files in my folder containing all the files for this website.\n\ncd ../..\nls\n\nREADME.md\n_freeze\n_post_template.qmd\n_quarto.yml\n_site\ndata\nimages\nindex.qmd\njhustatprogramming2023.Rproj\nlectures.qmd\nposts\nprofile.jpg\nprojects\nprojects.qmd\nresources.qmd\nschedule.qmd\nstyles.css\nsyllabus.qmd\n\n\nThese are all the files in my home directory on my computer.\n\ncd ~ \nls \n\nApplications\nCreative Cloud Files\nDesktop\nDocuments\nDownloads\nDropbox\nLibrary\nMovies\nMusic\nPictures\nPublic\nR\nZotero\nminiforge3"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#list-directory-contents",
    "href": "posts/2023-10-31-command-line-part-1/index.html#list-directory-contents",
    "title": "Introduction to the command-line",
    "section": "List directory contents",
    "text": "List directory contents\nls will list the contents of a directory. Using different arguments, we can\n\nlist hidden files\nview file permissions, ownership, size & modification date\nsort by size & modification date\n\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nls\nList directory contents\n\n\nls -l\nList files one per line\n\n\nls -a\nList all files including hidden files\n\n\nls -la\nDisplay file permissions, ownership, size & modification date\n\n\nls -lh\nLong format list with size displayed in human readable format\n\n\nls -lS\nLong format list sorted by size\n\n\nls -ltr\nLong format list sorted by modification date\n\n\n\nList files one per line\n\ncd ../..\nls -l\n\ntotal 240\n-rw-r--r--@  1 stephaniehicks  staff    354 Oct 24 18:03 README.md\ndrwxr-xr-x   7 stephaniehicks  staff    224 Oct 24 18:30 _freeze\n-rw-r--r--   1 stephaniehicks  staff    976 Aug 14 21:48 _post_template.qmd\n-rw-r--r--   1 stephaniehicks  staff    901 Aug 14 21:48 _quarto.yml\ndrwxr-xr-x  15 stephaniehicks  staff    480 Oct 31 12:48 _site\ndrwxr-xr-x   8 stephaniehicks  staff    256 Aug 14 21:48 data\ndrwxr-xr-x  17 stephaniehicks  staff    544 Oct 29 23:54 images\n-rw-r--r--   1 stephaniehicks  staff   2200 Aug 14 21:48 index.qmd\n-rw-r--r--@  1 stephaniehicks  staff    205 Oct 31 12:35 jhustatprogramming2023.Rproj\n-rw-r--r--   1 stephaniehicks  staff    189 Aug 14 21:48 lectures.qmd\ndrwxr-xr-x  15 stephaniehicks  staff    480 Oct 30 00:20 posts\n-rw-r--r--   1 stephaniehicks  staff  60521 Aug 14 21:48 profile.jpg\ndrwxr-xr-x   3 stephaniehicks  staff     96 Sep  6 13:09 projects\n-rw-r--r--   1 stephaniehicks  staff    191 Aug 14 21:48 projects.qmd\n-rw-r--r--   1 stephaniehicks  staff    501 Aug 14 21:48 resources.qmd\n-rw-r--r--@  1 stephaniehicks  staff   3591 Oct 30 00:12 schedule.qmd\n-rw-r--r--   1 stephaniehicks  staff     17 Aug 14 21:48 styles.css\n-rw-r--r--@  1 stephaniehicks  staff  18899 Oct 30 01:38 syllabus.qmd\n\n\n\nHidden files\nNext, let’s talk about hidden (or invisible) files. These are everywhere on modern operating systems.\nWhen a programmer needs to have a file or folder, but does not want to show it to the user, they prefixes the file name with a single period (.). The operating system then hides this files from the user.\nBut now you can see these invisible files using the command line. Just use the -a flag (short for “all”) for the ls command to have it show you all the files that are there:\n\ncd ../..\nls -a\n\n.\n..\n.Rproj.user\n.git\n.github\n.gitignore\n.quarto\nREADME.md\n_freeze\n_post_template.qmd\n_quarto.yml\n_site\ndata\nimages\nindex.qmd\njhustatprogramming2023.Rproj\nlectures.qmd\nposts\nprofile.jpg\nprojects\nprojects.qmd\nresources.qmd\nschedule.qmd\nstyles.css\nsyllabus.qmd\n\n\nYes, we have lots of hidden files and folders in our course repository: .git, .github, .gitignore, .quarto, etc.\nThese are normal files — you can move them, rename them, or open them like any other — they are just hidden by default.\nNext, we can display file permissions, ownership, size & modification date\n\ncd ../..\nls -la\n\ntotal 248\ndrwxr-xr-x@ 25 stephaniehicks  staff    800 Oct 31 12:48 .\ndrwxr-xr-x@ 16 stephaniehicks  staff    512 Aug 14 13:25 ..\ndrwxr-xr-x   4 stephaniehicks  staff    128 Aug  9  2022 .Rproj.user\ndrwxr-xr-x  14 stephaniehicks  staff    448 Oct 31 12:48 .git\ndrwxr-xr-x   3 stephaniehicks  staff     96 Aug 14 21:48 .github\n-rw-r--r--   1 stephaniehicks  staff     99 Aug 14 21:48 .gitignore\ndrwxr-xr-x   8 stephaniehicks  staff    256 Oct 31 12:47 .quarto\n-rw-r--r--@  1 stephaniehicks  staff    354 Oct 24 18:03 README.md\ndrwxr-xr-x   7 stephaniehicks  staff    224 Oct 24 18:30 _freeze\n-rw-r--r--   1 stephaniehicks  staff    976 Aug 14 21:48 _post_template.qmd\n-rw-r--r--   1 stephaniehicks  staff    901 Aug 14 21:48 _quarto.yml\ndrwxr-xr-x  15 stephaniehicks  staff    480 Oct 31 12:48 _site\ndrwxr-xr-x   8 stephaniehicks  staff    256 Aug 14 21:48 data\ndrwxr-xr-x  17 stephaniehicks  staff    544 Oct 29 23:54 images\n-rw-r--r--   1 stephaniehicks  staff   2200 Aug 14 21:48 index.qmd\n-rw-r--r--@  1 stephaniehicks  staff    205 Oct 31 12:35 jhustatprogramming2023.Rproj\n-rw-r--r--   1 stephaniehicks  staff    189 Aug 14 21:48 lectures.qmd\ndrwxr-xr-x  15 stephaniehicks  staff    480 Oct 30 00:20 posts\n-rw-r--r--   1 stephaniehicks  staff  60521 Aug 14 21:48 profile.jpg\ndrwxr-xr-x   3 stephaniehicks  staff     96 Sep  6 13:09 projects\n-rw-r--r--   1 stephaniehicks  staff    191 Aug 14 21:48 projects.qmd\n-rw-r--r--   1 stephaniehicks  staff    501 Aug 14 21:48 resources.qmd\n-rw-r--r--@  1 stephaniehicks  staff   3591 Oct 30 00:12 schedule.qmd\n-rw-r--r--   1 stephaniehicks  staff     17 Aug 14 21:48 styles.css\n-rw-r--r--@  1 stephaniehicks  staff  18899 Oct 30 01:38 syllabus.qmd\n\n\nDisplay size in human readable format\n\ncd ../..\nls -lh\n\ntotal 240\n-rw-r--r--@  1 stephaniehicks  staff   354B Oct 24 18:03 README.md\ndrwxr-xr-x   7 stephaniehicks  staff   224B Oct 24 18:30 _freeze\n-rw-r--r--   1 stephaniehicks  staff   976B Aug 14 21:48 _post_template.qmd\n-rw-r--r--   1 stephaniehicks  staff   901B Aug 14 21:48 _quarto.yml\ndrwxr-xr-x  15 stephaniehicks  staff   480B Oct 31 12:48 _site\ndrwxr-xr-x   8 stephaniehicks  staff   256B Aug 14 21:48 data\ndrwxr-xr-x  17 stephaniehicks  staff   544B Oct 29 23:54 images\n-rw-r--r--   1 stephaniehicks  staff   2.1K Aug 14 21:48 index.qmd\n-rw-r--r--@  1 stephaniehicks  staff   205B Oct 31 12:35 jhustatprogramming2023.Rproj\n-rw-r--r--   1 stephaniehicks  staff   189B Aug 14 21:48 lectures.qmd\ndrwxr-xr-x  15 stephaniehicks  staff   480B Oct 30 00:20 posts\n-rw-r--r--   1 stephaniehicks  staff    59K Aug 14 21:48 profile.jpg\ndrwxr-xr-x   3 stephaniehicks  staff    96B Sep  6 13:09 projects\n-rw-r--r--   1 stephaniehicks  staff   191B Aug 14 21:48 projects.qmd\n-rw-r--r--   1 stephaniehicks  staff   501B Aug 14 21:48 resources.qmd\n-rw-r--r--@  1 stephaniehicks  staff   3.5K Oct 30 00:12 schedule.qmd\n-rw-r--r--   1 stephaniehicks  staff    17B Aug 14 21:48 styles.css\n-rw-r--r--@  1 stephaniehicks  staff    18K Oct 30 01:38 syllabus.qmd\n\n\n\n\nWildcards\nWildcards are the use of asterisk (*) to allow any pattern to appear in part of a filename.\nFor example, to list all the .txt files in a folder (but only the .txt files), you can type:\n\nls *.txt\n\ncombined_names.txt\npackage_names.txt\nr_release.txt\nrelease_names.txt\n\n\nOr if you wanted to see any file in the directory that has a “r” in it\n\nls *r*\n\nindex.rmarkdown\nr_release.txt\nrelease_names.txt\n\nsecret_directory:\nteam_standings.csv\n\nsoccer_directory:\nteam_standings.csv\n\n\nThis is an extremely powerful tool, and one you will likely use a lot.\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s try to write the command to pattern match all files that start with the pattern “team”\n\n### try it out"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#create-new-file",
    "href": "posts/2023-10-31-command-line-part-1/index.html#create-new-file",
    "title": "Introduction to the command-line",
    "section": "Create new file",
    "text": "Create new file\ntouch modifies file timestamps which is information associated with file modification. It can be any of the following:\n\naccess time (the last time the file was read)\nmodification time (the last time the contents of the file was changed)\nchange time (the last time the file’s metadata was changed)\n\nIf the file does not exist, it will create an empty file of the same name.\n\n\n\n\n\n\nExample\n\n\n\nLet us use touch to create a new file secret_analysis.R.\n\ntouch secret_analysis.R\nls\n\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_analysis.R\nsecret_directory\nsoccer_directory\nteam_standings.csv\nteam_standings_3.csv"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#copy-files-and-folders",
    "href": "posts/2023-10-31-command-line-part-1/index.html#copy-files-and-folders",
    "title": "Introduction to the command-line",
    "section": "Copy files and folders",
    "text": "Copy files and folders\ncp makes copies of files and directories.\n\n\n\n\n\n\nNote\n\n\n\nBy default, it will overwrite files without prompting for confirmation so be cautious while copying files or folders.\n\n\n\n\n\n\n\n\nExample\n\n\n\nLet us create a copy of team_standings.csv file and name it as team_standings_2.csv in the same folder.\n\ncp team_standings.csv team_standings_2.csv\nls\n\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_analysis.R\nsecret_directory\nsoccer_directory\nteam_standings.csv\nteam_standings_2.csv\nteam_standings_3.csv\n\n\n\n\nTo copy folders, you use the -r option which refers to --recursive i.e. copy directories recursively.\n\ncp -r secret_directory secret_directory_2\nls secret*\n\nsecret_analysis.R\n\nsecret_directory:\nteam_standings.csv\n\nsecret_directory_2:\nteam_standings.csv"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#move-and-rename-files",
    "href": "posts/2023-10-31-command-line-part-1/index.html#move-and-rename-files",
    "title": "Introduction to the command-line",
    "section": "Move and rename files",
    "text": "Move and rename files\nmv moves and renames files and directories. Using different options, we can ensure\n\nfiles are not overwritten\nuser is prompted for confirmation before overwriting files\ndetails of files being moved is displayed\n\n\n\n\nCommand\nDescription\n\n\n\n\nmv\nMove or rename files/directories\n\n\nmv -f\nDo not prompt for confirmation before overwriting files\n\n\nmv -i\nPrompt for confirmation before overwriting files\n\n\nmv -n\nDo not overwrite existing files\n\n\nmv -v\nMove files in verbose mode\n\n\n\nLet us move/rename the team_standings_2.csv file to team_standings_3.csv in verbose mode.\n\nmv -v team_standings_2.csv team_standings_3.csv\nls team*\n\nteam_standings_2.csv -&gt; team_standings_3.csv\nteam_standings.csv\nteam_standings_3.csv\n\n\nWe see that there is no more file called team_standings_2.csv as it’s now been renamed!"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#removedelete-files",
    "href": "posts/2023-10-31-command-line-part-1/index.html#removedelete-files",
    "title": "Introduction to the command-line",
    "section": "remove/delete files",
    "text": "remove/delete files\nThe rm command is used to delete/remove files & folders. Using additional options, we can\n\nremove directories & sub-directories\nforcibly remove directories\ninteractively remove multiple files\ndisplay information about files removed/deleted\n\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nrm\nRemove files/directories\n\n\nrm -r\nRecursively remove a directory & all its subdirectories\n\n\nrm -rf\nForcibly remove directory without prompting for confirmation or showing error messages\n\n\nrm -i\nInteractively remove multiple files, with a prompt before every removal\n\n\nrm -v\nRemove files in verbose mode, printing a message for each removed file\n\n\n\nLet’s remove the secret_analysis.R file that we created earlier with the touch command.\n\nrm secret_analysis.R\nls\n\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_directory\nsecret_directory_2\nsoccer_directory\nteam_standings.csv\nteam_standings_3.csv\n\n\nTo remove a folder (and all of it’s contents), we need to use recursive deletion with -r\n\nrm -r secret_directory_2\nls\n\nanalysis.R\ncombined_names.txt\nindex.qmd\nindex.rmarkdown\npackage_names.txt\nr_release.txt\nrelease_names.txt\nsecret_directory\nsoccer_directory\nteam_standings.csv\nteam_standings_3.csv"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#display-messages",
    "href": "posts/2023-10-31-command-line-part-1/index.html#display-messages",
    "title": "Introduction to the command-line",
    "section": "Display messages",
    "text": "Display messages\nThe echo command prints text to the terminal.\nIt can be used for writing or appending messages to a file as well.\n\n\n\nCommand\nDescription\n\n\n\n\necho\nDisplay messages\n\n\necho -n\nPrint message without trailing new line\n\n\necho &gt; file\nWrite message to a file\n\n\necho -e\nEnable interpretation of special characters\n\n\n\nLet us start with a simple example. We will print the text “Funny-Looking Kid” to the terminal. It is the release name for R version 4.2.1.\n\necho Funny-looking Kid\n\nFunny-looking Kid\n\n\nIf we wanted to redirect that output from printing to the terminal and write to a file, we use the redirection (&gt;) operator.\n\necho Funny-looking Kid &gt; r_release.txt\ncat r_release.txt\n\nFunny-looking Kid\n\n\n\n\n\n\n\n\nRedirection operator\n\n\n\nIf we want to redirect that output from printing to the terminal and write to a file, we use the &gt; operator like so (command &gt; [file]) where on the left side is output gets piped into a file on the right side."
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#the-path-variable",
    "href": "posts/2023-10-31-command-line-part-1/index.html#the-path-variable",
    "title": "Introduction to the command-line",
    "section": "The PATH variable",
    "text": "The PATH variable\nAn important feature of the command line is the PATH variable.\nI won’t get into all the details about the PATH variable, but having a basic understanding will likely prove useful if you ever have to troubleshoot problems in the future.\n\nHave you ever wondered how the command-line knows what to do when you type a command like python or ls?\nHow does it know what program to run, especially on a computer that might have multiple installations of a program like Python?\n\nThe answer is that your system has a list of folders stored in an “environment variable” called PATH.\nWhen you run a command (like python or ls), it goes through those folders in order until it finds an executable file with the name of the command you typed.\nThen, when it finds that file, it executes that program and stops looking.\nYou can see the value of the PATH variable on your computer by typing\n\necho $PATH\n\n/Library/Frameworks/R.framework/Resources/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/usr/local/bin:/System/Cryptexes/App/usr/bin:/usr/bin:/bin:/usr/sbin:/sbin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/local/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/bin:/var/run/com.apple.security.cryptexd/codex.system/bootstrap/usr/appleinternal/bin:/opt/X11/bin:/Library/TeX/texbin:/Applications/quarto/bin:/Library/Frameworks/R.framework/Resources/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/opt/homebrew/Caskroom/miniforge/base/bin:/opt/homebrew/Caskroom/miniforge/base/condabin:/Users/stephaniehicks/Applications/quarto/bin:/usr/texbin:/Applications/RStudio.app/Contents/Resources/app/bin/postback\n\n\nThat means that when I type python, my computer will first look in the folder /Applications/quarto/bin to see if there is a file named python it can run. If it can’t find one there, it moves on to to the next one.\n\nWhy is this useful\nIn a perfect world, you will never have to worry about your PATH variable, but there are a couple situations where knowing about your PATH variable can be helpful. In particular:\n\nIf you downloaded a program, but you cannot run it from the command line, that probably means that its location is not in the PATH variable.\nIf you find that when you type a command like python, the command line is not running the version of python you want it to run, that’s probably because a different version of python appears earlier in the PATH variable (since the command line will stop looking through these folders as soon as it finds a match).\n\n\n\n\n\n\n\nNote\n\n\n\nYou can diagnose this problem by typing which COMMANDNAME, which will tell you the folder from which COMMANDNAME is being run.\n\nwhich python\n\n/opt/homebrew/Caskroom/miniforge/base/bin/python\n\n\n\nwhich ls\n\n/bin/ls"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#print-file-contents",
    "href": "posts/2023-10-31-command-line-part-1/index.html#print-file-contents",
    "title": "Introduction to the command-line",
    "section": "Print file contents",
    "text": "Print file contents\nThe cat (stands for catenate) command reads data from files, and outputs (or prints) their contents to the screen.\n\n\n\n\n\n\nExample\n\n\n\nLet’s consider the release_names.txt file, which contains release names of different R versions.\nIf we wanted to print the file contents to the screen:\n\ncat release_names.txt\n\nUnsuffered Consequences\nGreat Pumpkin\nDecember Snowflakes\nGift-Getting Season\nEaster Beagle\nRoasted Marshmallows\nTrick or Treat\nSecurity Blanket\nMasked Marvel\nGood Sport\nFrisbee Sailing\nWarm Puppy\nSpring Dance\nSock it to Me\nPumpkin Helmet\nSmooth Sidewalk\nFull of Ingredients\nWorld-Famous Astronaut\nFire Safety\nWooden Christmas Tree\nVery Secure Dishes\nVery, Very Secure Dishes\nSupposedly Educational\nBug in Your Hair\nSincere Pumpkin Patch\nAnother Canoe\nYou Stupid Darkness\nSingle Candle\nShort Summer\nKite Eating Tree\n\n\n\n\nIf we wanted to number all the output, use the -n option:\n\ncat -n release_names.txt \n\n     1  Unsuffered Consequences\n     2  Great Pumpkin\n     3  December Snowflakes\n     4  Gift-Getting Season\n     5  Easter Beagle\n     6  Roasted Marshmallows\n     7  Trick or Treat\n     8  Security Blanket\n     9  Masked Marvel\n    10  Good Sport\n    11  Frisbee Sailing\n    12  Warm Puppy\n    13  Spring Dance\n    14  Sock it to Me\n    15  Pumpkin Helmet\n    16  Smooth Sidewalk\n    17  Full of Ingredients\n    18  World-Famous Astronaut\n    19  Fire Safety\n    20  Wooden Christmas Tree\n    21  Very Secure Dishes\n    22  Very, Very Secure Dishes\n    23  Supposedly Educational\n    24  Bug in Your Hair\n    25  Sincere Pumpkin Patch\n    26  Another Canoe\n    27  You Stupid Darkness\n    28  Single Candle\n    29  Short Summer\n    30  Kite Eating Tree\n\n\nTo concatenate several source (or input) files into one final target (or output) file, we can also use the redirect operator (&gt;):\n\ncat r_release.txt release_names.txt &gt; combined_names.txt\ncat combined_names.txt\n\nFunny-looking Kid\nUnsuffered Consequences\nGreat Pumpkin\nDecember Snowflakes\nGift-Getting Season\nEaster Beagle\nRoasted Marshmallows\nTrick or Treat\nSecurity Blanket\nMasked Marvel\nGood Sport\nFrisbee Sailing\nWarm Puppy\nSpring Dance\nSock it to Me\nPumpkin Helmet\nSmooth Sidewalk\nFull of Ingredients\nWorld-Famous Astronaut\nFire Safety\nWooden Christmas Tree\nVery Secure Dishes\nVery, Very Secure Dishes\nSupposedly Educational\nBug in Your Hair\nSincere Pumpkin Patch\nAnother Canoe\nYou Stupid Darkness\nSingle Candle\nShort Summer\nKite Eating Tree\n\n\n\nThe head command will display the first 10 lines of a file(s) by default.\nThe tail command displays the last 10 lines of a file(s) by default.\n\nIt can be used to display the first (or last) few lines or bytes of a file as well.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nhead\nOutput the first parts of a file\n\n\nhead -n num\nOutput the first num lines of a file\n\n\nhead -c num\nOutput the first num bytes of a file\n\n\ntail\nDisplay the last part of a file\n\n\ntail -n num\nShow the last num lines of a file\n\n\ntail -n +num\nShow all contents of the file starting from num line\n\n\ntail -c num\nShow last num bytes of a file\n\n\n\nTo show the head of the first 8 lines of the combined_names.txt file:\n\nhead -c 8 combined_names.txt \n\nFunny-lo\n\n\nTo show all the lines starting from line 8 and beyond:\n\ntail -n +8 combined_names.txt \n\nTrick or Treat\nSecurity Blanket\nMasked Marvel\nGood Sport\nFrisbee Sailing\nWarm Puppy\nSpring Dance\nSock it to Me\nPumpkin Helmet\nSmooth Sidewalk\nFull of Ingredients\nWorld-Famous Astronaut\nFire Safety\nWooden Christmas Tree\nVery Secure Dishes\nVery, Very Secure Dishes\nSupposedly Educational\nBug in Your Hair\nSincere Pumpkin Patch\nAnother Canoe\nYou Stupid Darkness\nSingle Candle\nShort Summer\nKite Eating Tree\n\n\nThe more command displays text, one screen at a time. It opens a file for\n\ninteractive reading\nscrolling\nsearching\n\n\n\n\n\n\n\nTip\n\n\n\nPress space to scroll down the page, the forward slash (/) for searching strings, n to go to the next match, and q to quit.\n\n\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nmore\nOpen a file for interactive reading, scrolling and searching\n\n\nspace\nPage down\n\n\n/\nSearch for a string; press n to go the next match\n\n\nq\nQuit\n\n\n\nThe less command is similar to more, but offers more features.\nIt allows the user to scroll up and down the file, go to the beginning and end of the file, forward and backward search and the ability to go the next and previous match while searching the file.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\nless\nOpen a file for interactive reading, scrolling and searching\n\n\nspace\nPage down\n\n\nb\nPage up\n\n\nG\nGo to the end of file\n\n\ng\nGo to the start of file\n\n\n/\nForward search\n\n\n?\nBackward search\n\n\nn\nGo to next match\n\n\nN\nGo to previous match\n\n\nq\nQuit"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#sort-files",
    "href": "posts/2023-10-31-command-line-part-1/index.html#sort-files",
    "title": "Introduction to the command-line",
    "section": "Sort files",
    "text": "Sort files\nThe sort command will sort the contents of text file, line by line. Using additional options, we can\n\nsort a file in ascending/descending order\nignore case while sorting\nuse numeric order for sorting\npreserve only unique lines while sorting\n\n\n\n\n\n\n\nTip\n\n\n\nUsing the sort command, the contents can be sorted numerically and alphabetically. By default, the rules for sorting are:\n\nlines starting with a number will appear before lines starting with a letter.\nlines starting with a letter that appears earlier in the alphabet will appear before lines starting with a letter that appears later in the alphabet.\nlines starting with a lowercase letter will appear before lines starting with the same letter in uppercase.\n\n\n\nUsing additional options, the rules for sorting can be changed. We list the options in the below table.\n\n\n\nCommand\nDescription\n\n\n\n\nsort\nSort lines of text files\n\n\nsort -r\nSort a file in descending order\n\n\nsort --ignore-case\nIgnore case while sorting\n\n\nsort -n\nUse numeric order for sorting\n\n\nsort -u\nPreserve only unique lines while sorting\n\n\n\nHere we are sorting in a descending alphabetical order of the combined_names.txt\n\nsort -r combined_names.txt\n\nYou Stupid Darkness\nWorld-Famous Astronaut\nWooden Christmas Tree\nWarm Puppy\nVery, Very Secure Dishes\nVery Secure Dishes\nUnsuffered Consequences\nTrick or Treat\nSupposedly Educational\nSpring Dance\nSock it to Me\nSmooth Sidewalk\nSingle Candle\nSincere Pumpkin Patch\nShort Summer\nSecurity Blanket\nRoasted Marshmallows\nPumpkin Helmet\nMasked Marvel\nKite Eating Tree\nGreat Pumpkin\nGood Sport\nGift-Getting Season\nFunny-looking Kid\nFull of Ingredients\nFrisbee Sailing\nFire Safety\nEaster Beagle\nDecember Snowflakes\nBug in Your Hair\nAnother Canoe"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#count-length-of-file",
    "href": "posts/2023-10-31-command-line-part-1/index.html#count-length-of-file",
    "title": "Introduction to the command-line",
    "section": "Count length of file",
    "text": "Count length of file\nwc (word count) will print newline, word, and byte counts for file(s).\n\nwc combined_names.txt\n\n      31      75     564 combined_names.txt\n\n\n\nwc -l combined_names.txt\n\n      31 combined_names.txt\n\n\n\nwc -w combined_names.txt\n\n      75 combined_names.txt\n\n\n\nwc -c combined_names.txt\n\n     564 combined_names.txt\n\n\nIf more than one file is specified, it will also print total line.\n\nwc combined_names.txt package_names.txt\n\n      31      75     564 combined_names.txt\n     108     216    1498 package_names.txt\n     139     291    2062 total"
  },
  {
    "objectID": "posts/2023-10-31-command-line-part-1/index.html#search-for-a-string-in-a-file",
    "href": "posts/2023-10-31-command-line-part-1/index.html#search-for-a-string-in-a-file",
    "title": "Introduction to the command-line",
    "section": "Search for a string in a file",
    "text": "Search for a string in a file\nThe grep command is used for pattern matching. Along with additional options, it can be used to\n\nmatch pattern in input text\nignore case\nsearch recursively for an exact string\nprint filename and line number for each match\ninvert match for excluding specific strings\n\ngrep (stands for global regular expression) processes text line by line, and prints any lines which match a specified pattern.\nIt is a powerful tool for matching a regular expression against text in a file, multiple files, or a stream of input.\n\n\n\n\n\n\n\nCommand\nDescription\n\n\n\n\ngrep\nMatches pattern in input text\n\n\ngrep -i\nIgnore case\n\n\ngrep -RI\nSearch recursively for an exact string\n\n\ngrep -E\nUse extended regular expression\n\n\ngrep -Hn\nPrint file name & corresponding line number for each match\n\n\ngrep -v\nInvert match for excluding specific strings\n\n\n\nFirst, we will search for packages that include the letter “R” in a list of R package names (package_names.txt).\n\ngrep R package_names.txt\n\n14. RJDBC\n30. logNormReg\n27. gLRTH\n35. fermicatsR\n42. OptimaRegion\n61. PropScrRand\n25. RPyGeo\n47. SMARTp\n24. SCRT\n56. MARSS\n85. edfReader\n32. SPEDInstabR\n98. SmallCountRounding\n\n\nIf you are familiar with regular expressions, you can do cool things like search for a “r” followed by a white space with the \\s character set for white spaces.\n\ngrep -i 'r\\s' release_names.txt\n\nDecember Snowflakes\nEaster Beagle\nTrick or Treat\nBug in Your Hair\nAnother Canoe\nShort Summer\n\n\nIf there is more than one file to search, use the -H option to print the filename for each match.\n\ngrep -H F r_release.txt package_names.txt\n\nr_release.txt:Funny-looking Kid\npackage_names.txt:69. FField\npackage_names.txt:78. sybilccFBA\n\n\nAnd here is the file name and line number\n\ngrep -Hn F r_release.txt package_names.txt\n\nr_release.txt:1:Funny-looking Kid\npackage_names.txt:82:69. FField\npackage_names.txt:93:78. sybilccFBA\n\n\nAnd here we invert match for excluding the string “R”\n\ngrep -vi R r_release.txt package_names.txt\n\nr_release.txt:Funny-looking Kid\npackage_names.txt:36. mlflow\npackage_names.txt:10. aweek\npackage_names.txt:31. BIGDAWG\npackage_names.txt:22. vqtl\npackage_names.txt:29. sspline\npackage_names.txt:39. mev\npackage_names.txt:66. SuppDists\npackage_names.txt:15. MIAmaxent\npackage_names.txt:31. BIGDAWG\npackage_names.txt:29. sspline\npackage_names.txt:60. Eagle\npackage_names.txt:83. WPKDE\npackage_names.txt:11. hdnom\npackage_names.txt:26. blink\npackage_names.txt:18. gazepath\npackage_names.txt:52. ClimMobTools\npackage_names.txt:44. expstudies\npackage_names.txt:65. mined\npackage_names.txt:81. mgcViz\npackage_names.txt:45. solitude\npackage_names.txt:9. pAnalysis\npackage_names.txt:65. mined\npackage_names.txt:94. ICAOD\npackage_names.txt:48. geoknife\npackage_names.txt:45. solitude\npackage_names.txt:67. tictactoe\npackage_names.txt:46. cbsem\npackage_names.txt:93. PathSelectMP\npackage_names.txt:96. poisbinom\npackage_names.txt:17. ASIP\npackage_names.txt:5. pls\npackage_names.txt:84. BIOMASS\npackage_names.txt:59. AdMit\npackage_names.txt:77. SetMethods\npackage_names.txt:53. MVB\npackage_names.txt:2. odk\npackage_names.txt:86. mongolite\npackage_names.txt:4. TIMP\npackage_names.txt:97. AnalyzeTS\npackage_names.txt:87. WGScan\npackage_names.txt:63. dagitty\npackage_names.txt:69. FField\npackage_names.txt:13. MaXact\npackage_names.txt:73. VineCopula\npackage_names.txt:7. bayesbio\npackage_names.txt:34. ibd\npackage_names.txt:8. MVTests\npackage_names.txt:19. mcmcabn\npackage_names.txt:43. accept\npackage_names.txt:78. sybilccFBA\npackage_names.txt:62. lue\npackage_names.txt:100. addhaz\npackage_names.txt:37. CombinePValue\npackage_names.txt:1. cyclocomp\npackage_names.txt:54. OxyBS"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Statistical Programming Paradigms and Workflows!",
    "section": "",
    "text": "Welcome to Statistical Programming Paradigms and Workflows at Johns Hopkins Bloomberg School of Public Health!"
  },
  {
    "objectID": "index.html#what-is-this-course",
    "href": "index.html#what-is-this-course",
    "title": "Welcome to Statistical Programming Paradigms and Workflows!",
    "section": "What is this course?",
    "text": "What is this course?\nThis course covers advanced statistical computing programming paradigms and workflows required for the research and application of statistical methods. Includes the basics of programming in unix and/or using command-line tools, introduction to version control, advanced R and tidyverse skills, introduction to creating R packages with documentation, working with relational databases, introduction to functional programming, getting and using data from APIs, introduction to Shiny and dashboards. Topics in statistical data analysis provide working examples."
  },
  {
    "objectID": "index.html#getting-started",
    "href": "index.html#getting-started",
    "title": "Welcome to Statistical Programming Paradigms and Workflows!",
    "section": "Getting started",
    "text": "Getting started\nI suggest that you start by looking over the Syllabus and Schedule under General Information. After that, start with the Lectures content in the given order."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Welcome to Statistical Programming Paradigms and Workflows!",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis course was developed and is maintained by Stephanie Hicks.\nThe following individuals have contributed to improving the course or materials have been adapted from their courses: Roger D. Peng, Andreas Handel, Naim Rashid, Michael Love.\nThe image above was generated with aRtsy.\nThe course materials are licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. Linked and embedded materials are governed by their own licenses. I assume that all external materials used or embedded here are covered under the educational fair use policy. If this is not the case and any material displayed here violates copyright, please let me know and I will remove it."
  },
  {
    "objectID": "lectures.html",
    "href": "lectures.html",
    "title": "Lectures",
    "section": "",
    "text": "Strategies for dealing with large data\n\n\n\n\n\n\n\nmodule 5\n\n\nweek 9\n\n\nlarge data\n\n\nprogramming\n\n\nR\n\n\n\n\nIntroduction to basic strategies for dealing with large data in R\n\n\n\n\n\n\nDec 19, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nScraping data from the web with rvest\n\n\n\n\n\n\n\nmodule 4\n\n\nweek 8\n\n\nhtml\n\n\nrvest\n\n\n\n\nIntroduction to scrape (or harvest) data from web pages\n\n\n\n\n\n\nDec 14, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nBuilding dashboards with flexdashboard and shinydashboard\n\n\n\n\n\n\n\nmodule 4\n\n\nweek 8\n\n\ndata viz\n\n\nflexdashboard\n\n\nshinydashboard\n\n\ndashboard\n\n\ninteractive\n\n\n\n\nIntroduction to building dashboards in R with flexdashboard and shinydashboard\n\n\n\n\n\n\nDec 12, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nRelational databases and SQL basics\n\n\n\n\n\n\n\nmodule 3\n\n\nweek 7\n\n\ndatabases\n\n\nSQL\n\n\nlarge data\n\n\ntidyverse\n\n\nDBI\n\n\nRSQLite\n\n\ndplyr\n\n\ndbplyr\n\n\n\n\nIntroduction to relational databases and SQL in R\n\n\n\n\n\n\nDec 7, 2023\n\n\nAlyssa Columbus\n\n\n\n\n\n\n  \n\n\n\n\nRetrieving data from APIs with httr\n\n\n\n\n\n\n\nmodule 3\n\n\nweek 7\n\n\nJSON\n\n\nAPIs\n\n\nhttr\n\n\n\n\nIntroduction to JSON files and interacting with APIs with httr\n\n\n\n\n\n\nDec 5, 2023\n\n\nJoe Sartini\n\n\n\n\n\n\n  \n\n\n\n\nPackage development with pkgdown\n\n\n\n\n\n\n\nmodule 3\n\n\nweek 6\n\n\npackages\n\n\npkgdown\n\n\n\n\nBuilding a website for R software packages\n\n\n\n\n\n\nNov 30, 2023\n\n\nBoyi Guo\n\n\n\n\n\n\n  \n\n\n\n\nReproducibile Workflows with targets\n\n\n\n\n\n\n\nmodule 3\n\n\nweek 6\n\n\nproject management\n\n\ntargets\n\n\n\n\nA Make-line pipeline tool for creating reproducible workflows in R\n\n\n\n\n\n\nNov 30, 2023\n\n\nBoyi Guo\n\n\n\n\n\n\n  \n\n\n\n\nFunctional Programming with purrr\n\n\n\n\n\n\n\nmodule 3\n\n\nweek 6\n\n\nfunctions\n\n\nfunctional\n\n\nprogramming\n\n\npurrr\n\n\n\n\nIntroduction to tools to work with functions and vectors in R\n\n\n\n\n\n\nNov 28, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nBuilding R packages\n\n\n\n\n\n\n\nmodule 2\n\n\nweek 5\n\n\nR\n\n\nprogramming\n\n\ndocumentation\n\n\nR package\n\n\nfunctions\n\n\n\n\nIntroduction to building and documenting R packages\n\n\n\n\n\n\nNov 21, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nObject Oriented Programming\n\n\n\n\n\n\n\nmodule 2\n\n\nweek 4\n\n\nR\n\n\nfunctions\n\n\nprogramming\n\n\n\n\nIntroduction to S3, S4, or reference class with generics and methods\n\n\n\n\n\n\nNov 14, 2023\n\n\nJoe Sartini\n\n\n\n\n\n\n  \n\n\n\n\nVersion control (Part 2)\n\n\n\n\n\n\n\nmodule 1\n\n\nweek 3\n\n\nversion control\n\n\ngit\n\n\nGitHub\n\n\n\n\nIntroduction to version control with git and GitHub (part 2)\n\n\n\n\n\n\nNov 9, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nVersion control (Part 1)\n\n\n\n\n\n\n\nmodule 1\n\n\nweek 3\n\n\nversion control\n\n\ngit\n\n\nGitHub\n\n\n\n\nIntroduction to version control with git and GitHub (part 1)\n\n\n\n\n\n\nNov 7, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nAdvanced command-line tools\n\n\n\n\n\n\n\nmodule 1\n\n\nweek 2\n\n\ncommand-line\n\n\n\n\nDoing more powerful things on the command-line\n\n\n\n\n\n\nNov 2, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to the command-line\n\n\n\n\n\n\n\nmodule 1\n\n\nweek 2\n\n\ncommand-line\n\n\n\n\nIntroduction to the command-line for data analysis\n\n\n\n\n\n\nOct 31, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nAuthoring projects and websites with Quarto\n\n\n\n\n\n\n\nmodule 1\n\n\nweek 1\n\n\nwebsites\n\n\nquarto\n\n\n\n\nHello Quarto! Or next-generation literate programming\n\n\n\n\n\n\nOct 26, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html",
    "href": "posts/2023-10-26-build-website/index.html",
    "title": "Authoring projects and websites with Quarto",
    "section": "",
    "text": "The next lecture falls on 👻 Halloween ! I plan to give the lecture dressed up in a costume. This is entirely optional, but I encourage students to come in costume if you wish! Candy 🍬 will be offered to anyone in costume!"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#introduction-1",
    "href": "posts/2023-10-26-build-website/index.html#introduction-1",
    "title": "Authoring projects and websites with Quarto",
    "section": "Introduction",
    "text": "Introduction\nQuarto provides a unified authoring framework for data science, combining your code, its results, and your prose.\nQuarto documents are fully reproducible and support dozens of output formats, like PDFs, Word files, presentations, and more.\nQuarto files are designed to be used in three ways:\n\nFor communicating to decision makers, who want to focus on the conclusions, not the code behind the analysis.\nFor collaborating with other data scientists (including future you!), who are interested in both your conclusions, and how you reached them (i.e. the code).\nAs an environment in which to do data science, as a modern day lab notebook where you can capture not only what you did, but also what you were thinking.\n\n\n\n\n\n\n\nImportant\n\n\n\nQuarto is a command line interface tool, not an R package.\nThis means that help is, by-and-large, not available through ? in the R console.\nAnd not to add to the confusion, but there is an quarto R package that has helper functions for you to use in R to e.g. check the Quarto version installed, etc.\n\n\nFormally, Quarto is a publishing system built on Pandoc that allows users to create dynamic content using R, Python, Julia, and ObservableJS (with plans to add more languages too!).\n\n\n\n\n\n\n\n\n\n\n\nArt by Allison Horst. Be sure to check out the rest of Allison’s seriously cute Quarto penguin art in the #rstudioconf2022 keynote talk, Hello Quarto, by Julie Lowndes & Mine Çetinkaya-Rundel!"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#prerequisites",
    "href": "posts/2023-10-26-build-website/index.html#prerequisites",
    "title": "Authoring projects and websites with Quarto",
    "section": "Prerequisites",
    "text": "Prerequisites\nYou need the Quarto command line interface (Quarto CLI), but you don’t need to explicitly install it or load it, as RStudio automatically does both when needed.\n\nhttps://quarto.org/docs/get-started\nhttps://formulae.brew.sh/cask/quarto (this is my preferred way using home brew)"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#qmd-files",
    "href": "posts/2023-10-26-build-website/index.html#qmd-files",
    "title": "Authoring projects and websites with Quarto",
    "section": ".qmd files",
    "text": ".qmd files\nQuarto files end in a .qmd. This is short for quarto markdown.\n\n\n\n\n\n\nNote\n\n\n\nThese files are decoupled from RStudio IDE and there are plugins to work with .qmd files for\n\nVSCode\nJupyterLab\nRStudio\n\n(Quick demo in VSCode)\n\n\n\nRendering\nUse the  Render button in the RStudio IDE to render the file and preview the output with a single click or keyboard shortcut (⇧⌘K).\n\n\n\n\n\nIf you prefer to automatically render whenever you save, you can check the Render on Save option on the editor toolbar. The preview will update whenever you re-render the document. Side-by-side preview works for both HTML and PDF outputs.\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDocuments can also be rendered from the R console via the quarto package:\n\n\nCode run in the R Console\n\ninstall.packages(\"quarto\")\nquarto::quarto_render(\"hello.qmd\")\n\nAnd documents can also be rendered from the command line:\n\n\nCode run in the command line\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles\n\n\n\n\nHow rendering works\nWhen you render a Quarto document, first knitr executes all of the code chunks and creates a new markdown (.md) document which includes the code and its output. The markdown file generated is then processed by pandoc, which creates the finished format. The Render button encapsulates these actions and executes them in the right order for you.\n\n\n\n\n\nWhen rendering, Quarto generates a new file that contains selected text, code, and results from the .qmd file. The new file can be an HTML, PDF, MS Word document, presentation, website, book, interactive document, or other format.\n\n\n\nAuthoring\nIn the image below we can see the same document in the two modes of the RStudio editor:\n\nvisual (on the left)\nsource (on the right)\n\nRStudio’s visual editor offers an WYSIWYM authoring experience for markdown. For formatting (e.g. bolding text) you can use the toolbar, a keyboard shortcut (⌘B), or the markdown construct (**bold**).\nYou can toggle back and forth these two modes by clicking on Source and Visual in the editor toolbar (or using the keyboard shortcut ⌘⇧ F4).\n\n\n\n\n\n\n\nHow does multi-language support work?\n\n\n\n\n\n\nQuarto supports multiple languages\n\n\n\nThese languages include\n\nR\nPython\nJulia\nObservable javascript\n\nQuarto can also interchange between languages using Apache Arrow.\n\n\nThe idea behind how quarto supports multi-language code is that the code output is “frozen” after it is rendered.\nIn this way, code output is not recomputed, unless you want it to."
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#r-markdown-vs-quarto",
    "href": "posts/2023-10-26-build-website/index.html#r-markdown-vs-quarto",
    "title": "Authoring projects and websites with Quarto",
    "section": "R Markdown vs Quarto",
    "text": "R Markdown vs Quarto\nSome high-level differences include\n\nStandardized YAML across formats\nDecoupled from RStudio\nMore consistent presentation across formats\nTab Panels\nCode Highlighting\n\n\nCode block options\nAnother noticeable difference are options for code blocks. Rather than being in the header of the code block, options are moved to within the code block using the #| (hash-pipe) for each line.\nThis is a code block for R Markdown:\n```{r setup, include=FALSE}\nlibrary(tidyverse)\nlibrary(tidytext)\n```\nThis is a code block for Quarto:\n```{r}\n#| label: \"setup\"\n#| include: false\nlibrary(tidyverse)\nlibrary(tidytext)\n```\n\n\nOutput Options\nThere are a wide variety of output options available for customizing output from executed code.\nAll of these options can be specified either\n\nglobally (in the document front-matter) or\nper code-block\n\nFor example, here’s a modification of the Python example to specify that we don’t want to “echo” the code into the output document:\n---\ntitle: \"My Document\"\nexecute:\n  echo: false\njupyter: python3\n---\nNote that we can override this option on a per code-block basis. For example:\n```{python}\n#| echo: true\n\nimport matplotlib.pyplot as plt\nplt.plot([1,2,3,4])\nplt.show()\n```\nCode block options available for customizing output include:\n\n\n\n\n\n\n\nOption\nDescription\n\n\n\n\neval\nEvaluate the code chunk (if false, just echos the code into the output).\n\n\necho\nInclude the source code in output\n\n\noutput\nInclude the results of executing the code in the output (true, false, or asis to indicate that the output is raw markdown and should not have any of Quarto’s standard enclosing markdown).\n\n\nwarning\nInclude warnings in the output.\n\n\nerror\nInclude errors in the output (note that this implies that errors executing code will not halt processing of the document).\n\n\ninclude\nCatch all for preventing any output (code or results) from being included (e.g. include: false suppresses all output from the code block).\n\n\n\nHere’s a example with r code blocks and some of these additional options included:\n---\ntitle: \"Knitr Document\"\nexecute:\n  echo: false\n---\n\n```{r}\n#| warning: false\n\nlibrary(ggplot2)\nggplot(airquality, aes(Temp, Ozone)) + \n  geom_point() + \n  geom_smooth(method = \"loess\", se = FALSE)\n```\n\n```{r}\nsummary(airquality)\n```\n\n\n\n\n\n\nTip\n\n\n\nWhen using the Knitr engine, you can also use any of the available native options (e.g. collapse, tidy, comment, etc.).\nSee the Knitr options documentation for additional details. You can include these native options in option comment blocks as shown above, or on the same line as the {r} as shown in the Knitr documentation.\n\n\n\n\nMargin content\nYou can place content within the right margin of Quarto document. For example, here we use the .column-margin class to place an image in the margin:\n::: {.column-margin}\nWe know from *the first fundamental theorem of calculus* that for $x$ in $[a, b]$:\n\n$$\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).$$\n:::\n\n\nWe know from the first fundamental theorem of calculus that for \\(x\\) in \\([a, b]\\):\n\\[\\frac{d}{dx}\\left( \\int_{a}^{x} f(u)\\,du\\right)=f(x).\\]\n\n\nMargin Figures\nFigures that you create using code blocks can be placed in the margin by using the column: margin code block option.\nIf the code produces more than one figure, each of the figures will be placed in the margin.\n\n```{r}\n#| label: fig-mtcars\n#| fig-cap: \"MPG vs horsepower, colored by transmission.\"\n#| column: margin\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\n```\n\n\n\n\n\nFigure 1: MPG vs horsepower, colored by transmission.\n\n\n\n\n\nMargin Tables\nYou an also place tables in the margin of your document by specifying column: margin.\n\n```{r}\n#| column: margin\nknitr::kable(\n  mtcars[1:6, 1:3]\n)\n```\n\n\n\n\n\n\nmpg\ncyl\ndisp\n\n\n\n\nMazda RX4\n21.0\n6\n160\n\n\nMazda RX4 Wag\n21.0\n6\n160\n\n\nDatsun 710\n22.8\n4\n108\n\n\nHornet 4 Drive\n21.4\n6\n258\n\n\nHornet Sportabout\n18.7\n8\n360\n\n\nValiant\n18.1\n6\n225\n\n\n\n\n\n\nCode line numbers\nIf you want to display line numbers alongside the code block, add the code-line-numbers option. For example:\nformat:\n  html:\n    code-line-numbers: true\nHere’s how a code block with line numbers would display throughout the document:\nlibrary(ggplot2)\nmtcars2 &lt;- mtcars\nmtcars2$am &lt;- factor(\n  mtcars$am, labels = c('automatic', 'manual')\n)\nggplot(mtcars2, aes(hp, mpg, color = am)) +\n  geom_point() +\n  geom_smooth(formula = y ~ x, method = \"loess\") +\n  theme(legend.position = 'bottom')\nYou can also enable line numbers for an individual code block using the code-line-numbers attribute.\n\n\nShould you switch to quarto?\n\nShould you switch to Quarto? Not necessarily. If you find R Markdown meets your need, you can definitely stay there. It is not imperative to switch. - Yihui Xie\n\n\n\nhttps://yihui.org/en/2022/04/quarto-r-markdown/"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#project",
    "href": "posts/2023-10-26-build-website/index.html#project",
    "title": "Authoring projects and websites with Quarto",
    "section": "Project",
    "text": "Project\nHere are the general steps for creating a Quarto project:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the project"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#website",
    "href": "posts/2023-10-26-build-website/index.html#website",
    "title": "Authoring projects and websites with Quarto",
    "section": "Website",
    "text": "Website\nHere are the general steps for creating a Quarto website:\n\nCreate a new Quarto project\nEdit _quarto.yml file\nAdd / delete relevant content\nRender the website\nDeploy the website\n\n\n\n\n\n\n\nDeploying a website\n\n\n\nquarto publish can push and update a number of different kinds of webhosts. You will need credentials to publish to each of these.\nquarto publish gh-pages    # GitHub Pages\nquarto publish quarto-pub  # Quarto.pub \nquarto publish netlify     # Netlify\nquarto publish connect     # RStudio Connect"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#freeze-results-and-avoid-recomputing",
    "href": "posts/2023-10-26-build-website/index.html#freeze-results-and-avoid-recomputing",
    "title": "Authoring projects and websites with Quarto",
    "section": "Freeze Results and avoid recomputing",
    "text": "Freeze Results and avoid recomputing\nFreezing code output is generally used when you have either\n\nA large number of collaborators or\nMany computational documents created over a longer period of time\nA project with different types of file formats from different languages (e.g. .qmd, .ipynb, .Rmd)\n\nIn the above cases, it can be challenging to fully re-execute every document when you render the site.\nThis could be because some documents have esoteric or environment-specific requirements (e.g. require access/authentication to a data source) or due to general fragility of dependencies over time.\nUsing freeze ensures that you can always reproducibly render your site.\nThe computational results of documents executed with freeze are stored in the _freeze/ directory, and re-used when needed to fulfill document renders.\nYou should check the contents of _freeze/ into version control so that others rendering the project don’t need to reproduce your computational environment to render it in their environment.\n\n\n\n\n\n\nNote\n\n\n\nYou will still want to take care to fully re-render your project when things outside of source code change (e.g. input data).\nYou can remove previously frozen output by deleting the _freeze folder at the root of your project.\n\n\nFor example, consider the _quarto.yml file.\nOne argument in the file is the freeze option to denote that computational documents should never be re-rendered during a global project render, or alternatively only be re-rendered when their source file changes:\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n  \nexecute:\n  freeze: true  # never re-render during project render\nproject:\n  title: \"qmd_rmd\"\n  type: website\n  output-dir: docs\n\nexecute:\n  freeze: auto  # re-render only when source changes\n\n\n\n\n\n\nNote\n\n\n\nThe freeze option in the _quarto.yml file controls whether execution occurs during global project renders.\nIf you do an incremental render of either a single document or a project sub-directory then code is always executed. For example:\n\n\nTerminal\n\n# render single document (always executes code)\nquarto render document.qmd\n\n# render project subdirectory (always executes code)\nquarto render articles"
  },
  {
    "objectID": "posts/2023-10-26-build-website/index.html#next-steps",
    "href": "posts/2023-10-26-build-website/index.html#next-steps",
    "title": "Authoring projects and websites with Quarto",
    "section": "Next steps",
    "text": "Next steps\nHere are some tutorials I really like for getting started with Quarto generally and for getting started building and deploying websites with Quarto:\n\nCreating Quarto websites\nCustomize Quarto websites"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html",
    "href": "posts/2023-11-02-command-line-part-2/index.html",
    "title": "Advanced command-line tools",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://swcarpentry.github.io/shell-novice\n\n\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://swcarpentry.github.io/shell-novice/04-pipefilter\nhttps://swcarpentry.github.io/shell-novice/05-loop\nhttps://swcarpentry.github.io/shell-novice/06-script"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#capturing-output-from-commands",
    "href": "posts/2023-11-02-command-line-part-2/index.html#capturing-output-from-commands",
    "title": "Advanced command-line tools",
    "section": "Capturing output from commands",
    "text": "Capturing output from commands\nIn this section, we will continue to explore how to use pipes to re-direct output from to the terminal and write it to a file.\n\n\n\n\n\n\nDataset\n\n\n\nThe dataset we will use is a folder that contains six files describing some simple organic molecules. The .pdb extension indicates that these files are in Protein Data Bank format, a simple text format that specifies the type and position of each atom in the molecule.\n\nls proteins\n\ncubane.pdb\nethane.pdb\nlengths.txt\nmethane.pdb\noctane.pdb\npentane.pdb\npropane.pdb\n\n\n\n\nLet’s count the lines in one of the files cubane.pdb using the wc command (word count):\n\nwc -l proteins/cubane.pdb\n\n      20 proteins/cubane.pdb\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nUsing wildcard (*), list out all the number of lines in each .pdb file in the protein directory\n\n## try it out \n\n\n\nThis is useful information, but all of that output gets printed to the screen and then it’s gone. Let’s try saving the output to a file with the redirection &gt; operator:\n\n\n\n\n\n\nRedirection operator\n\n\n\nIn the previous lecture, we learned that if we wanted to redirect that output from printing to the terminal and write to a file, we use the &gt; operator like so (command &gt; [file]) where on the left side is output gets piped into a file on the right side.\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nWrite the commands for the followings tasks:\n\nUsing the &gt; redirect operator, pipe the output from our example above to a file called lengths.txt.\nPrint the file contents in length.txt to the screen.\n\n\n## try it out"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#appending-data-to-a-file",
    "href": "posts/2023-11-02-command-line-part-2/index.html#appending-data-to-a-file",
    "title": "Advanced command-line tools",
    "section": "Appending data to a file",
    "text": "Appending data to a file\nIn general, it is a very bad idea to try redirecting the output of a command that operates on a file to the same file.\nFor example:\n\n\nBash\n\nsort -n lengths.txt &gt; lengths.txt\n\nDoing something like this may give you incorrect results and/or delete the contents of lengths.txt.\nAn alternative is another type of redirect operator (&gt;&gt;), which is used to append to a file (command &gt;&gt; [file]).\nLet’s try this out.\n\n\n\n\n\n\nExample\n\n\n\nNow test the commands below to reveal the difference between the two operators\n\necho hello &gt; testfile01.txt\n\n\necho hello &gt;&gt; testfile02.txt\n\nTask: Try executing each command twice in a row and then examining the output files. What happened?\n\n\nOK let’s clean up our space before we move on\n\nrm testfile01.txt testfile02.txt"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#passing-output-to-another-command",
    "href": "posts/2023-11-02-command-line-part-2/index.html#passing-output-to-another-command",
    "title": "Advanced command-line tools",
    "section": "Passing output to another command",
    "text": "Passing output to another command\nAnother operator is the vertical bar (|) (or pipe operator) which is used between two commands to pass the output from one command as input to another command ([first] | [second]).\n\n\n\n\n\n\nExample\n\n\n\nLet’s sort the rows in lengths.txt in a numeric order and then pipe the output into another command to show only the first row.\n\ncat lengths.txt\n\n      20 proteins/cubane.pdb\n      12 proteins/ethane.pdb\n       9 proteins/methane.pdb\n      30 proteins/octane.pdb\n      21 proteins/pentane.pdb\n      15 proteins/propane.pdb\n     107 total\n\n\n\nsort -n lengths.txt | head -n 1\n\n       9 proteins/methane.pdb\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s practice using the pipe operator and combine three commands together. Write the following commands and pipe the output with the | operator.\nUsing the *.pdb files in the protein folder:\n\nCount the number of lines in each each *.pdb file.\nSort the lines numerically in an ascending order.\nShow the first line of the output.\n\n\n## try it out"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#loop-basics",
    "href": "posts/2023-11-02-command-line-part-2/index.html#loop-basics",
    "title": "Advanced command-line tools",
    "section": "Loop basics",
    "text": "Loop basics\nAnother way to do this is to use a loop to solve this problem, but first let’s look at the general form of a for loop, using the pseudo-code below:\n\n\nBash\n\nfor thing in list_of_things\ndo\n    operation_using $thing    # Indentation within the loop is not required, but aids legibility\ndone\n\nand we can apply this to our example like this:\n\ncd creatures\nfor filename in basilisk.dat minotaur.dat unicorn.dat\ndo\n    head -n 2 $filename | tail -n 1\ndone\n\nCLASSIFICATION: basiliscus vulgaris\nCLASSIFICATION: bos hominus\nCLASSIFICATION: equus monoceros\n\n\n\n\n\n\n\n\nPro-tip #1\n\n\n\n\nWhen using variables it is also possible to put the names into curly braces to clearly delimit the variable name: $filename is equivalent to ${filename}, but is different from ${file}name. You may find this notation in other people’s programs.\n\n\n\n\n\n\n\n\n\nPro-tip #2\n\n\n\n\nWe have called the variable in this loop filename in order to make its purpose clearer to human readers. The shell itself doesn’t care what the variable is called; if we wrote this loop with x:\n\n\ncd creatures\nfor x in basilisk.dat minotaur.dat unicorn.dat\ndo\n    head -n 2 $x | tail -n 1\ndone\n\nCLASSIFICATION: basiliscus vulgaris\nCLASSIFICATION: bos hominus\nCLASSIFICATION: equus monoceros\n\n\n\n\n\n\n\n\n\n\nPro-tip #3\n\n\n\n\nSpaces are used to separate the elements of the list that we are going to loop over. If one of those elements contains a space character, we need to surround it with quotes, and do the same thing to our loop variable.\n\n\nfor x in \"spooky ghost\" \"scary monster\" \"creepy spider\"\ndo\n   echo $x\ndone\n\nspooky ghost\nscary monster\ncreepy spider\n\n\n\n\n\n\n\n\n\n\nPro-tip #4\n\n\n\n\nThere are other types of loops including\n\n\nThe for loop: executes the given commands over a series of defined number of iterations\nThe while loop: executes the given commands until the given condition changes from true to false\nThe until loop: executes the given commands until a given condition becomes true\nThe select loop: easy way to create a numbered menu from which users can select options. It is useful when you need to ask the user to choose one or more items from a list of choices.\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nUsing the six files in the proteins folder, let’s predict what the output of these loops are.\ncd proteins\nfor datafile in *.pdb\ndo\n    ls *.pdb\ndone\ncd proteins\nfor datafile in *.pdb\ndo\n    ls $datafile\ndone\ncd proteins\nfor datafile in c*\ndo\n    ls $datafile\ndone\ncd proteins\nfor datafile in *c*\ndo\n    ls $datafile\ndone"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#naming-files",
    "href": "posts/2023-11-02-command-line-part-2/index.html#naming-files",
    "title": "Advanced command-line tools",
    "section": "Naming files",
    "text": "Naming files\nYou can also use the variables in for loops to name files or folders.\nFor example, let’s say we want to save a version of the original files in the creatures folder, naming the copies original-basilisk.dat and original-unicorn.dat, etc.\n\ncd creatures\nfor filename in *.dat\ndo\n    cp $filename original-$filename\ndone\n\nls *.dat\n\nbasilisk.dat\nminotaur.dat\noriginal-basilisk.dat\noriginal-minotaur.dat\noriginal-unicorn.dat\nunicorn.dat\n\n\nThis loop runs the cp command once for each filename. The first time, when $filename expands to basilisk.dat, the shell executes:\n\n\nBash\n\ncp basilisk.dat original-basilisk.dat\n\nand so on. Finally, let’s clean up our copies\n\nrm creatures/original-*\nls creatures/*\n\ncreatures/basilisk.dat\ncreatures/minotaur.dat\ncreatures/unicorn.dat"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#create-a-.sh-file",
    "href": "posts/2023-11-02-command-line-part-2/index.html#create-a-.sh-file",
    "title": "Advanced command-line tools",
    "section": "Create a .sh file",
    "text": "Create a .sh file\nLet’s start by going back to proteins/ and creating a new file, middle.sh which will become our shell script:\n\ncd proteins\ntouch middle.sh\n\nWe can open the file and simply insert the following line:\nhead -n 15 octane.pdb | tail -n 5\nThis is a variation on the pipe we constructed earlier:\n\nit selects lines 11-15 of the file octane.pdb.\n\n\n\n\n\n\n\nNote\n\n\n\nWe are not running it as a command just yet: we are putting the commands in a file.\n\n\nWe can see that the directory proteins/ now contains a file called middle.sh.\nOnce we have saved the file, we can ask the shell to execute the commands it contains.\n\ncd proteins\nbash middle.sh"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#file-arguements",
    "href": "posts/2023-11-02-command-line-part-2/index.html#file-arguements",
    "title": "Advanced command-line tools",
    "section": "File arguements",
    "text": "File arguements\nWhat if we want to select lines from an arbitrary file?\nWe could edit middle.sh each time to change the filename, but that would probably take longer than typing the command out again in the shell and executing it with a new file name.\nInstead, let’s edit middle.sh and make it more versatile:\n\nReplace the text octane.pdb with the special variable called $1:\n\nhead -n 15 \"$1\" | tail -n 5\n\n\n\n\n\n\nNote\n\n\n\nInside a shell script, $1 means ‘the first filename (or other argument) on the command line’.\n\n\nWe can now run our script like this:\n\ncd proteins\nbash middle.sh octane.pdb\n\nor on a different file like this:\n\ncd proteins\nbash middle.sh pentane.pdb\n\n\n\n\n\n\n\nPro-tip: double-quotes around arguments\n\n\n\nFor the same reason that we put the loop variable inside double-quotes, in case the filename happens to contain any spaces, we surround $1 with double-quotes.\n\n\nCurrently, we need to edit middle.sh each time we want to adjust the range of lines that is returned.\nLet’s fix that by configuring our script to instead use three command-line arguments.\n\nAfter the first command-line argument ($1), each additional argument that we provide will be accessible via the special variables $1, $2, $3, which refer to the first, second, third command-line arguments, respectively.\n\n\n\n\n\n\n\nQuestion\n\n\n\nKnowing about $1, $2, $3, let’s modify middle.sh such that we can use additional arguments to define the range of lines to be passed to head and tail respectively.\n\n## try it out\n\n\nBy changing the arguments to our command we can change our script’s behaviour:\n\n\n\nThis works, but it may take the next person who reads middle.sh a moment to figure out what it does. We can improve our script by adding some comments at the top of the file:\n# Select lines from the middle of a file.\n# Usage: bash middle.sh filename end_line num_lines\nhead -n \"$2\" \"$1\" | tail -n \"$3\"\n\n\n\n\n\n\nNote\n\n\n\n\nA comment starts with a # character and runs to the end of the line.\nThe computer ignores comments, but they are invaluable for helping people (including your future self) understand and use scripts.\nThe only caveat is that each time you modify the script, you should check that the comment is still accurate: an explanation that sends the reader in the wrong direction is worse than none at all.\n\n\n\nFinally, let’s clean up our space\n\ncd proteins\nrm middle.sh"
  },
  {
    "objectID": "posts/2023-11-02-command-line-part-2/index.html#overview",
    "href": "posts/2023-11-02-command-line-part-2/index.html#overview",
    "title": "Advanced command-line tools",
    "section": "Overview",
    "text": "Overview\nThe SSH protocol uses encryption to secure the connection between a client and a server.\nAll user authentication, commands, output, and file transfers are encrypted to protect against attacks in the network.\nFor details of how the SSH protocol works, see the protocol page. To understand the SSH File Transfer Protocol, see the SFTP page.\n\nYou can read more about setting up your SSH keys to connect to JHPCE here:\n\nhttps://jhpce.jhu.edu/knowledge-base/authentication/ssh-key-setup\nDemo connecting to JHPCE via ssh\n\nYou can read more about setting up your SSH keys to connect to GitHub here:\n\nhttps://docs.github.com/en/authentication/connecting-to-github-with-ssh"
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html",
    "href": "posts/2023-11-09-version-control-part-2/index.html",
    "title": "Version control (Part 2)",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nSoftware Carpentry: Version Control with Git\n\n\n\n\n\n\n\n\n\nRead ahead\n\n\n\nIn the previous lesson, we learned how to use git from the command line.\nIn this lesson, we will learn how to use git remotes and GitHub. As preparation, you can sign up for a GitHub account if you do not already have one.\nWe will use the local git repository in the planets directory that we created in the previous lesson. If you do not have this any more, please create it by initializing the git repository and adding the set of git commits from the previous lesson.\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nSoftware Carpentry: Version Control with Git"
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html#create-a-remote-repository",
    "href": "posts/2023-11-09-version-control-part-2/index.html#create-a-remote-repository",
    "title": "Version control (Part 2)",
    "section": "Create a remote repository",
    "text": "Create a remote repository\nLog in to GitHub, then click on the icon in the top right corner to create a new repository called planets.\n\nName your repository “planets” and then click “Create Repository”.\n\n\n\n\n\n\nNote\n\n\n\n\nSince this repository will be connected to a local repository, it needs to be empty.\nLeave “Initialize this repository with a README” unchecked, and keep “None” as options for both “Add .gitignore” and “Add a license.”\nSee the “GitHub License and README files” exercise in the Software Carpentry materials for a full explanation of why the repository needs to be empty.\n\n\n\n\nAs soon as the repository is created, GitHub displays a page with a URL and some information on how to configure your local repository\n\nThis effectively does the following on GitHub’s servers:\nmkdir planets\ncd planets\ngit init\nIf you remember back to the previous lecture where we added and committed our earlier work on mars.txt, you can visualize that process in our local repository like this:\n\nNow that we have created the remote repository, we really have two repositories and this is the idea you should keep in mind:\n\n\n\n\n\n\n\nNote\n\n\n\nOur local repository still contains our earlier work on mars.txt, but the remote repository on GitHub appears empty as it does not contain any files yet.\n\n\nCheck that we still have our history of commits in the git repository from the previous lesson:\ncd ~/Desktop/planets\ngit log --oneline\nc687412 (HEAD -&gt; main) Ignore data files and the results folder.\n1507c2a Add some initial thoughts on spaceships\nad5b7d1 Discuss concerns about Mars' climate for Mummy\n75a0e21 Add concerns about effects of Mars' moons on Wolfman\ncf69058 Start notes on Mars as a base"
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html#connect-local-to-remote-repository",
    "href": "posts/2023-11-09-version-control-part-2/index.html#connect-local-to-remote-repository",
    "title": "Version control (Part 2)",
    "section": "Connect local to remote repository",
    "text": "Connect local to remote repository\nNow we connect the two repositories. We do this by making the GitHub repository a “remote” for the local repository. The home page of the repository on GitHub includes the URL string we need to identify it:\n\nClick on the ‘SSH’ link to change the protocol from HTTPS to SSH.\n\n\n\n\n\n\nHTTPS vs. SSH\n\n\n\nWe use SSH here because, while it requires some additional configuration, it is a security protocol widely used by many applications. The steps below describe SSH at a minimum level for GitHub. A supplemental lesson in the Software Carpentry materials discusses advanced setup and concepts of SSH and key pairs, and other material supplemental to git related SSH.\n\n\n\nCopy that URL from the browser, go into the local planets repository, and run this command:\ngit remote add origin git@github.com:&lt;username&gt;/planets.git\nMake sure to use the URL for your repository, i.e. your username.\norigin is a local name used to refer to the remote repository. It could be called anything, but origin is a convention that is often used by default in git and GitHub, so it’s helpful to stick with this unless there’s a reason not to.\nWe can check that the command has worked by running git remote -v:\ngit remote -v\norigin   git@github.com:stephaniehicks/planets.git (fetch)\norigin   git@github.com:stephaniehicks/planets.git (push)\nWe’ll discuss remotes in more detail in the next section, while talking about how they might be used for collaboration."
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html#ssh-background-and-setup",
    "href": "posts/2023-11-09-version-control-part-2/index.html#ssh-background-and-setup",
    "title": "Version control (Part 2)",
    "section": "SSH Background and Setup",
    "text": "SSH Background and Setup\nBefore you can connect to a remote repository, you need to set up a way for your computer to authenticate with GitHub so it knows it’s you trying to connect to your remote repository.\nThese sections below will not be covered in class, but you are encouraged to set up your SSH key pairs to make your lives easier using git/GitHub!\n\n\n\n\n\n\nWhat are SSH key pairs?\n\n\n\n\n\nWe are going to set up the method that is commonly used by many different services to authenticate access on the command line. This method is called Secure Shell Protocol (SSH). SSH is a cryptographic network protocol that allows secure communication between computers using an otherwise insecure network.\nSSH uses what is called a key pair. This is two keys that work together to validate access. One key is publicly known and called the public key, and the other key called the private key is kept private.\nWhat we will do now is the minimum required to set up the SSH keys and add the public key to a GitHub account.\nThe first thing we are going to do is check if this has already been done on the computer you are on. Because generally speaking, this setup only needs to happen once.\nWe will run the list command to check what key pairs already exist on your computer.\nls -al ~/.ssh\nYour output is going to look a little different depending on whether or not SSH has ever been set up on the computer you are using.\nIf you have not set up SSH on your computer, your output is\nls: cannot access '/c/Users/&lt;username&gt;/.ssh': No such file or directory\nIf SSH has been set up on the computer you’re using, the public and private key pairs will be listed. The file names are either id_ed25519 / id_ed25519.pub or id_rsa / id_rsa.pub depending on how the key pairs were set up. If they don’t exist yet, we use this command to create them.\n\n\n\n\n\n\n\n\n\nCreate an SSH key pair\n\n\n\n\n\nTo create an SSH key pair we use this command, where the -t option specifies which type of algorithm to use and -C attaches a comment to the key (here, your email):\nssh-keygen -t ed25519 -C \"myemail@email.com\"\nIf you are using a legacy system that doesn’t support the Ed25519 algorithm, use:\nssh-keygen -t rsa -b 4096 -C \"myemail@email.com\"\nGenerating public/private ed25519 key pair.\nEnter file in which to save the key (/c/Users/&lt;username&gt;/.ssh/id_ed25519):\nWe want to use the default file, so just press Enter.\nCreated directory '/c/Users/&lt;username&gt;/.ssh'.\nEnter passphrase (empty for no passphrase):\nNow, it is prompting for a passphrase. If you are using a lab laptop that other people sometimes have access to, create a passphrase. Be sure to use something memorable or save your passphrase somewhere, as there is no “reset my password” option. Alternatively, if you are using your own laptop, you can leave it empty.\nEnter same passphrase again:\nAfter entering the same passphrase a second time, you receive a confirmation that looks something like this:\nYour identification has been saved in /c/Users/&lt;username&gt;/.ssh/id_ed25519\nYour public key has been saved in /c/Users/&lt;username&gt;/.ssh/id_ed25519.pub\nThe key fingerprint is:\nSHA256:SMSPIStNyA00KPxuYu94KpZgRAYjgt9g4BA4kFy3g1o myemail@email.com\nThe key's randomart image is:\n+--[ED25519 256]--+\n|^B== o.          |\n|%*=.*.+          |\n|+=.E =.+         |\n| .=.+.o..        |\n|....  . S        |\n|.+ o             |\n|+ =              |\n|.o.o             |\n|oo+.             |\n+----[SHA256]-----+\nThe “identification” is actually the private key. You should never share it. The public key is appropriately named. The “key fingerprint” is a shorter version of a public key.\nNow that we have generated the SSH keys, we will find the SSH files when we check.\nls -al ~/.ssh\ndrwxr-xr-x 1 &lt;username&gt; 197121   0 Jul 16 14:48 ./\ndrwxr-xr-x 1 &lt;username&gt; 197121   0 Jul 16 14:48 ../\n-rw-r--r-- 1 &lt;username&gt; 197121 419 Jul 16 14:48 id_ed25519\n-rw-r--r-- 1 &lt;username&gt; 197121 106 Jul 16 14:48 id_ed25519.pub\n\n\n\n\n\n\n\n\n\nCopy the public key to GitHub\n\n\n\n\n\nNow we have a SSH key pair and we can run this command to check if GitHub can read our authentication.\nssh -T git@github.com\nThe authenticity of host 'github.com (192.30.255.112)' can't be established.\nRSA key fingerprint is SHA256:nThbg6kXUpJWGl7E1IGOCspRomTxdCARLviKw6E5SY8.\nThis key is not known by any other names\nAre you sure you want to continue connecting (yes/no/[fingerprint])? y\nPlease type 'yes', 'no' or the fingerprint: yes\nWarning: Permanently added 'github.com' (RSA) to the list of known hosts.\ngit@github.com: Permission denied (publickey).\nRight, we forgot that we need to give GitHub our public key!\nFirst, we need to copy the public key. Be sure to include the .pub at the end, otherwise you’re looking at the private key.\ncat ~/.ssh/id_ed25519.pub\nssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIDmRA3d51X0uu9wXek559gfn6UFNF69yZjChyBIU2qKI myemail@email.com\nNow, going to github.com, click on your profile icon in the top right corner to get the drop-down menu. Click “Settings,” then on the settings page, click “SSH and GPG keys,” on the left side “Account settings” menu. Click the “New SSH key” button on the right side. Now, you can add the title (e.g. using the title “MacBook Air” so you can remember where the original key pair files are located), paste your SSH key into the field, and click the “Add SSH key” to complete the setup.\nNow that we’ve set that up, let’s check our authentication again from the command line.\nssh -T git@github.com\nHi stephaniehicks! You've successfully authenticated, but GitHub does not provide shell access.\nGood! This output confirms that the SSH key works as intended. We are now ready to push our work to the remote repository."
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html#push-local-changes-to-a-remote",
    "href": "posts/2023-11-09-version-control-part-2/index.html#push-local-changes-to-a-remote",
    "title": "Version control (Part 2)",
    "section": "Push local changes to a remote",
    "text": "Push local changes to a remote\nAfter your authentication is setup, we can uuse this command to push the changes from our local repository to the repository on GitHub:\ngit push origin main\n\n\n\n\n\n\nPassphrases\n\n\n\nIf you set up a passphrase when setting up your SSH key pairs, it will prompt you for it. If you completed advanced settings for your authentication, it will not prompt for a passphrase.\n\n\nEnumerating objects: 16, done.\nCounting objects: 100% (16/16), done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (11/11), done.\nWriting objects: 100% (16/16), 1.45 KiB | 372.00 KiB/s, done.\nTotal 16 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), done.\nTo https://github.com/stephaniehicks/planets.git\n * [new branch]      main -&gt; main\n\n\n\n\n\n\nProxy\n\n\n\nIf the network you are connected to uses a proxy, there is a chance that your last command failed with “Could not resolve hostname” as the error message.\nTo solve this issue, you need to tell Git about the proxy using git config --global.\nSee the Software Carpentry materials for details.\n\n\n\n\n\n\n\n\nPassword Managers\n\n\n\nIf your operating system has a password manager configured, git push will try to use it when it needs your username and password. For example, this is the default behavior for Git Bash on Windows. If you want to type your username and password at the terminal instead of using a password manager, type:\nunset SSH_ASKPASS\nin the terminal, before you run git push.\n\n\nOK, so now that have we used git push, our local and remote repositories are now in this state:\n\n\n\n\n\n\n\nThe -u Flag\n\n\n\nYou may see a -u option used with git push in some documentation. This option is synonymous with the --set-upstream-to option for the git branch command, and is used to associate the current branch with a remote branch so that the git pull command can be used without any arguments.\nTo do this, use git push -u origin main once the remote has been set up.\n\n\nWe can pull changes from the remote repository to the local one as well:\ngit pull origin main\nFrom https://github.com/stephaniehicks/planets\n * branch            main     -&gt; FETCH_HEAD\nAlready up-to-date.\nPulling has no effect in this case because the two repositories are already synchronized. If someone else had pushed some changes to the repository on GitHub, though, this command would download them to our local repository.\n\n\n\n\n\n\nKey Points\n\n\n\n\nA local Git repository can be connected to one or more remote repositories.\nUse the SSH protocol to connect to remote repositories.\ngit push copies changes from a local repository to a remote repository.\ngit pull copies changes from a remote repository to a local repository."
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html#exercises",
    "href": "posts/2023-11-09-version-control-part-2/index.html#exercises",
    "title": "Version control (Part 2)",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nGitHub GUI\n\n\n\n\n\nBrowse to your planets repository on GitHub. Under the Code tab, find and click on the text that says “XX commits” (where “XX” is some number). Hover over, and click on, the three buttons to the right of each commit. What information can you gather/explore from these buttons? How would you get that same information in the shell?\n\nThe left-most button (with the picture of a clipboard) copies the full identifier of the commit to the clipboard. In the shell, git log will show you the full commit identifier for each commit.\nWhen you click on the middle button, you’ll see all of the changes that were made in that particular commit. Green shaded lines indicate additions and red ones removals. In the shell we can do the same thing with git diff. In particular, git diff ID1..ID2 where ID1 and ID2 are commit identifiers (e.g. git diff a3bf1e5..041e637) will show the differences between those two commits.\nThe right-most button lets you view all of the files in the repository at the time of that commit. To do this in the shell, we’d need to checkout the repository at that particular time. We can do this with git checkout ID where ID is the identifier of the commit we want to look at. If we do this, we need to remember to put the repository back to the right state afterwards!\n\n\n\n\n\n\n\n\n\n\nUploading files directly in GitHub browser\n\n\n\n\n\nGithub also allows you to skip the command line and upload files directly to your repository without having to leave the browser. There are two options. First you can click the “Upload files” button in the toolbar at the top of the file tree. Or, you can drag and drop files from your desktop onto the file tree. You can read more about this in the GitHub help pages.\n\n\n\n\n\n\n\n\n\nGitHub Timestamp\n\n\n\n\n\nCreate a remote repository on GitHub. Push the contents of your local repository to the remote. Make changes to your local repository and push these changes. Go to the repo you just created on GitHub and check the timestamps of the files. How does GitHub record times, and why?\n\nGitHub displays timestamps in a human readable relative format (i.e. “22 hours ago” or “three weeks ago”). However, if you hover over the timestamp, you can see the exact time at which the last change to the file occurred.\n\n\n\n\n\n\n\n\n\n\nPush vs. Commit\n\n\n\n\n\nIn this lesson, we introduced the git push command. How is git push different from git commit?\n\nWhen we push changes, we’re interacting with a remote repository to update it with the changes we’ve made locally (often this corresponds to sharing the changes we’ve made with others). Commit only updates your local repository.\n\n\n\n\n\n\n\n\n\n\nGitHub License and README files\n\n\n\n\n\nIn this lesson we learned about creating a remote repository on GitHub, but when you initialized your GitHub repo, you didn’t add a README.md or a license file. If you had, what do you think would have happened when you tried to link your local and remote repositories?\n\nIn this case, we’d see a “merge conflict” due to unrelated histories. When GitHub creates a README.md file, it performs a commit in the remote repository. When you try to pull the remote repository to your local repository, Git detects that they have histories that do not share a common origin and refuses to merge.\n\ngit pull origin main\nwarning: no common commits\nremote: Enumerating objects: 3, done.\nremote: Counting objects: 100% (3/3), done.\nremote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\nUnpacking objects: 100% (3/3), done.\nFrom https://github.com/stephaniehicks/planets\n * branch            main     -&gt; FETCH_HEAD\n * [new branch]      main     -&gt; origin/main\nfatal: refusing to merge unrelated histories\nYou can force git to merge the two repositories with the option --allow-unrelated-histories. Be careful when you use this option and carefully examine the contents of local and remote repositories before merging.\ngit pull --allow-unrelated-histories origin main\nFrom https://github.com/stephaniehicks/planets\n * branch            main     -&gt; FETCH_HEAD\nMerge made by the 'recursive' strategy.\nREADME.md | 1 +\n1 file changed, 1 insertion(+)\ncreate mode 100644 README.md"
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html#exercises-1",
    "href": "posts/2023-11-09-version-control-part-2/index.html#exercises-1",
    "title": "Version control (Part 2)",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nSwitch Roles and Repeat\n\n\n\n\n\nSwitch roles and repeat the whole process.\n\n\n\n\n\n\n\n\n\nReview Changes\n\n\n\n\n\nThe Owner pushed commits to the repository without giving any information to the Collaborator. How can the Collaborator find out what has changed with command line? And on GitHub?\n\nOn the command line, the Collaborator can use git fetch origin main to get the remote changes into the local repository, but without merging them. Then by running git diff main origin/main the Collaborator will see the changes output in the terminal.\nOn GitHub, the Collaborator can go to the repository and click on “commits” to view the most recent commits pushed to the repository.\n\n\n\n\n\n\n\n\n\n\nComment Changes in GitHub\n\n\n\n\n\nThe Collaborator has some questions about one line change made by the Owner and has some suggestions to propose.\nWith GitHub, it is possible to comment on the diff of a commit. Over the line of code to comment, a blue comment icon appears to open a comment window.\nThe Collaborator posts their comments and suggestions using the GitHub interface."
  },
  {
    "objectID": "posts/2023-11-09-version-control-part-2/index.html#exercises-2",
    "href": "posts/2023-11-09-version-control-part-2/index.html#exercises-2",
    "title": "Version control (Part 2)",
    "section": "Exercises",
    "text": "Exercises\n\n\n\n\n\n\nConflicts on Non-textual files\n\n\n\n\n\nWhat does Git do when there is a conflict in an image or some other non-textual file that is stored in version control (e.g. mars.jpg)?\n\nGit will return an additional warning in the merge conflict message:\n\nwarning: Cannot merge binary files: mars.jpg (HEAD vs. 439dc8c08869c342438f6dc4a2b615b05b93c76e)\nGit cannot automatically insert conflict markers into an image as it does for text files. So, instead of editing the image file, we must check out the version we want to keep. Then we can add and commit this version.\nWe can also keep both images if we give them different filenames and then add and commit them.\n\n\n\n\n\n\n\n\n\nA Typical Work Session\n\n\n\n\n\nA short example of a typical workflow in an order that will minimize merge conflicts:\n\nUpdate local repo: git pull origin main\nMake changes: e.g. echo 100 &gt;&gt; numbers.txt\nStage changes: git add numbers.txt\nCommit changes: git commit -m \"Add 100 to numbers.txt\"\nUpdate remote: git push origin main"
  },
  {
    "objectID": "posts/2023-11-28-purrr-fun-programming/index.html",
    "href": "posts/2023-11-28-purrr-fun-programming/index.html",
    "title": "Functional Programming with purrr",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://adv-r.hadley.nz/functionals.html\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/purrr.pdf\n\n\n\n\n\n\nBefore starting you must install the additional package:\n\npurrr - this provides a consistent functional programming interface to work with functions and vectors\n\nYou can do this by calling\n\ninstall.packages(\"purrr\")\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://adv-r.hadley.nz/fp.html\nhttps://adv-r.hadley.nz/functionals.html\nhttps://raw.githubusercontent.com/rstudio/cheatsheets/main/purrr.pdf"
  },
  {
    "objectID": "posts/2023-11-28-purrr-fun-programming/index.html#functional-programming-language",
    "href": "posts/2023-11-28-purrr-fun-programming/index.html#functional-programming-language",
    "title": "Functional Programming with purrr",
    "section": "Functional programming language",
    "text": "Functional programming language\nA functional style of programming is contrast to a the formal definition of a functional language (or functional programming, which can be complementary to object-oriented programming), which are languages that use functions to create conditional expressions to perform specific computations.\n\n\n\n\n\n\nDifferences between functional and object-oriented programming\n\n\n\nFrom this resource some differences are:\n\nBasic elements: The fundamental elements of object-oriented languages are objects and methods, while the elements of functional programming are functions and variables.\nStates: Object-oriented languages can change objects within the program, which means it has states or current modifications that affect the result of inputs. Functional languages do not use imperative programming, so they do not keep track of current states.\nParallel programming: This type of programming involves multiple computational processes occurring at the same time. Object-oriented languages have little support for parallel programming, but functional languages have extensive support for it.\nOrder: In object-oriented programming, computations occur in a specific order. In functional programming, computations can occur in any order.\nIterative data: Object-oriented programming uses loops, meaning repeated execution, for iterative data. Functional programming uses recursion for iterative data, meaning it attempts to solve problems using simpler versions of the same problem.\n\n\n\nA traditional weakness of functional languages are poorer performance and sometimes unpredictable memory usage, but these have been much reduced in recent years."
  },
  {
    "objectID": "posts/2023-11-28-purrr-fun-programming/index.html#characteristics-of-a-functional-language",
    "href": "posts/2023-11-28-purrr-fun-programming/index.html#characteristics-of-a-functional-language",
    "title": "Functional Programming with purrr",
    "section": "Characteristics of a functional language",
    "text": "Characteristics of a functional language\nThere are many definitions for precisely what makes a language functional, but there are two common threads and/or characteristics.\n\n1. First-class functions\nAt it is core, functional programming treats functions equally as other data structures, called first class functions.\n\nIn R, this means that you can do many of the things with a function that you can do with a vector: you can assign them to variables, store them in lists, pass them as arguments to other functions, create them inside functions, and even return them as the result of a function.\n\n\n\n\n\n\n\nExamples of cool things you can do with functions in R\n\n\n\n\nAssign a function to a variable (foo):\n\n\nfoo &lt;- function(){\n  return(\"This is foo.\")\n}\nclass(foo)\n\n[1] \"function\"\n\nfoo\n\nfunction(){\n  return(\"This is foo.\")\n}\n\nfoo()\n\n[1] \"This is foo.\"\n\n\n\nYou can store functions in a list:\n\n\nfoo_list &lt;- list( \n  fun_1 = function() return(\"foo_1\"),\n  fun_2 = function() return(\"foo_2\")\n)\n\nstr(foo_list)\n\nList of 2\n $ fun_1:function ()  \n  ..- attr(*, \"srcref\")= 'srcref' int [1:8] 2 11 2 36 11 36 2 2\n  .. ..- attr(*, \"srcfile\")=Classes 'srcfilecopy', 'srcfile' &lt;environment: 0x10c9994f8&gt; \n $ fun_2:function ()  \n  ..- attr(*, \"srcref\")= 'srcref' int [1:8] 3 11 3 36 11 36 3 3\n  .. ..- attr(*, \"srcfile\")=Classes 'srcfilecopy', 'srcfile' &lt;environment: 0x10c9994f8&gt; \n\nfoo_list$fun_1()\n\n[1] \"foo_1\"\n\nfoo_list$fun_2()\n\n[1] \"foo_2\"\n\n\n\nYou can pass functions as arguments to other functions:\n\n\nshell_fn &lt;- function(f) f()\nshell_fn(foo_list$fun_1)\n\n[1] \"foo_1\"\n\nshell_fn(foo_list$fun_2)\n\n[1] \"foo_2\"\n\n\n\nYou can create functions inside of functions and return them as the result of a function\n\n\nfoo_wrap &lt;- function(){\n  foo_2 &lt;- function(){\n    return(\"This is foo_2.\")\n  }\n  return(foo_2)\n}\n\nfoo_wrap()\n\nfunction(){\n    return(\"This is foo_2.\")\n  }\n&lt;environment: 0x10d049120&gt;\n\n(foo_wrap())()\n\n[1] \"This is foo_2.\"\n\n\nThe bottom line, you can manipulate functions as the same way as you can to a vector or a matrix.\n\n\n\n\n2. Pure functions\nA function is pure, if it satisfies two properties:\n\nThe output only depends on the inputs, i.e. if you call it again with the same inputs, you get the same outputs. This excludes functions like runif(), read.csv(), or Sys.time() that can return different values.\nThe function has no side-effects, like changing the value of a global variable, writing to disk, or displaying to the screen. This excludes functions like print(), write.csv() and &lt;-.\n\nPure functions are much easier to reason about, but obviously have significant downsides: imagine doing a data analysis where you could not generate random numbers or read files from disk.\n\n\n\n\n\n\nImportant\n\n\n\nTo be clear, R is not formally a functional programming language as it does not require pure functions to be used when writing code.\n\n\nSo you might be asking yourself, why are we talking about this then?\nThe formal definition of a functional programming language introduces a new style of programming, namely a functional style of programming.\n\n\n\n\n\n\nNote\n\n\n\nThe key idea of a functional style is this programming style encourages programmers to write a big function as many smaller isolated functions, where each function addresses one specific task.\n\n\nYou can always adopt a functional style for certain parts of your code! For example, this style of writing code motivates more humanly readable code, and recyclable code.\n\n\"data_set.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()\n\n\"data_set2.csv\" |&gt; \n  import_data_from_file() |&gt; \n  data_cleaning() |&gt; \n  run_different_regression() |&gt;\n  model_diagnostics() |&gt;\n  model_visualization()"
  },
  {
    "objectID": "posts/2023-11-28-purrr-fun-programming/index.html#functional-style",
    "href": "posts/2023-11-28-purrr-fun-programming/index.html#functional-style",
    "title": "Functional Programming with purrr",
    "section": "Functional style",
    "text": "Functional style\nAt a high-level, a functional style is the concept of decomposing a big problem into smaller components, then solving each piece with a function or combination of functions.\n\nWhen using a functional style, you strive to decompose components of the problem into isolated functions that operate independently.\nEach function taken by itself is simple and straightforward to understand; complexity is handled by composing functions in various ways.\n\n\nFunctionals\nIn this lecture, we will focus on one type of functional technique, namely functionals, which are functions that take another function as an argument and returns a vector as output.\nFunctionals allow you to take a function that solves the problem for a single input and generalize it to handle any number of inputs. Once you learn about them, you will find yourself using them all the time in data analysis.\n\n\n\n\n\n\nExample of a functional\n\n\n\nHere’s a simple functional: it calls the function provided as input with 1000 random uniform numbers.\n\nrandomise &lt;- function(f) f(runif(1e3))\nrandomise(mean)\n\n[1] 0.5055154\n\nrandomise(mean)\n\n[1] 0.5032077\n\nrandomise(sum)\n\n[1] 507.0181\n\n\n\n\nThe chances are that you have already used a functional. You might have used for-loop replacements like base R’s lapply(), apply(), and tapply() or maybe you have used a mathematical functional like integrate() or optim().\nOne of the most common use of functionals is an alternative to for loops.\nFor loops have a bad rap in R because many people believe they are slow, but the real downside of for loops is that they’re very flexible: a loop conveys that you’re iterating, but not what should be done with the results.\n\n\nTypically it is not the for loop itself that is slow, but what you are doing inside of it. A common culprit of slow loops is modifying a data structure, where each modification generates a copy.\nIf you’re an experienced for loop user, switching to functionals is typically a pattern matching exercise. You look at the for loop and find a functional that matches the basic form. If one does not exist, do not try and torture an existing functional to fit the form you need. Instead, just leave it as a for loop! (Or once you have repeated the same loop two or more times, maybe think about writing your own functional).\nJust as it is better to use while than repeat, and it’s better to use for than while, it is better to use a functional than for.\nEach functional is tailored for a specific task, so when you recognize the functional you immediately know why it’s being used."
  },
  {
    "objectID": "posts/2023-11-28-purrr-fun-programming/index.html#the-map-family",
    "href": "posts/2023-11-28-purrr-fun-programming/index.html#the-map-family",
    "title": "Functional Programming with purrr",
    "section": "The map family",
    "text": "The map family\nThe most fundamental functional in the purrr package is the map(.x, .f) function. It takes a vector (.x) and a function (.f), calls the function once for each element of the vector, and returns the results in a list. In other words, map(1:3, f) is equivalent to list(f(1), f(2), f(3)).\n\nlibrary(purrr)\n\n# we create a function called \"triple\"\ntriple &lt;- function(x) x * 3\n\n# using for loop to iterate over a vector\nloop_ret &lt;- list()\nfor(i in 1:3){\n  loop_ret[i] &lt;- triple(i)\n}\nloop_ret\n\n[[1]]\n[1] 3\n\n[[2]]\n[1] 6\n\n[[3]]\n[1] 9\n\n\n\n# map implementation to iterate over a vector\nmap_eg1 &lt;- map(.x = 1:3, .f = triple)\nmap_eg2 &lt;- map(.x = 1:3, .f = function(x) triple(x)) # create an inline anonymous function\nmap_eg3 &lt;- map(.x = 1:3, .f = ~triple(.x)) # same as above, but special purrr syntax with a \"twiddle\"\n\n\nidentical(loop_ret,map_eg1)\n\n[1] TRUE\n\nidentical(loop_ret,map_eg2)\n\n[1] TRUE\n\nidentical(loop_ret,map_eg3)\n\n[1] TRUE\n\n\nOr, graphically this is what map() is doing:\n\n\n\n\n\n\n\n\n\n\n\nHow does map relate to functional programming in base R?\n\n\n\nmap() returns a list, which makes it the most general of the map family because you can put anything in a list.\nThe base equivalent to map(.x, .f) is lapply(X, FUN).\nBecause the arguments include functions (.f) besides data (.x), map() functions are considered as a convenient interface to implement functional programming.\n\n\n\nmap variants\nSometimes it is inconvenient to return a list when a simpler data structure would do, so there are four more specific variants of map that make it really a family of functions (of syntax map_*()).\n\nmap_lgl()\nmap_int()\nmap_dbl()\nmap_chr()\n\nFor example, purrr uses the convention that suffixes, like _dbl(), refer to the output. Each returns an atomic vector of the specified type:\n\n# map_chr() always returns a character vector\nmap_chr(.x = mtcars, .f = typeof)\n\n     mpg      cyl     disp       hp     drat       wt     qsec       vs \n\"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \"double\" \n      am     gear     carb \n\"double\" \"double\" \"double\" \n\n# map_lgl() always returns a logical vector\nmap_lgl(.x = mtcars, .f = is.double)\n\n mpg  cyl disp   hp drat   wt qsec   vs   am gear carb \nTRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE \n\n# map_int() always returns a integer vector\nn_unique &lt;- function(x) length(unique(x))\nmap_int(.x = mtcars, .f = n_unique)\n\n mpg  cyl disp   hp drat   wt qsec   vs   am gear carb \n  25    3   27   22   22   29   30    2    2    3    6 \n\n# map_dbl() always returns a double vector\nmap_dbl(.x = mtcars, .f = mean)\n\n       mpg        cyl       disp         hp       drat         wt       qsec \n 20.090625   6.187500 230.721875 146.687500   3.596563   3.217250  17.848750 \n        vs         am       gear       carb \n  0.437500   0.406250   3.687500   2.812500 \n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nAll map_*() functions can take any type of vector as input. The examples above rely on two facts:\n\nmtcars is a data.frame. In R, data.frame is a special case of list, where each column as one item of the list. Don’t confuse with each row as an item.\n\n\nclass(mtcars)\n\n[1] \"data.frame\"\n\ntypeof(mtcars)\n\n[1] \"list\"\n\n\n\nAll map functions always return an output vector the same length as the input, which implies that each call to .f must return a single value. If it does not, you will get an error:\n\n\npair &lt;- function(x) c(x, x)\nmap_dbl(.x = 1:2, .f = pair)\n\nError in `map_dbl()`:\nℹ In index: 1.\nCaused by error:\n! Result must be length 1, not 2.\n\n\nThis is similar to the error you will get if .f returns the wrong type of result:\n\nmap_dbl(1:2, as.character)\n\nError in `map_dbl()`:\nℹ In index: 1.\nCaused by error:\n! Can't coerce from a string to a double.\n\n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s assume I have a dataframe called tmp_dat. How would I use map() to calculate the mean for the columns?\n\ntmp_dat &lt;- data.frame(\n  x = 1:5,\n  y = 6:10\n)\n\n\n## try it out \n\n\n\n\n\n\n\n\n\nQuestion\n\n\n\nCan we re-write the map() function above to use tmp_data as input with the |&gt; operator?\n\n## try it out \n\n\n\n\n\nPassing arguments with ...\nIt is often convenient to pass along additional arguments to the function that you are calling.\nFor example, you might want to pass na.rm = TRUE along to mean(). One way to do that is with an anonymous function:\n\nx &lt;- list(1:5, c(1:10, NA))\nmap_dbl(x, ~ mean(.x, na.rm = TRUE))\n\n[1] 3.0 5.5\n\n\nBut because the map functions pass ... along, there is a simpler form available:\n\nmap_dbl(x, mean, na.rm = TRUE)\n\n[1] 3.0 5.5\n\n\nThis is easiest to understand with a picture: any arguments that come after f in the call to map() are inserted after the data in individual calls to f():\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt’s important to note that these arguments are not decomposed; or said another way, map() is only vectorised over its first argument.\nIf an argument after f is a vector, it will be passed along as is:\n\n\n\n\n\n\n\n\n\nStratified analysis with map\nBefore we go on to explore more map variants, let’s take a quick look at how you tend to use multiple purrr functions to solve a moderately realistic problem: fitting a model to each subgroup and extracting a coefficient of the model.\nFor this toy example, I will break the mtcars data set down into groups defined by the number of cylinders, using the base split function:\n\n# different numbers of cylinders\nunique(mtcars$cyl) \n\n[1] 6 4 8\n\n\n\nby_cyl &lt;- split(mtcars, mtcars$cyl)\nlength(by_cyl)\n\n[1] 3\n\nstr(by_cyl)\n\nList of 3\n $ 4:'data.frame':  11 obs. of  11 variables:\n  ..$ mpg : num [1:11] 22.8 24.4 22.8 32.4 30.4 33.9 21.5 27.3 26 30.4 ...\n  ..$ cyl : num [1:11] 4 4 4 4 4 4 4 4 4 4 ...\n  ..$ disp: num [1:11] 108 146.7 140.8 78.7 75.7 ...\n  ..$ hp  : num [1:11] 93 62 95 66 52 65 97 66 91 113 ...\n  ..$ drat: num [1:11] 3.85 3.69 3.92 4.08 4.93 4.22 3.7 4.08 4.43 3.77 ...\n  ..$ wt  : num [1:11] 2.32 3.19 3.15 2.2 1.61 ...\n  ..$ qsec: num [1:11] 18.6 20 22.9 19.5 18.5 ...\n  ..$ vs  : num [1:11] 1 1 1 1 1 1 1 1 0 1 ...\n  ..$ am  : num [1:11] 1 0 0 1 1 1 0 1 1 1 ...\n  ..$ gear: num [1:11] 4 4 4 4 4 4 3 4 5 5 ...\n  ..$ carb: num [1:11] 1 2 2 1 2 1 1 1 2 2 ...\n $ 6:'data.frame':  7 obs. of  11 variables:\n  ..$ mpg : num [1:7] 21 21 21.4 18.1 19.2 17.8 19.7\n  ..$ cyl : num [1:7] 6 6 6 6 6 6 6\n  ..$ disp: num [1:7] 160 160 258 225 168 ...\n  ..$ hp  : num [1:7] 110 110 110 105 123 123 175\n  ..$ drat: num [1:7] 3.9 3.9 3.08 2.76 3.92 3.92 3.62\n  ..$ wt  : num [1:7] 2.62 2.88 3.21 3.46 3.44 ...\n  ..$ qsec: num [1:7] 16.5 17 19.4 20.2 18.3 ...\n  ..$ vs  : num [1:7] 0 0 1 1 1 1 0\n  ..$ am  : num [1:7] 1 1 0 0 0 0 1\n  ..$ gear: num [1:7] 4 4 3 3 4 4 5\n  ..$ carb: num [1:7] 4 4 1 1 4 4 6\n $ 8:'data.frame':  14 obs. of  11 variables:\n  ..$ mpg : num [1:14] 18.7 14.3 16.4 17.3 15.2 10.4 10.4 14.7 15.5 15.2 ...\n  ..$ cyl : num [1:14] 8 8 8 8 8 8 8 8 8 8 ...\n  ..$ disp: num [1:14] 360 360 276 276 276 ...\n  ..$ hp  : num [1:14] 175 245 180 180 180 205 215 230 150 150 ...\n  ..$ drat: num [1:14] 3.15 3.21 3.07 3.07 3.07 2.93 3 3.23 2.76 3.15 ...\n  ..$ wt  : num [1:14] 3.44 3.57 4.07 3.73 3.78 ...\n  ..$ qsec: num [1:14] 17 15.8 17.4 17.6 18 ...\n  ..$ vs  : num [1:14] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ am  : num [1:14] 0 0 0 0 0 0 0 0 0 0 ...\n  ..$ gear: num [1:14] 3 3 3 3 3 3 3 3 3 3 ...\n  ..$ carb: num [1:14] 2 4 3 3 3 4 4 4 2 2 ...\n\n\nThis creates a list of three data frames: the cars with 4, 6, and 8 cylinders respectively.\nFirst, imagine we want to fit a linear model to understand how the miles per gallon (mpg) associated with the weight (wt). We can do this for all observations in mtcars using:\n\nlm(mpg ~ wt, data = mtcars)\n\n\nCall:\nlm(formula = mpg ~ wt, data = mtcars)\n\nCoefficients:\n(Intercept)           wt  \n     37.285       -5.344  \n\n\nThe following code shows how you might do that with purrr, which returns a list with output from each lm fit for each cylinder:\n\nby_cyl |&gt;\n  map(.f = ~ lm(mpg ~ wt, data = .x))\n\n$`4`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n     39.571       -5.647  \n\n\n$`6`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n      28.41        -2.78  \n\n\n$`8`\n\nCall:\nlm(formula = mpg ~ wt, data = .x)\n\nCoefficients:\n(Intercept)           wt  \n     23.868       -2.192  \n\n\n\n\n\n\n\n\nQuestion\n\n\n\nLet’s say we wanted to extract the second coefficient (i.e. the slope). Using all the observations in mtcars (i.e. ignoring cyl), it would be something like this:\n\nlm.fit &lt;- lm(mpg ~ wt, data = mtcars)\ncoef(lm.fit)\n\n(Intercept)          wt \n  37.285126   -5.344472 \n\ncoef(lm.fit)[2]\n\n       wt \n-5.344472 \n\n\nHow would we do this with the map() family functions if we wanted to stratify the analysis for each cyl?\nHint: you can use two map functions (e.g. map() and map_dbl(2) where you can extract a specific element by a specific name or position).\n\n## try it out \n\n\n\nOr, of course, you could use a for loop:\n\nslopes &lt;- double(length(by_cyl))\nfor (i in seq_along(by_cyl)) {\n  model &lt;- lm(mpg ~ wt, data = by_cyl[[i]])\n  slopes[[i]] &lt;- coef(model)[[2]]\n}\nslopes\n\n[1] -5.647025 -2.780106 -2.192438\n\n\nIt’s interesting to note that as you move from purrr to base apply functions to for loops you tend to do more and more in each iteration.\nIn purrr we iterate 3 times (map(), map(), map_dbl()), and with a for loop we iterate once. I prefer more, but simpler, steps because I think it makes the code easier to understand and later modify.\n\n\n\n\n\n\nQuestion\n\n\n\nNow we are interested in calculating the average mpg for vehicles with different numbers of cylinders. How can we use map functions to do this? You can return a list.\nHint: You can use the syntax x$mpg where x is a dataframe within a map function.\n\n## try it out \n\n\n\n\n\nMatrix as the output\nThe map family include functions that organize the output in different data structures, whose names follow the pattern map_*. As we’ve seen, the map function return a list. The following functions will return a vector of a specific kind, e.g. map_lgl returns a vector of logical variables, map_chr returns a vector of strings.\nIt is also possible to return the the results as data frames by\n\nrow binding (map_dfr) or\ncolumn binding (map_dfc)\n\n\nby_cyl |&gt; \n  map_dbl(.f = ~mean(.x$mpg)) # returns a vector of doubles\n\n       4        6        8 \n26.66364 19.74286 15.10000 \n\nby_cyl |&gt; \n  map_dfr(.f = ~colMeans(.x)) # return a data frame by row binding\n\n# A tibble: 3 × 11\n    mpg   cyl  disp    hp  drat    wt  qsec    vs    am  gear  carb\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  26.7     4  105.  82.6  4.07  2.29  19.1 0.909 0.727  4.09  1.55\n2  19.7     6  183. 122.   3.59  3.12  18.0 0.571 0.429  3.86  3.43\n3  15.1     8  353. 209.   3.23  4.00  16.8 0     0.143  3.29  3.5 \n\nby_cyl |&gt; \n  map_dfc(.f = ~colMeans(.x)) # return a data frame by col binding\n\n# A tibble: 11 × 3\n       `4`     `6`     `8`\n     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1  26.7    19.7    15.1  \n 2   4       6       8    \n 3 105.    183.    353.   \n 4  82.6   122.    209.   \n 5   4.07    3.59    3.23 \n 6   2.29    3.12    4.00 \n 7  19.1    18.0    16.8  \n 8   0.909   0.571   0    \n 9   0.727   0.429   0.143\n10   4.09    3.86    3.29 \n11   1.55    3.43    3.5"
  },
  {
    "objectID": "posts/2023-11-28-purrr-fun-programming/index.html#more-map-variants",
    "href": "posts/2023-11-28-purrr-fun-programming/index.html#more-map-variants",
    "title": "Functional Programming with purrr",
    "section": "More map variants",
    "text": "More map variants\nThere are 23 primary variants of map(). So far, we have learned about five (map(), map_lgl(), map_int(), map_dbl() and map_chr()). That means that you have got 18 (!!) more to learn. That sounds like a lot, but fortunately the design of purrr means that you only need to learn five new ideas:\n\nOutput same type as input with modify()\nIterate over two inputs with map2().\nIterate with an index using imap()\nReturn nothing with walk().\nIterate over any number of inputs with pmap().\n\nThe map family of functions has orthogonal input and outputs, meaning that we can organise all the family into a matrix, with inputs in the rows and outputs in the columns. Once you have mastered the idea in a row, you can combine it with any column; once you have mastered the idea in a column, you can combine it with any row. That relationship is summarised in the following table:\n\n\n\n\n\n\n\n\n\n\n\nList\nAtomic\nSame type\nNothing\n\n\n\n\nOne argument\nmap()\nmap_lgl(), …\nmodify()\nwalk()\n\n\nTwo arguments\nmap2()\nmap2_lgl(), …\nmodify2()\nwalk2()\n\n\nOne argument + index\nimap()\nimap_lgl(), …\nimodify()\niwalk()\n\n\nN arguments\npmap()\npmap_lgl(), …\n—\npwalk()\n\n\n\n\nmodify()\nImagine you wanted to double every column in a data frame. You might first try using map(), but map() always returns a list:\n\ndf &lt;- data.frame(\n  x = 1:3,\n  y = 6:4\n)\n\nmap(df, ~ .x * 2)\n\n$x\n[1] 2 4 6\n\n$y\n[1] 12 10  8\n\n\nIf you want to keep the output as a data frame, you can use modify(), which always returns the same type of output as the input:\n\nmodify(df, ~ .x * 2)\n\n  x  y\n1 2 12\n2 4 10\n3 6  8\n\n\n\n\n\n\n\n\nNote\n\n\n\nDespite the name, modify() doesn’t modify in place, it returns a modified copy, so if you wanted to permanently modify df, you’d need to assign it:\n\ndf &lt;- modify(df, ~ .x * 2)\n\n\n\n\n\nmap2() and friends\nmap() is vectorised over a single argument, .x.\nThis means it only varies .x when calling .f, and all other arguments are passed along unchanged, thus making it poorly suited for some problems.\nFor example, how would you find a weighted mean when you have a list of observations and a list of weights? Imagine we have the following data:\n\nxs &lt;- map(1:8, ~ runif(10))\nxs[[1]][[1]] &lt;- NA\nws &lt;- map(1:8, ~ rpois(10, 5) + 1)\n\nYou can use map_dbl() to compute the unweighted means:\n\nmap_dbl(.x = xs, .f = mean)\n\n[1]        NA 0.6596358 0.6001102 0.3955773 0.4220107 0.6470785 0.2633766\n[8] 0.6809399\n\n\nBut passing ws as an additional argument does not work because arguments after .f are not transformed:\n\nmap_dbl(x. = xs, .f = weighted.mean, w = ws)\n\nError in map_dbl(x. = xs, .f = weighted.mean, w = ws): argument \".x\" is missing, with no default\n\n\nWe need a new tool: a map2(), which is vectorised over two arguments. This means both .x and .y are varied in each call to .f:\n\nmap2_dbl(.x = xs, .y = ws, .f = weighted.mean)\n\n[1]        NA 0.6461823 0.5858559 0.3832126 0.4033124 0.6399419 0.2586362\n[8] 0.6835747\n\n\nThe arguments to map2() are slightly different to the arguments to map() as two vectors come before the function, rather than one. Additional arguments still go afterwards:\n\nmap2_dbl(.x = xs, .y = ws, .f = weighted.mean, na.rm = TRUE)\n\n[1] 0.5480634 0.6461823 0.5858559 0.3832126 0.4033124 0.6399419 0.2586362\n[8] 0.6835747\n\n\n\n\nwalk() and friends\nMost functions are called for the value that they return, so it makes sense to capture and store the value with a map() function.\nBut some functions are called primarily for their side-effects (e.g. cat(), write.csv(), or ggsave()) and it does not make sense to capture their results.\nLet’s consider the example of saving a dataset. In this case, map will force an output, e.g. NULL. One can consider using walk instead. The function walk (and walk2 for more than two inputs) behaves exactly the same as map but does not output anything.\n\ntmp_fldr &lt;- tempdir()\n\nmap2(.x = by_cyl,\n     .y = 1:length(by_cyl),\n     .f = ~saveRDS(.x, \n                   file = paste0(tmp_fldr, \"/\",.y, \".rds\"))\n)\n\n$`4`\nNULL\n\n$`6`\nNULL\n\n$`8`\nNULL\n\n# No output\nwalk2(.x = by_cyl,\n      .y = (1:length(by_cyl)),\n      .f = ~saveRDS(.x, \n                    file = paste0(tmp_fldr, \"/\",.y, \".rds\"))\n)"
  },
  {
    "objectID": "posts/2023-11-30-targets-proj-workflows/index.html",
    "href": "posts/2023-11-30-targets-proj-workflows/index.html",
    "title": "Reproducibile Workflows with targets",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://books.ropensci.org/targets/\nhttps://books.ropensci.org/targets/walkthrough.html\n\n\n\n\n\n\nBefore starting you must install the additional package:\n\ntargets - the R Workflows package\nusethis - an automation package that simplifies project creation and setup\nrenv - a package manager in R\n\nYou can do this by calling\n\ninstall.packages( c(\"usethis\", \"targets\", \"renv\"))\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://books.ropensci.org/targets/walkthrough.html"
  },
  {
    "objectID": "posts/2023-11-30-targets-proj-workflows/index.html#why-do-we-use-targets",
    "href": "posts/2023-11-30-targets-proj-workflows/index.html#why-do-we-use-targets",
    "title": "Reproducibile Workflows with targets",
    "section": "Why do we use targets?",
    "text": "Why do we use targets?\ntargets helps us be more efficient at managing analytic workflows, and hence improve productivity with bare minimum efforts. Let me simply put this way, managing file names for your code or saved objects can be very painful. But targets can help you handle that when use in combination with other version control system git."
  },
  {
    "objectID": "posts/2023-11-30-targets-proj-workflows/index.html#how-to-use-targets",
    "href": "posts/2023-11-30-targets-proj-workflows/index.html#how-to-use-targets",
    "title": "Reproducibile Workflows with targets",
    "section": "How to use targets",
    "text": "How to use targets\nThe {targets} R package user manual is a great source to learn how to use targets. The intro level of targets tutorial is well documented in Chapter 2 Walkthrough.\nInstead going through the chapter with you, I will focus on some tricks that is not discussed in the user manual."
  },
  {
    "objectID": "posts/2023-11-30-targets-proj-workflows/index.html#set-up-a-targets-workflow",
    "href": "posts/2023-11-30-targets-proj-workflows/index.html#set-up-a-targets-workflow",
    "title": "Reproducibile Workflows with targets",
    "section": "Set up a targets workflow",
    "text": "Set up a targets workflow\n\n# Start a new R project\nusethis::create_project(\"targets_eg\")\n# Config target workflow\ntargets::use_targets()\n\n\n(Optional) Version control packages with renv\n\n# Config renv system\nrenv::init()\ntargets::tar_renv()\n\nIf other people opens up this project on a different computer, renv will automatically install all the necessary packages, especially the same versions of those packages.\n\n\n\n\n\n\nImportant renv functions\n\n\n\nIdealistically, you need to keep track of your R packages in every analysis, similar to you version control your files using git. You may need to call the following functions periodically, i.e. after you add/remove necessary packages.\n\ntargets::tar_renv() updates _targets_packages.R by gathering all packages in your analytic workflow\nrenv::status() shows which packages are outdated or not recorded\nrenv::snapshot() updates your packages version number by taking a snapshot of your project library\nrenv::restore() restores all missing packages or packages whose version number doesn’t match with the most updated snapshot.\n\nFor more information, visit https://rstudio.github.io/renv/articles/renv.html"
  },
  {
    "objectID": "posts/2023-11-30-targets-proj-workflows/index.html#set-up-keyboard-shortcuts",
    "href": "posts/2023-11-30-targets-proj-workflows/index.html#set-up-keyboard-shortcuts",
    "title": "Reproducibile Workflows with targets",
    "section": "Set up keyboard shortcuts",
    "text": "Set up keyboard shortcuts\ntargets provide some addins to help users navigate through workflow management with a click-and-point system. For example, if you click on the Addins button in the tool bar (highlighted in the screen capture below) which locates on the top of the RStudio window, you can see many options that help you to work with targets\n\n\n\n\n\nA screenshot of addins for targets\n\n\n\n\nWith these addins, you don’t necessarily have to remember all the functions to run targets, such as targets::tar_make(), targets::tar_load(), targets::tar_visnetwork(), etc.\nIf you prefer keyboard shortcuts, you can set up for these commonly used functions. In order to do that, you need to go to Tools -&gt; Modify Keyboard Shortcuts.\n\n\n\n\n\nA screenshot of how to modify keyboard shortcuts\n\n\n\n\nWith in the pop-up keyboard shortcuts menu, you can search addin or targets or a specific target addin function, e.g. Load target at cursor in the search box. You can customize the keyboard shortcut by clicking on the input box within the Shortcut column.\n\n\n\n\n\nA screenshot of keyboard shortcuts menu"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html",
    "href": "posts/2023-12-07-relational-databases/index.html",
    "title": "Relational databases and SQL basics",
    "section": "",
    "text": "Read ahead\n\n\n\nBefore class, you can prepare by reading the following materials:\n\nhttps://dbi.r-dbi.org\nhttps://solutions.posit.co/connections/db/databases/sqlite/\nhttps://dbplyr.tidyverse.org\n\n\n\n\n\n\nMaterial for this lecture was borrowed and adopted from\n\nhttps://www.stephaniehicks.com/jhuads2021/posts/2021-12-06-sql-basics\nhttps://swcarpentry.github.io/sql-novice-survey"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#command-line-tool-sqlite3",
    "href": "posts/2023-12-07-relational-databases/index.html#command-line-tool-sqlite3",
    "title": "Relational databases and SQL basics",
    "section": "Command-line tool sqlite3",
    "text": "Command-line tool sqlite3\nFor this lecture, we will use Unix shell, plus SQLite3 or DB Browser for SQLite.\nYou can see if the command-line tool sqlite3 (also known as “SQLite”) is already installed with\n\nsqlite3 --version\n\n3.39.5 2022-10-14 20:58:05 554764a6e721fab307c63a4f98cd958c8428a5d9d8edfde951858d6fd02daapl\n\n\nIf not, you can install with homebrew or follow the instructions here:\n\nhttps://swcarpentry.github.io/sql-novice-survey/setup.html"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#r-packages",
    "href": "posts/2023-12-07-relational-databases/index.html#r-packages",
    "title": "Relational databases and SQL basics",
    "section": "R packages",
    "text": "R packages\nYou will need to install these R packages:\n\ninstall.packages(\"DBI\")\ninstall.packages(\"RSQLite\")\ninstall.packages(\"dbplyr\")\n\nWe will load them here before kicking off the lecture.\n\nlibrary(tidyverse)\nlibrary(DBI)\nlibrary(RSQLite)\nlibrary(dbplyr)"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#languages",
    "href": "posts/2023-12-07-relational-databases/index.html#languages",
    "title": "Relational databases and SQL basics",
    "section": "Languages",
    "text": "Languages\nWe write queries in a language called Structured Query Language (SQL), which provides hundreds of different ways to analyze and recombine data.\nMany database managers understand SQL but each stores data in a different way, so a database created with one cannot be used directly by another.\nHowever, every database manager can import and export data in a variety of formats like .csv, .sql, so it is possible to move information from one to another.\nNext, we will some example SQL queries that are common tasks for data scientists."
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#example-data",
    "href": "posts/2023-12-07-relational-databases/index.html#example-data",
    "title": "Relational databases and SQL basics",
    "section": "Example data",
    "text": "Example data\nBefore we get into using SQLite to select the data, let’s take a look at the tables of the database we will use in our examples:\n\n\nPerson: People who took readings, id being the unique identifier for that person.\n\n\n\nid\npersonal\nfamily\n\n\n\n\ndyer\nWilliam\nDyer\n\n\npb\nFrank\nPabodie\n\n\nlake\nAnderson\nLake\n\n\nroe\nValentina\nRoerich\n\n\ndanforth\nFrank\nDanforth\n\n\n\nSite: Locations of the sites where readings were taken.\n\n\n\nname\nlat\nlong\n\n\n\n\nDR-1\n-49.85\n-128.57\n\n\nDR-3\n-47.15\n-126.72\n\n\nMSK-4\n-48.87\n-123.4\n\n\n\nVisited: Specific identification id of the precise locations where readings were taken at the sites and dates.\n\n\n\nid\nsite\ndated\n\n\n\n\n619\nDR-1\n1927-02-08\n\n\n622\nDR-1\n1927-02-10\n\n\n734\nDR-3\n1930-01-07\n\n\n735\nDR-3\n1930-01-12\n\n\n751\nDR-3\n1930-02-26\n\n\n752\nDR-3\n-null-\n\n\n837\nMSK-4\n1932-01-14\n\n\n844\nDR-1\n1932-03-22\n\n\n\n\n\nSurvey: The measurements taken at each precise location on these sites. They are identified as taken. The field quant is short for quantity and indicates what is being measured. The values are rad, sal, and temp referring to ‘radiation’, ‘salinity’ and ‘temperature’, respectively.\n\n\n\ntaken\nperson\nquant\nreading\n\n\n\n\n619\ndyer\nrad\n9.82\n\n\n619\ndyer\nsal\n0.13\n\n\n622\ndyer\nrad\n7.8\n\n\n622\ndyer\nsal\n0.09\n\n\n734\npb\nrad\n8.41\n\n\n734\nlake\nsal\n0.05\n\n\n734\npb\ntemp\n-21.5\n\n\n735\npb\nrad\n7.22\n\n\n735\n-null-\nsal\n0.06\n\n\n735\n-null-\ntemp\n-26.0\n\n\n751\npb\nrad\n4.35\n\n\n751\npb\ntemp\n-18.5\n\n\n751\nlake\nsal\n0.1\n\n\n752\nlake\nrad\n2.19\n\n\n752\nlake\nsal\n0.09\n\n\n752\nlake\ntemp\n-16.0\n\n\n752\nroe\nsal\n41.6\n\n\n837\nlake\nrad\n1.46\n\n\n837\nlake\nsal\n0.21\n\n\n837\nroe\nsal\n22.5\n\n\n844\nroe\nrad\n11.25"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#sql-.tables-and-.schema",
    "href": "posts/2023-12-07-relational-databases/index.html#sql-.tables-and-.schema",
    "title": "Relational databases and SQL basics",
    "section": "SQL .tables and .schema",
    "text": "SQL .tables and .schema\nIn an interactive sqlite3 session,\n\nType .tables to list the tables in the database\nType .schema to see the SQL statements used to create the tables in the database. The statements will have a list of the columns and the data types each column stores.\n\n\n\n\n\n\n\nMore about .schema\n\n\n\nThe output from .schema is formatted as &lt;columnName dataType&gt;.\n\n\nOutput\n\nCREATE TABLE Person (id text, personal text, family text);\nCREATE TABLE Site (name text, lat real, long real);\nCREATE TABLE Survey (taken integer, person text, quant text, reading real);\nCREATE TABLE Visited (id integer, site text, dated text);\n\nThus we can see from the first line that the table Person has three columns:\n\nid with type text\npersonal with type text\nfamily with type text\n\n\n\nThe available data types vary based on the database manager - you can search online for what data types are supported."
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#more-about-select",
    "href": "posts/2023-12-07-relational-databases/index.html#more-about-select",
    "title": "Relational databases and SQL basics",
    "section": "More about SELECT",
    "text": "More about SELECT\nRow and columns in a database table are not actually stored in any particular order.\nThey will always be displayed in some order, but we can control that in various ways.\n\n\n\n\n\n\nExample\n\n\n\nWe could swap the columns in the output by writing our query as:\n\n\nSQL\n\nSELECT personal, family FROM Person;\n\n\n\nOutput\n\n|personal |family  |\n|---------|--------|\n|William  |Dyer    |\n|Frank    |Pabodie |\n|Anderson |Lake    |\n|Valentina|Roerich |\n|Frank    |Danforth|\n\nor even repeat columns:\n\n\nSQL\n\nSELECT id, id, id FROM Person;\n\n\n\nOutput\n\n|id      |id      |id      |\n|--------|--------|--------|\n|dyer    |dyer    |dyer    |\n|pb      |pb      |pb      |\n|lake    |lake    |lake    |\n|roe     |roe     |roe     |\n|danforth|danforth|danforth|\n\n\n\n\nThe * operator\nAs a shortcut, we can select all of the columns in a table using *:\n\n\nSQL\n\nSELECT * FROM Person;\n\n\n\nOutput\n\n|id      |personal |family  |\n|--------|---------|--------|\n|dyer    |William  |Dyer    |\n|pb      |Frank    |Pabodie |\n|lake    |Anderson |Lake    |\n|roe     |Valentina|Roerich |\n|danforth|Frank    |Danforth|"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#sorting-and-removing-duplicates",
    "href": "posts/2023-12-07-relational-databases/index.html#sorting-and-removing-duplicates",
    "title": "Relational databases and SQL basics",
    "section": "Sorting and removing duplicates",
    "text": "Sorting and removing duplicates\nIn this section, we will explore the following questions of the Antarctic data\n\nWhat are the unique types of measurements taken in Survey?\nWhich scientists took measurements on the expedition?\n\nTo answer the first question, we will extract the values in column quant (short for quantity) from Survey, which contains values rad, sal, and temp referring to ‘radiation’, ‘salinity’ and ‘temperature’, respectively.\nHowever, we only want the unique value labels.\nThe following will extract the quant column from the Survey table, but not return unique / distinct labels.\n\n\nSQL\n\nSELECT quant FROM Survey;\n\nBut, adding the DISTINCT keyword to our query eliminates the redundant output to make the result more readable:\n\n\nSQL\n\nSELECT DISTINCT quant FROM Survey;\n\n\n\nOutput\n\n|quant|\n|-----|\n|rad  |\n|sal  |\n|temp |\n\nYou can also use the DISTINCT keyword on multiple columns.\nIf we select more than one column, distinct sets of values are returned (in this case pairs, because we are selecting two columns) and duplicates are removed:\n\n\nSQL\n\nSELECT DISTINCT taken, quant FROM Survey;\n\n\n\nOutput\n\n|taken|quant|\n|-----|-----|\n|619  |rad  |\n|619  |sal  |\n|622  |rad  |\n|622  |sal  |\n|734  |rad  |\n|734  |sal  |\n|734  |temp |\n|735  |rad  |\n|735  |sal  |\n|735  |temp |\n|751  |rad  |\n|751  |temp |\n|751  |sal  |\n|752  |rad  |\n|752  |sal  |\n|752  |temp |\n|837  |rad  |\n|837  |sal  |\n|844  |rad  |\n\nNext, we will look at the Person table and sort the scientists names.\nDatabase records are not necessarily sorted in any particular order.\nIf you want to have the table returned sorted in a particular way, you add the ORDER BY clause to our query:\n\n\nSQL\n\nSELECT * FROM Person ORDER BY id;\n\n\n\nOutput\n\n|id     |personal |family  |\n|-------|---------|--------|\n|danfort|Frank    |Danforth|\n|dyer   |William  |Dyer    |\n|lake   |Anderson |Lake    |\n|pb     |Frank    |Pabodie |\n|roe    |Valentina|Roerich |\n\nThe default is to sort in an ascending order, but we can sort in a descending order using DESC (for “descending”):\n\n\nSQL\n\nSELECT * FROM person ORDER BY id DESC;\n\n\n\nOutput\n\n|id     |personal |family  |\n|-------|---------|--------|\n|roe    |Valentina|Roerich |\n|pb     |Frank    |Pabodie |\n|lake   |Anderson |Lake    |\n|dyer   |William  |Dyer    |\n|danfort|Frank    |Danforth|\n\n(And if we want to make it clear that we’re sorting in ascending order, we can use ASC instead of DESC.)\n\n\n\n\n\n\nExample\n\n\n\nLet’s look at which scientist (person) measured what quantities (quant) during each visit (taken) with the Survey table.\nWe also want to sort by two columns at once\n\nSort results first in ascending order by taken\nAnd then in descending order by person within each group of equal taken values:\n\n\n\nSQL\n\nSELECT taken, person, quant FROM Survey ORDER BY taken ASC, person DESC;\n\n\n\nOutput\n\n|taken|person|quant|\n|-----|------|-----|\n|619  |dyer  |rad  |\n|619  |dyer  |sal  |\n|622  |dyer  |rad  |\n|622  |dyer  |sal  |\n|734  |pb    |rad  |\n|734  |pb    |temp |\n|734  |lake  |sal  |\n|735  |pb    |rad  |\n|735  |-null-|sal  |\n|735  |-null-|temp |\n|751  |pb    |rad  |\n|751  |pb    |temp |\n|751  |lake  |sal  |\n|752  |roe   |sal  |\n|752  |lake  |rad  |\n|752  |lake  |sal  |\n|752  |lake  |temp |\n|837  |roe   |sal  |\n|837  |lake  |rad  |\n|837  |lake  |sal  |\n|844  |roe   |rad  |\n\nThis query gives us a good idea of which scientist was involved in which visit, and what measurements they performed during the visit.\n\n\nLooking at the table, it seems like some scientists specialized in certain kinds of measurements.\nWe can examine which scientists performed which measurements by selecting the appropriate columns and removing duplicates.\n\n\nSQL\n\nSELECT DISTINCT quant, person FROM Survey ORDER BY quant ASC;\n\n\n\nOutput\n\n|quant|person|\n|-----|------|\n|rad  |dyer  |\n|rad  |pb    |\n|rad  |lake  |\n|rad  |roe   |\n|sal  |dyer  |\n|sal  |lake  |\n|sal  |-null-|\n|sal  |roe   |\n|temp |pb    |\n|temp |-null-|\n|temp |lake  |"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#other-important-tasks",
    "href": "posts/2023-12-07-relational-databases/index.html#other-important-tasks",
    "title": "Relational databases and SQL basics",
    "section": "Other important tasks",
    "text": "Other important tasks\nThere are many other tasks you can do with SQL, but for purposes of the lecture, I will leave you to work through this carpentries tutorial if you want to know more:\n\nhttps://swcarpentry.github.io/sql-novice-survey\n\n\nFiltering\nHow can you select subsets of data? You use WHERE.\nHere is an example of filtering for all rows that contain “dyer” in the Person column.\n\n\nSQL\n\nSELECT * FROM Survey WHERE person = \"dyer\";\n\n\n\nOutput\n\n619|dyer|rad|9.82\n619|dyer|sal|0.13\n622|dyer|rad|7.8\n622|dyer|sal|0.09\n\nFor more information about filtering, read through this tutorial:\n\nhttps://swcarpentry.github.io/sql-novice-survey/03-filter\n\n\n\nAnd more\nThe carpentries tutorial has so much more including how to:\n\nCalculating new values (https://swcarpentry.github.io/sql-novice-survey/04-calc)\nHow to deal with missing data (https://swcarpentry.github.io/sql-novice-survey/05-null)\nHow to aggregate data to calculate summaries (https://swcarpentry.github.io/sql-novice-survey/06-agg)\nHow to write queries that joins together two tables (https://swcarpentry.github.io/sql-novice-survey/07-join)\nHow to create tables or modify exisiting data in tables (https://swcarpentry.github.io/sql-novice-survey/09-create)"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#connect-to-the-sql-database",
    "href": "posts/2023-12-07-relational-databases/index.html#connect-to-the-sql-database",
    "title": "Relational databases and SQL basics",
    "section": "Connect to the SQL database",
    "text": "Connect to the SQL database\nThe main workhorse packages that we will use are the DBI and RSQLite packages.\n\nDBI is an R package that connects R to database management systems (DBMS). DBI separates the connectivity to the DBMS into a “front-end” and a “back-end”. The package defines an interface that is implemented by DBI backends such as RPostgres, RMariaDB, RSQLite, odbc, bigrquery, and more!\nRSQLite is an R package that embeds the SQLite database engine in R, providing a DBI-compliant interface. SQLite is a public-domain, single-user, very light-weight database engine that implements a decent subset of the SQL 92 standard, including the core table creation, updating, insertion, and selection operations, plus transaction management."
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#example-workflow",
    "href": "posts/2023-12-07-relational-databases/index.html#example-workflow",
    "title": "Relational databases and SQL basics",
    "section": "Example workflow",
    "text": "Example workflow\n\n\n\n\n\n\nExample\n\n\n\nHere’s a short R program that sorts the scientists names in a descending order from from an SQLite database stored in a file called survey.db:\n\nlibrary(RSQLite)\nconnection &lt;- dbConnect(drv = RSQLite::SQLite(), \n                        dbname = here::here(\"posts\", \"2023-12-07-relational-databases\", \"data\", \"survey.db\"))\nresults &lt;- dbGetQuery(connection, \"SELECT * FROM Person ORDER BY id DESC;\")\nprint(results)\n\n        id  personal   family\n1      roe Valentina  Roerich\n2       pb     Frank  Pabodie\n3     lake  Anderson     Lake\n4     dyer   William     Dyer\n5 danforth     Frank Danforth\n\ndbDisconnect(connection)\n\n\n\nLet’s break this down.\nThe program starts by importing the RSQLite library.\nIf we were connecting to MySQL, DB2, or some other database, we would import a different library, but all of them provide the same functions, so that the rest of our program does not have to change (at least, not much) if we switch from one database to another.\nLine 2 establishes a connection to the database.\nSince we’re using SQLite, all we need to specify is the name of the database file. Other systems may require us to provide a username and password as well.\nOn line 3, we retrieve the results from an SQL query.\nIt’s our job to make sure that SQL is properly formatted; if it isn’t, or if something goes wrong when it is being executed, the database will report an error.\nThis result is a data.frame with one row for each entry and one column for each column in the database.\nFinally, the last line closes our connection, since the database can only keep a limited number of these open at one time.\nSince establishing a connection takes time, though, we should not open a connection, do one operation, then close the connection, only to reopen it a few microseconds later to do another operation.\nInstead, it’s normal to create one connection that stays open for the lifetime of the program.\nQueries in real applications will often depend on values provided by users.\nFor example, this function takes a user’s ID as a parameter and returns only the rows with their ID:\n\nlibrary(RSQLite)\nconnection &lt;- dbConnect(drv = SQLite(), \n                        dbname = here::here(\"posts\", \"2023-12-07-relational-databases\", \"data\", \"survey.db\"))\n\ngetName &lt;- function(personID) {\n  query &lt;- paste0(\"SELECT * FROM Survey WHERE person ='\", \n                  personID, \"';\")\n  return(dbGetQuery(connection, query))\n}\n\ngetName(\"dyer\")\n\n  taken person quant reading\n1   619   dyer   rad    9.82\n2   619   dyer   sal    0.13\n3   622   dyer   rad    7.80\n4   622   dyer   sal    0.09\n\ndbDisconnect(connection)\n\nWe use string concatenation on the first line of this function to construct a query containing the user ID we have been given."
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#database-helper-functions-in-r",
    "href": "posts/2023-12-07-relational-databases/index.html#database-helper-functions-in-r",
    "title": "Relational databases and SQL basics",
    "section": "Database helper functions in R",
    "text": "Database helper functions in R\nR’s database interface packages (like RSQLite) all share a common set of helper functions useful for exploring databases and reading/writing entire tables at once.\nTo view all tables in a database, we can use dbListTables():\n\nconnection &lt;- dbConnect(SQLite(), \n                        here::here(\"posts\", \"2023-12-07-relational-databases\", \"data\", \"survey.db\"))\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\"\n\n\nTo view all column names of a table, use dbListFields():\n\ndbListFields(connection, \"Survey\")\n\n[1] \"taken\"   \"person\"  \"quant\"   \"reading\"\n\n\nTo read an entire table as a dataframe, use dbReadTable():\n\ndbReadTable(connection, \"Person\")\n\n        id  personal   family\n1     dyer   William     Dyer\n2       pb     Frank  Pabodie\n3     lake  Anderson     Lake\n4      roe Valentina  Roerich\n5 danforth     Frank Danforth\n\n\nFinally, to write an entire table to a database, you can use dbWriteTable().\n\n\n\n\n\n\nNote\n\n\n\nWe will always want to use the row.names = FALSE argument or R will write the row names as a separate column.\n\n\n\ndbWriteTable(connection, \"iris\", iris, row.names = FALSE)\nhead(dbReadTable(connection, \"iris\"))\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nIn this example we will write R’s built-in iris dataset as a table in survey.db.\nWhich you can see here:\n\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\" \"iris\"   \n\n\nWe can remove iris as a table with dbRemoveTable() and check it’s been removed with dbListTables().\n\ndbRemoveTable(connection, \"iris\")\ndbListTables(connection)\n\n[1] \"Person\"  \"Site\"    \"Survey\"  \"Visited\"\n\n\nAnd as always, remember to close the database connection when done!\n\ndbDisconnect(connection)"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#example-album-covers",
    "href": "posts/2023-12-07-relational-databases/index.html#example-album-covers",
    "title": "Relational databases and SQL basics",
    "section": "Example: album covers",
    "text": "Example: album covers\nWe will use the\n\nchinook sqlite database\n\nThe database represents a “digital media store, including tables for artists, albums, media tracks, invoices and customers”.\nFrom the Readme.md file:\n\nSample Data\nMedia related data was created using real data from an iTunes Library. … Customer and employee information was manually created using fictitious names, addresses that can be located on Google maps, and other well formatted data (phone, fax, email, etc.). Sales information is auto generated using random data for a four year period.\n\nThe data are saved in our /data folder:\n\nlibrary(here)\n\nhere() starts at /Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023\n\nlist.files(here(\"data\"))\n\n[1] \"Chinook.sqlite\"            \"nycflights13\"             \n[3] \"SRR1039508_subset_1.fastq\" \"SRR1039509_subset_1.fastq\"\n[5] \"SRR1039512_subset_1.fastq\" \"SRR1039513_subset_1.fastq\""
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#connect-to-the-sqlite-database",
    "href": "posts/2023-12-07-relational-databases/index.html#connect-to-the-sqlite-database",
    "title": "Relational databases and SQL basics",
    "section": "Connect to the SQLite database",
    "text": "Connect to the SQLite database\nLet’s connect to the Chinook.sqlite file\n\nconnection &lt;- dbConnect(SQLite(), \n                        here(\"data\", \"Chinook.sqlite\"))\n\nSo we have opened up a connection with the SQLite database. Next, we can see what tables are available in the database using the dbListTables() function:\n\ndbListTables(connection)\n\n [1] \"Album\"         \"Artist\"        \"Customer\"      \"Employee\"     \n [5] \"Genre\"         \"Invoice\"       \"InvoiceLine\"   \"MediaType\"    \n [9] \"Playlist\"      \"PlaylistTrack\" \"Track\"        \n\n\nI have shown you how to write SQL queries with dbGetQuery().\nAn alternative approach to interact with SQL databases is to leverage the dplyr framework.\n\n“The dplyr package now has a generalized SQL backend for talking to databases, and the new dbplyr package translates R code into database-specific variants. As of this writing, SQL variants are supported for the following databases: Oracle, Microsoft SQL Server, PostgreSQL, Amazon Redshift, Apache Hive, and Apache Impala. More will follow over time.\n\nSo if we want to query a SQL databse with dplyr, the benefit of using dbplyr is:\n\n“You can write your code in dplyr syntax, and dplyr will translate your code into SQL. There are several benefits to writing queries in dplyr syntax: you can keep the same consistent language both for R objects and database tables, no knowledge of SQL or the specific SQL variant is required, and you can take advantage of the fact that dplyr uses lazy evaluation.\n\nLet’s take a closer look at the conn database that we just connected to:\n\nlibrary(dbplyr)\nsrc_dbi(connection)\n\nsrc:  sqlite 3.41.2 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/data/Chinook.sqlite]\ntbls: Album, Artist, Customer, Employee, Genre, Invoice, InvoiceLine,\n  MediaType, Playlist, PlaylistTrack, Track\n\n\nYou can think of the multiple tables similar to having multiple worksheets in a spreadsheet.\nLet’s try interacting with one."
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#using-dplyr",
    "href": "posts/2023-12-07-relational-databases/index.html#using-dplyr",
    "title": "Relational databases and SQL basics",
    "section": "Using dplyr",
    "text": "Using dplyr\nFirst, let’s look at the first ten rows in the Album table using the tbl() function from dplyr:\n\ntbl(connection, \"Album\") %&gt;%\n  head(n=10)\n\n# Source:   SQL [10 x 3]\n# Database: sqlite 3.41.2 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/data/Chinook.sqlite]\n   AlbumId Title                                 ArtistId\n     &lt;int&gt; &lt;chr&gt;                                    &lt;int&gt;\n 1       1 For Those About To Rock We Salute You        1\n 2       2 Balls to the Wall                            2\n 3       3 Restless and Wild                            2\n 4       4 Let There Be Rock                            1\n 5       5 Big Ones                                     3\n 6       6 Jagged Little Pill                           4\n 7       7 Facelift                                     5\n 8       8 Warner 25 Anos                               6\n 9       9 Plays Metallica By Four Cellos               7\n10      10 Audioslave                                   8\n\n\nThe output looks just like a data.frame that we are familiar with. But it’s important to know that it’s not really a data frame. For example, what about if we use the dim() function?\n\ntbl(connection, \"Album\") %&gt;%\n  dim()\n\n[1] NA  3\n\n\nInteresting! We see that the number of rows returned is NA. This is because these functions are different than operating on datasets in memory (e.g. loading data into memory using read_csv()).\nInstead, dplyr communicates differently with a SQLite database.\nLet’s consider our example. If we were to use straight SQL, the following SQL query returns the first 10 rows from the Album table:\n\n\nSQL\n\nSELECT * FROM Album LIMIT 10;\n\n\n\nOutput\n\n1|For Those About To Rock We Salute You|1\n2|Balls to the Wall|2\n3|Restless and Wild|2\n4|Let There Be Rock|1\n5|Big Ones|3\n6|Jagged Little Pill|4\n7|Facelift|5\n8|Warner 25 Anos|6\n9|Plays Metallica By Four Cellos|7\n10|Audioslave|8\n\nIn the background, dplyr does the following:\n\ntranslates your R code into SQL\nsubmits it to the database\ntranslates the database’s response into an R data frame\n\nTo better understand the dplyr code, we can use the show_query() function:\n\nAlbum &lt;- tbl(connection, \"Album\")\nshow_query(head(Album, n = 10))\n\n&lt;SQL&gt;\nSELECT *\nFROM `Album`\nLIMIT 10\n\n\nThis is nice because instead of having to write the SQL query our self, we can just use the dplyr and R syntax that we are used to.\nHowever, the downside is that dplyr never gets to see the full Album table. It only sends our query to the database, waits for a response and returns the query.\nHowever, in this way we can interact with large datasets!\nMany of the usual dplyr functions are available too:\n\nselect()\nfilter()\nsummarize()\n\nand many join functions.\nOk let’s try some of the functions out. First, let’s count how many albums each artist has made.\n\ntbl(connection, \"Album\") %&gt;%\n  group_by(ArtistId) %&gt;% \n  summarize(n = count(ArtistId)) %&gt;% \n  head(n=10)\n\n# Source:   SQL [10 x 2]\n# Database: sqlite 3.41.2 [/Users/stephaniehicks/Documents/github/teaching/jhustatprogramming2023/data/Chinook.sqlite]\n   ArtistId     n\n      &lt;int&gt; &lt;int&gt;\n 1        1     2\n 2        2     2\n 3        3     1\n 4        4     1\n 5        5     1\n 6        6     2\n 7        7     1\n 8        8     3\n 9        9     1\n10       10     1"
  },
  {
    "objectID": "posts/2023-12-07-relational-databases/index.html#data-viz",
    "href": "posts/2023-12-07-relational-databases/index.html#data-viz",
    "title": "Relational databases and SQL basics",
    "section": "data viz",
    "text": "data viz\nNext, let’s plot it.\n\ntbl(connection, \"Album\") %&gt;%\n  group_by(ArtistId) %&gt;% \n  summarize(n = count(ArtistId)) %&gt;% \n  arrange(desc(n)) %&gt;% \n  ggplot(aes(x = ArtistId, y = n)) + \n  geom_bar(stat = \"identity\")\n\n\n\n\nLet’s also extract the first letter from each album and plot the frequency of each letter.\n\ntbl(connection, \"Album\") %&gt;%\n  mutate(first_letter = str_sub(Title, end = 1)) %&gt;% \n  ggplot(aes(first_letter)) + \n  geom_bar()\n\n\n\n\nIf you decide to make an album, you should try picking a less frequently used letter like E, J, K, Q, U, W, or Z!"
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html",
    "href": "posts/2023-12-14-web-rvest/index.html",
    "title": "Scraping data from the web with rvest",
    "section": "",
    "text": "Material for this lecture was borrowed and adopted from\n\nhttps://rvest.tidyverse.org\n\n\n\n\nBefore we begin, you will need to install the rvest package\n\ninstall.packages(\"rvest\")\n\nNow we load a few R packages\n\nlibrary(tidyverse)\nlibrary(rvest)"
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html#html-basics",
    "href": "posts/2023-12-14-web-rvest/index.html#html-basics",
    "title": "Scraping data from the web with rvest",
    "section": "HTML basics",
    "text": "HTML basics\nHTML stands for “HyperText Markup Language” and looks like this:\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Page title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1 id='first'&gt;A heading&lt;/h1&gt;\n  &lt;p&gt;Some text &amp; &lt;b&gt;some bold text.&lt;/b&gt;&lt;/p&gt;\n  &lt;img src='myimg.png' width='100' height='100'&gt;\n&lt;/body&gt;\nHTML has a hierarchical structure formed by elements which consist of a start tag (e.g. &lt;tag&gt;), optional attributes (id='first'), an end tag (like &lt;/tag&gt;), and contents (everything in between the start and end tag).\n\n\n\n\n\n\nNote\n\n\n\nA number of tags (including &lt;p&gt; and &lt;li&gt;) don’t require end tags, but I think it’s best to include them because it makes seeing the structure of the HTML a little easier.\n\n\n\nElements\nAll up, there are over 100 HTML elements. Some of the most important are:\n\nEvery HTML page must be must be in an &lt;html&gt; element, and it must have two children:\n\n&lt;head&gt;, which contains document metadata like the page title\n&lt;body&gt;, which contains the content you see in the browser\n\nBlock tags like &lt;h1&gt; (heading 1), &lt;p&gt; (paragraph), and &lt;ol&gt; (ordered list) form the overall structure of the page.\nInline tags like &lt;b&gt; (bold), &lt;i&gt; (italics), and &lt;a&gt; (links) formats text inside block tags.\n\nIf you encounter a tag that you have never seen before, you can find out what it does with a little googling.\nI recommend the MDN Web Docs which are produced by Mozilla, the company that makes the Firefox web browser.\n\n\nContents\nMost elements can have content in between their start and end tags. This content can either be text or more elements. For example, the following HTML contains paragraph of text, with one word in bold.\n&lt;p&gt;\n  Hi! My &lt;b&gt;name&lt;/b&gt; is Stephanie.\n&lt;/p&gt;\nThe children of a node refers only to elements, so the &lt;p&gt; element above has one child, the &lt;b&gt; element. The &lt;b&gt; element has no children, but it does have contents (the text “name”).\nSome elements, like &lt;img&gt; can’t have children. These elements depend solely on attributes for their behavior.\n\n\nAttributes\nTags can have named attributes which look like name1='value1' name2='value2'.\nTwo of the most important attributes are id and class, which are used in conjunction with CSS (Cascading Style Sheets) to control the visual appearance of the page.\nThese are often useful when scraping data off a page."
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html#reading-html-with-rvest",
    "href": "posts/2023-12-14-web-rvest/index.html#reading-html-with-rvest",
    "title": "Scraping data from the web with rvest",
    "section": "Reading HTML with rvest",
    "text": "Reading HTML with rvest\nYou will usually start the scraping process with read_html(). This returns a xml_document object which you will then manipulate using rvest functions:\n\n\n\n\n\n\nNote\n\n\n\nThis xml_document class comes from the xml2 package, which is a low-level package that rvest builds on top of.\n\n\n\nhtml &lt;- read_html(\"http://rvest.tidyverse.org/\")\nclass(html)\n\n[1] \"xml_document\" \"xml_node\"    \n\n\nFor examples and experimentation, rvest also includes a function (minimal_html()) that lets you create an xml_document from literal HTML:\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;This is a paragraph&lt;p&gt;\n  &lt;ul&gt;\n    &lt;li&gt;This is a bulleted list&lt;/li&gt;\n  &lt;/ul&gt;\n\")\nclass(html)\n\n[1] \"xml_document\" \"xml_node\"    \n\nhtml\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n&lt;p&gt;This is a paragraph&lt;/p&gt;\\n&lt;p&gt;\\n  &lt;/p&gt;\\n&lt;ul&gt;\\n&lt;li&gt;This is a bull ...\n\n\nRegardless of how you get the HTML, you will need some way to identify the elements that contain the data you care about.\nrvest provides two options:\n\nCSS selectors\nXPath expressions\n\nHere I will focus on CSS selectors because they are simpler, but still sufficiently powerful for most scraping tasks."
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html#css-selectors",
    "href": "posts/2023-12-14-web-rvest/index.html#css-selectors",
    "title": "Scraping data from the web with rvest",
    "section": "CSS selectors",
    "text": "CSS selectors\nCSS is short for cascading style sheets, and is a tool for defining the visual styling of HTML documents.\nCSS includes a miniature language for selecting elements on a page called CSS selectors.\nCSS selectors define patterns for locating HTML elements, and are useful for scraping because they provide a concise way of describing which elements you want to extract.\nCSS selectors can be quite complex, but fortunately you only need the simplest for rvest, because you can also write R code for more complicated situations.\nThe four most important selectors are:\n\np: selects all &lt;p&gt; elements.\n.title: selects all elements with class “title”.\np.special: selects all &lt;p&gt; elements with class “special”.\n#title: selects the element with the id attribute that equals “title”. Id attributes must be unique within a document, so this will only ever select a single element.\n\nIf you want to learn more CSS selectors, I recommend starting with the fun CSS dinner tutorial and then referring to the MDN web docs.\nLets try out the most important selectors with a simple example:\n\nhtml &lt;- minimal_html(\"\n  &lt;h1&gt;This is a heading&lt;/h1&gt;\n  &lt;p id='first'&gt;This is a paragraph&lt;/p&gt;\n  &lt;p class='important'&gt;This is an important paragraph&lt;/p&gt;\n\")\n\nIn rvest you can extract\n\na single element with html_element() or\nall matching elements with html_elements()\n\nBoth functions take a document (or another element) and a css selector:\n\nhtml %&gt;% html_elements(\"h1\")\n\n{xml_nodeset (1)}\n[1] &lt;h1&gt;This is a heading&lt;/h1&gt;\n\nhtml %&gt;% html_elements(\"p\")\n\n{xml_nodeset (2)}\n[1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n[2] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\n\nhtml %&gt;% html_elements(\".important\")\n\n{xml_nodeset (1)}\n[1] &lt;p class=\"important\"&gt;This is an important paragraph&lt;/p&gt;\n\nhtml %&gt;% html_elements(\"#first\")\n\n{xml_nodeset (1)}\n[1] &lt;p id=\"first\"&gt;This is a paragraph&lt;/p&gt;\n\n\n\n\n\n\n\n\nPro-tip\n\n\n\nIf you don’t know exactly what selector you need, I highly recommend using SelectorGadget, which lets you automatically generate the selector you need by supplying positive and negative examples in the browser"
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html#extracting-data",
    "href": "posts/2023-12-14-web-rvest/index.html#extracting-data",
    "title": "Scraping data from the web with rvest",
    "section": "Extracting data",
    "text": "Extracting data\nNow that you have got the elements you care about, you will need to get data out of them.\nYou will usually get the data from either the text contents or an attribute. But, sometimes (if you’re lucky!), the data you need will be in an HTML table.\n\nText\nUse html_text2() to extract the plain text contents of an HTML element:\n\nhtml &lt;- minimal_html(\"\n  &lt;ol&gt;\n    &lt;li&gt;apple &amp; pear&lt;/li&gt;\n    &lt;li&gt;banana&lt;/li&gt;\n    &lt;li&gt;pineapple&lt;/li&gt;\n  &lt;/ol&gt;\n\")\nhtml %&gt;% \n  html_elements(\"li\") %&gt;% \n  html_text2()\n\n[1] \"apple & pear\" \"banana\"       \"pineapple\"   \n\n\nNote that the escaped ampersand is automatically converted to &; you will only ever see HTML escapes in the source HTML, not in the data returned by rvest.\nYou might wonder why I used html_text2(), since it seems to give the same result as html_text():\n\nhtml %&gt;% \n  html_elements(\"li\") %&gt;% \n  html_text()\n\n[1] \"apple & pear\" \"banana\"       \"pineapple\"   \n\n\nThe main difference is how the two functions handle white space.\nIn HTML, white space is largely ignored, and it is the structure of the elements that defines how text is laid out.\nhtml_text2() does its best to follow the same rules, giving you something similar to what you’d see in the browser. Take this example which contains a bunch of white space that HTML ignores.\n\nhtml &lt;- minimal_html(\"&lt;body&gt;\n  &lt;p&gt;\n  This is\n  a\n  paragraph.&lt;/p&gt;&lt;p&gt;This is another paragraph.\n  \n  It has two sentences.&lt;/p&gt;\n\")\n\nhtml_text2() gives you what you expect: two paragraphs of text separated by a blank line.\n\nhtml %&gt;% \n  html_element(\"body\") %&gt;% \n  html_text2() %&gt;% \n  cat()\n\nThis is a paragraph.\n\nThis is another paragraph. It has two sentences.\n\n\nWhereas html_text() returns the garbled raw underlying text:\n\nhtml %&gt;% \n  html_element(\"body\") %&gt;% \n  html_text() %&gt;% \n  cat()\n\n\n  \n  This is\n  a\n  paragraph.This is another paragraph.\n  \n  It has two sentences.\n\n\n\n\nAttributes\nAttributes are used to record the destination of links (the href attribute of &lt;a&gt; elements) and the source of images (the src attribute of the &lt;img&gt; element):\n\nhtml &lt;- minimal_html(\"\n  &lt;p&gt;&lt;a href='https://en.wikipedia.org/wiki/Cat'&gt;cats&lt;/a&gt;&lt;/p&gt;\n  &lt;img src='https://cataas.com/cat' width='100' height='200'&gt;\n\")\n\nThe value of an attribute can be retrieved with html_attr():\n\nhtml %&gt;% \n  html_elements(\"a\") %&gt;% \n  html_attr(\"href\")\n\n[1] \"https://en.wikipedia.org/wiki/Cat\"\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"src\")\n\n[1] \"https://cataas.com/cat\"\n\n\nNote that html_attr() always returns a string, so you may need to post-process with as.integer()/readr::parse_integer() or similar.\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"width\")\n\n[1] \"100\"\n\nhtml %&gt;% \n  html_elements(\"img\") %&gt;% \n  html_attr(\"width\") %&gt;% \n  as.integer()\n\n[1] 100\n\n\n\n\nTables\nHTML tables are composed four main elements:\n\n&lt;table&gt;\n&lt;tr&gt; (table row)\n&lt;th&gt; (table heading)\nand &lt;td&gt; (table data)\n\nHere’s a simple HTML table with two columns and three rows:\n\nhtml &lt;- minimal_html(\"\n  &lt;table&gt;\n    &lt;tr&gt;\n      &lt;th&gt;x&lt;/th&gt;\n      &lt;th&gt;y&lt;/th&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;1.5&lt;/td&gt;\n      &lt;td&gt;2.7&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;4.9&lt;/td&gt;\n      &lt;td&gt;1.3&lt;/td&gt;\n    &lt;/tr&gt;\n    &lt;tr&gt;\n      &lt;td&gt;7.2&lt;/td&gt;\n      &lt;td&gt;8.1&lt;/td&gt;\n    &lt;/tr&gt;\n  &lt;/table&gt;\n  \")\n\nBecause tables are a common way to store data, rvest includes the handy html_table() which converts a table into a data frame:\n\nhtml %&gt;% \n  html_node(\"table\") %&gt;% \n  html_table()\n\n# A tibble: 3 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1   1.5   2.7\n2   4.9   1.3\n3   7.2   8.1"
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html#element-vs-elements",
    "href": "posts/2023-12-14-web-rvest/index.html#element-vs-elements",
    "title": "Scraping data from the web with rvest",
    "section": "Element vs elements",
    "text": "Element vs elements\nWhen using rvest, your eventual goal is usually to build up a data frame, and you want each row to correspond some repeated unit on the HTML page.\nIn this case, you should generally\n\nstart by using html_elements() to select the elements that contain each observation\nthen, use html_element() to extract the variables from each observation\n\nThis guarantees that you will get the same number of values for each variable because html_element() always returns the same number of outputs as inputs.\nTo illustrate this problem take a look at this simple example I constructed using a few entries from dplyr::starwars:\n\nhtml &lt;- minimal_html(\"\n  &lt;ul&gt;\n    &lt;li&gt;&lt;b&gt;C-3PO&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;167 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R2-D2&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt; that weighs &lt;span class='weight'&gt;96 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;Yoda&lt;/b&gt; weighs &lt;span class='weight'&gt;66 kg&lt;/span&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;b&gt;R4-P17&lt;/b&gt; is a &lt;i&gt;droid&lt;/i&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n  \")\n\nIf you try to extract name, species, and weight directly, you end up with one vector of length four and two vectors of length three, and no way to align them:\n\nhtml %&gt;% html_elements(\"b\") %&gt;% html_text2()\n\n[1] \"C-3PO\"  \"R2-D2\"  \"Yoda\"   \"R4-P17\"\n\nhtml %&gt;% html_elements(\"i\") %&gt;% html_text2()\n\n[1] \"droid\" \"droid\" \"droid\"\n\nhtml %&gt;% html_elements(\".weight\") %&gt;% html_text2()\n\n[1] \"167 kg\" \"96 kg\"  \"66 kg\" \n\n\nInstead, use html_elements() to find a element that corresponds to each character, then use html_element() to extract each variable for all observations:\n\ncharacters &lt;- html %&gt;% html_elements(\"li\")\n\ncharacters %&gt;% html_element(\"b\") %&gt;% html_text2()\n\n[1] \"C-3PO\"  \"R2-D2\"  \"Yoda\"   \"R4-P17\"\n\ncharacters %&gt;% html_element(\"i\") %&gt;% html_text2()\n\n[1] \"droid\" \"droid\" NA      \"droid\"\n\ncharacters %&gt;% html_element(\".weight\") %&gt;% html_text2()\n\n[1] \"167 kg\" \"96 kg\"  \"66 kg\"  NA      \n\n\nhtml_element() automatically fills in NA when no elements match, keeping all of the variables aligned and making it easy to create a data frame:\n\ndata.frame(\n  name = characters %&gt;% html_element(\"b\") %&gt;% html_text2(),\n  species = characters %&gt;% html_element(\"i\") %&gt;% html_text2(),\n  weight = characters %&gt;% html_element(\".weight\") %&gt;% html_text2()\n)\n\n    name species weight\n1  C-3PO   droid 167 kg\n2  R2-D2   droid  96 kg\n3   Yoda    &lt;NA&gt;  66 kg\n4 R4-P17   droid   &lt;NA&gt;"
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html#installation",
    "href": "posts/2023-12-14-web-rvest/index.html#installation",
    "title": "Scraping data from the web with rvest",
    "section": "Installation",
    "text": "Installation\nTo install it, open this page in your browser, and then drag the following link to your bookmark bar: SelectorGadget."
  },
  {
    "objectID": "posts/2023-12-14-web-rvest/index.html#use",
    "href": "posts/2023-12-14-web-rvest/index.html#use",
    "title": "Scraping data from the web with rvest",
    "section": "Use",
    "text": "Use\nTo use it, open the page you want to scrape, then:\n\nClick the SelectorGadget entry in your bookmark bar.\nClick on the element you want to select. SelectorGadget will make a first guess at what css selector you want. It’s likely to be bad since it only has one example to learn from, but it’s a start. Elements that match the selector will be highlighted in yellow.\nClick on elements that should not be selected. They will turn red. Click on elements that should be selected. They will turn green.\nIterate until only the elements you want are selected. SelectorGadget is not perfect and sometimes will not be able to find a useful css selector. Sometimes starting from a different element helps."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Project 4\n\n\n\n\n\n\n\nproject 4\n\n\nprojects\n\n\n\n\nBuilding static and interactive dashboards\n\n\n\n\n\n\nDec 12, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nProject 3\n\n\n\n\n\n\n\nproject 3\n\n\nprojects\n\n\n\n\nBuilding websites for R packages; practice functional programming and APIs\n\n\n\n\n\n\nNov 28, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nProject 2\n\n\n\n\n\n\n\nproject 2\n\n\nprojects\n\n\n\n\nBuilding an R package and practicing with S3\n\n\n\n\n\n\nNov 7, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\n  \n\n\n\n\nProject 1\n\n\n\n\n\n\n\nproject 1\n\n\nprojects\n\n\n\n\nBuilding a website and practicing with command-line tools\n\n\n\n\n\n\nOct 26, 2023\n\n\nStephanie Hicks\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html",
    "href": "projects/2023-11-07-project-2/index.html",
    "title": "Project 2",
    "section": "",
    "text": "Due date: November 28 at 11:59pm\nThe goal of this homework is to write a set of functions and put them into an R package so that other people can easily use the functions in their own data analyses after installing the package. In addition, they would receive documentation on how to use the functions.\nIn addition to building the R package, you will also build a S3 class for your package, and create a vignette where you demonstrate the functions in your R package with an example dataset from TidyTuesday.\nFinally, we will practice our command-line and version control skills by submitting the assignment through GitHub Classroom.\n\n\n\nThe link to create a private GitHub repository for yourself to complete Project 2 will be posted in CoursePlus (Note: this creates an empty repository and you need to push your code in your locate remote repository to GitHub when ready).\nBuild your R package locally and then push the files to the private Github repository that you created for yourself via GitHub Classroom.\nThe TA will grade the R package by cloning the repository, installing it, and checking for all the things described below. It must be installable without any errors."
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-1a-cosine-and-sine-transformation",
    "href": "projects/2023-11-07-project-2/index.html#part-1a-cosine-and-sine-transformation",
    "title": "Project 2",
    "section": "Part 1A: Cosine and sine transformation",
    "text": "Part 1A: Cosine and sine transformation\nThe cosine and sine of a number can be written as an infinite series expansion of the form\n\\[\n\\cos(x) = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!}  \\cdots\n\\]\n\\[\n\\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} \\cdots\n\\]\nWrite two functions that compute the cosine and sine (respectively) of a number using the truncated series expansion. Each function should take two arguments:\n\nx: the number to be transformed\nk: the number of terms to be used in the series expansion beyond the constant 1. The value of k is always \\(\\geq 1\\).\n\n\n\n\n\n\n\nNotes\n\n\n\n\nYou can assume that the input value x will always be a single number.\nYou can assume that the value k will always be an integer \\(\\geq 1\\).\nDo not use the cos() or sin() functions in R.\n\n\n\n\nfn_cos &lt;- function(x, k) {\n        # Add your solution here\n}\n\nfun_sin &lt;- function(x, k) { \n        # Add your solution here\n}"
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-1b-calculating-confidence-intervals",
    "href": "projects/2023-11-07-project-2/index.html#part-1b-calculating-confidence-intervals",
    "title": "Project 2",
    "section": "Part 1B: Calculating confidence intervals",
    "text": "Part 1B: Calculating confidence intervals\nWrite the following set of functions:\n\nsample_mean(), which calculates the sample mean\n\n\\[\n\\bar{x} = \\frac{1}{N} \\sum_{i=1}^n x_i\n\\]\n\nsample_sd(), which calculates the sample standard deviation\n\n\\[\ns = \\sqrt{\\frac{1}{N-1} \\sum_{i=1}^N (x_i - \\overline{x})^2}\n\\]\n\ncalculate_CI(), which calculates the confidence intervals of a sample mean and returns a named vector of length 2, where the first value is the lower_bound, the second value is the upper_bound.\n\n\\[\n\\bar{x} \\pm t_{\\alpha/2, N-1} s_{\\bar{x}}\n\\]\n\n\n\n\n\n\nNotes\n\n\n\n\nYou can assume that the input value x will always be a vector of numbers of length N.\nDo not use the mean() and sd() functions in R.\n\n\n\n\nsample_mean &lt;- function(x) {\n        # Add your solution here\n}\n\nsample_sd &lt;- function(x) {\n        # Add your solution here\n}\n\ncalculate_CI &lt;- function(x, conf = 0.95) {\n        # Add your solution here\n}"
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-1c-put-functions-into-an-r-package",
    "href": "projects/2023-11-07-project-2/index.html#part-1c-put-functions-into-an-r-package",
    "title": "Project 2",
    "section": "Part 1C: Put functions into an R package",
    "text": "Part 1C: Put functions into an R package\nCreate an R package for the functions you wrote from Part 1A and 1B. Your package will have three exported functions for users to call (see below). You will need to write documentation for each function that you export. Your package should include the functions:\n\nfn_cos(), which computes the approximation to the cosine function (exported)\nfn_sin(), which computes the approximation to the sine function (exported)\nsample_mean(), which calculates the sample mean (not exported)\nsample_sd(), which calculates the sample standard deviation (not exported)\ncalculate_CI(), which calculates the confidence intervals from simulated data (exported)\n\n\n\n\n\n\n\nNotes\n\n\n\n\nRemember that you should only export the functions that you want the user to use.\nFunctions that are not exported do not require any documentation.\nEach exported function should have at least one example of its usage (using the @example directive in the documentation).\nIn the functions in your package, consider using control structures and include checks (e.g. is.na(), is.numeric(), if()) to make sure the input is as you expect it to be. For example, try to break the the function with unexpected values that a user might provide (e.g. providing a negative value to a log transformation). This can help guide you on ways to address the possible ways to break the function.\nYour package should be installable without any warnings or errors."
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-3a-create-a-vignette",
    "href": "projects/2023-11-07-project-2/index.html#part-3a-create-a-vignette",
    "title": "Project 2",
    "section": "Part 3A: Create a vignette",
    "text": "Part 3A: Create a vignette\nIn this part, you will create a vignette where you demonstrate the functions in your R package. Specifically, you will create a R Markdown and put it in a folder called “vignettes” within your R package. The purpose of a vignette is to demonstrate the functions of your package in a longer tutorial instead of just short examples within the documentation of your functions (i.e. using the @example directive in the documentation).\n\n\n\n\n\n\nNote\n\n\n\nYou might find the use_vignette() function from the usethis R package helpful."
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-3b-create-a-readme.md-file",
    "href": "projects/2023-11-07-project-2/index.html#part-3b-create-a-readme.md-file",
    "title": "Project 2",
    "section": "Part 3B: Create a README.md file",
    "text": "Part 3B: Create a README.md file\nCreate a README.md file in the R package, which will be useful to readers when they learn about your package. The readme must include:\n\nThe title of package\nThe author of the package\nA goal / description of the package\nA list of exported functions that are in the package. Briefly describe each function.\nA basic example with one of the functions.\n\n\n\n\n\n\n\nNote\n\n\n\nYou might find the use_readme_md() function from the usethis R package helpful."
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-3c-demonstrate-fn_cos",
    "href": "projects/2023-11-07-project-2/index.html#part-3c-demonstrate-fn_cos",
    "title": "Project 2",
    "section": "Part 3C: Demonstrate fn_cos()",
    "text": "Part 3C: Demonstrate fn_cos()\nIn the vignette, make a plot and show the output of your function fn_cos(x,k) and how it approximates the cos(x) function from base R as \\(k\\) increases.\n\n\n\n\n\n\nNotes\n\n\n\n\nThe x-axis should range between 0 and 10.\nThe y-axis should be the output from fn_cos(x,k) or cos(x).\nPlot the output from cos(x) as points on the graph.\nPlot the output from fn_cos(x,k) as lines on the graph.\nShow 5 lines for values k = 1, 3, 5, 7, 9. Each line should be a different color."
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-3d-demonstrate-fn_sin",
    "href": "projects/2023-11-07-project-2/index.html#part-3d-demonstrate-fn_sin",
    "title": "Project 2",
    "section": "Part 3D: Demonstrate fn_sin()",
    "text": "Part 3D: Demonstrate fn_sin()\nRepeat a similar task and make a similar plot as in Part 3C, but here using fn_sin() instead of fn_cos()."
  },
  {
    "objectID": "projects/2023-11-07-project-2/index.html#part-3e-demonstrate-calculate_ci",
    "href": "projects/2023-11-07-project-2/index.html#part-3e-demonstrate-calculate_ci",
    "title": "Project 2",
    "section": "Part 3E: Demonstrate calculate_CI()",
    "text": "Part 3E: Demonstrate calculate_CI()\nThe goal here is to demonstrate the calculate_CI() function in your package inside the vignette with some example data from TidyTuesday. However, part of the requirement is to also wrangle and plot the data. At the end of the section, you must demonstrate how to apply calculate_CI() as an example to the data.\nOther requirements for this part of vignette are the following:\n\nPick any dataset you wish from TidyTuesday to analyze.\n\n\nYou must describe what is the question you aim to answer with the data and data analysis.\nYou must describe and link to where the original data come from that you chose.\nYou must include a link to a data dictionary for the data or create one inside the webpage.\n\n\nLoad the data into R (you must show the code from this section)\n\n\nIn this step, you must test if a directory named data exists locally. If it does not, write an R function that creates it programmatically.\n\nSaves the data only once (not each time you knit/render the document).\nRead in the data locally each time you knit/render.\n\n\nYour analysis must include some form of data wrangling and data visualization.\n\n\nYou must use at least eight different functions from dplyr, tidyr, lubridate, stringr, or forcats.\nYour analysis should include at least three plots with you using at least three different geom_*() functions from ggplot2 (or another package with geom_*() functions).\n\nPlots should have titles, subtitles, captions, and human-understandable axis labels.\n\n\n\nApply the function calculate_CI() at least once in the vignette.\n\n\nSummarize and interpret the results in 1-2 sentences.\n\n\nAt the end of the data analysis, list out each of the functions you used from each of the packages (dplyr, tidyr, ggplot2, etc) to help the TA with respect to making sure you met all the requirements described above."
  },
  {
    "objectID": "projects/2023-12-12-project-4/index.html",
    "href": "projects/2023-12-12-project-4/index.html",
    "title": "Project 4",
    "section": "",
    "text": "Background\n\nlibrary(tidyverse)\n\nDue date: December 22 at 11:59pm\nThe goal of this assignment is to practice building interactive dashboards and building effective data visualizations to communicate to an audience.\n\n\nTo submit your project\n\nCreate a public github repository for yourself. The link to create the repository will be in CoursePlus.\nFollow the instructions below and push all your code to this github repository.\nThen, you will also need to deploy your dashboard. As an example, here is a deployed interactive dashboard from the lecture we had on dashboards (https://stephaniehicks.shinyapps.io/OldFaithfulGeyser).\nYou must include a README.md in your github repository with your source code that includes a link to your deployed dashboard.\nShare a link to your github repo with your code and your deployed interactive dashboard on CoursePlus.\n\n\n\n\nPart 1: Identify the data\nPick a dataset from one of the datasets that you used in Project 3. You can also pick a different dataset if you wish, but to help minimize work in this project, you are encouraged to pick a dataset that you already are familiar with from Project 3.\nOnce you identify the dataset, save the data locally in your project repository to be able to load into R:\n\nIn this step, you must test if a directory named data exists locally. If it does not, write an R function that creates it programmatically.\n\nSave the data only once.\nRead in the data locally each time you knit/render.\n\n\n\nPart 2: Design the interactive dashbard\nUsing the data analysis that you created from Project 3, think about the following topics and questions from Project 3. You do not have to formally answer any the questions right now, but use them to help design your dashboard.\n\nMotivation and Overview: What are the goals and motivation of the data analysis?\nRelated Work: Anything that inspired you, such as a paper, a web site, or something we discussed in class.\nData Analytic Questions: What question(s) are you trying to answer with the data and data analysis? Did the questions change as you began to explore the data? What new questions did you consider in the course of your analysis? What variables seemed important or not important?\nAudience: Who is the target audience for your analysis? Should they be expected to have a specific background or knowledge?\nData: What are the original data sources? Is there a data dictionary or did you create a table yourself?\nExploratory Data Analysis: What visualizations did you use to look at your data in different ways? Did you consider statistical models (e.g. inference or prediction)? How did you decide? Were there any major changes to your ideas? How did you reach these conclusions?\nData visualization: What data analytic components (e.g. tables, plots, etc) would be useful to show in a static format versus an interactive format?\nNarrative and Summary: What did you learn from the data and data analysis? How did you answer the questions? How can you justify your answers? What are the key/important takeaways for the audience? What are the limitations of the analyses?\n\n\n\nPart 3: Build an interactive dashboard\nBuild an interactive dashboard with the following criteria. Outside of the following criteria, create a dashboard that effectively communicates the key ideas about the data or data analysis. You are strongly encouraged to spend time exploring flexdashboard and shiny to customize your dashboard beyond the following criteria. For example, you are welcomed to get inspired by dashboards you find online.\nSpecific criteria your dashboard must have:\n\nAbout tab: This must describe the purpose of the dashboard and a link or original location of the data.\nThe Data tab: A description of the data along with a table of the dataset.\nTwo tabs with static content. Within one of the tabs for the static content, there must be additional tabs.\nTwo tabs with interactive content. One of these tabs need to include some type of interactive plots. The other tab can be any other type of interactive content.\n\nAnalysis tab. This tab should contain the analysis you built for Project 3.\n\n\n\nPart 4: Make a two minute video\nMake a two minute (max!) screencast with narration showing highlights of your data analysis and a demo of your dashboard. There are several ways to do this, but one way is to join a zoom room, share your screen, and record yourself. When you are done, upload the video to YouTube or Vimeo and embed it into the dashboard.\n\n\n\n\n\n\nTip\n\n\n\nThere are several ways to do this, but I like to embed an iframe into the .Rmd\n\nhttps://www.eckher.com/c/21g4zwwx48\n\n\n\nUse principles of good storytelling and presentations to get your key points across.\n\nFocus the majority of your screencast on your main contributions rather than on technical details.\nWhat do you feel is the best part of your data analysis and dashboard?\nWhat insights did you gain?\nWhat is the single most important thing you would like your audience to take away? Make sure it is upfront and center rather than at the end.\n\n\n\nPart 5: Deploy dashboard and push code to Github\n\nUsing the public github repository that you created from CoursePlus, push your source code for this dashboard to GitHub.\nDeploy the website using shinyapps.io. As an example, here is a deployed interactive dashboard from our lecture on dashboards (https://stephaniehicks.shinyapps.io/OldFaithfulGeyser).\nInclude a README.md file in the GitHub repository with your name and a link to the deployed dashboard.\n\nShare a link to your github repo with your code and your deployed interactive dashboard on CoursePlus."
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "For Qmd files, go to the course GitHub repository and navigate the directories, or best of all to clone the repo and navigate within RStudio.\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopics\nProjects\n\n\n\n\n\nModule 1\n\nStatistical programming at the command-line\n\n\n\n\n\n\n\n\n\n\n\nWeek 1\nOct 26\nCourse introduction [syllabus]\n🌴 Project 1 [html] [Qmd]\n\n\n\n\n\nBuilding websites with quarto [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\nOct 31\nIntroduction to the command-line [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 2\nMore advanced command-line tools [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nWeek 3\nNov 7\nVersion control (git) [html] [Qmd]\n🌴 Project 2 [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nNov 9\nVersion control (GitHub) [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 10\n\n🍂 Project 1 due\n\n\n\n\n\n\n\n\n\n\nModule 2\n\nR software development\n\n\n\n\n\n\n\n\n\n\n\nWeek 4\nNov 14\nObject Oriented Programming [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 16\nMore OOP\n\n\n\n\n\n\n\n\n\n\n\nWeek 5\nNov 21\nR package software development [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 23\n🦃 No lecture, enjoy the break!\n\n\n\n\n\n\n\n\n\n\n\n\nNov 24\n\n\n\n\n\n\n\n\n\n\n\n\nModule 3\n\nAdvanced programming paradigms\n\n\n\n\n\n\n\n\n\n\n\nWeek 6\nNov 28\nFunctional programming with purrr [html] [Qmd]\n🍂 Project 2 due  🌴 Project 3 [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nNov 30\nPackage website with pkgdown [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nWeek 7\nDec 5\nRetrieving data from APIs [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 7\nRelational databases and SQL basics [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nModule 4\n\nInteractive web apps and dashboards\n\n\n\n\n\n\n\n\n\n\n\nWeek 8\nDec 12\nBuilding dashboards with flexdashboard and shinydashboard [html] [Qmd]\n🍂 Project 3 due  🌴 Project 4 [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nDec 14\nScraping data from the web with rvest [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nModule 5\n\nDealing with “big” data\n\n\n\n\n\n\n\n\n\n\n\nWeek 9\nDec 19\nStrategies for dealing with large data [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nDec 21\n❄️ Class is canceled\n\n\n\n\n\n\n\n\n\n\n\n\nDec 22\n\n🍂 Project 4 due"
  },
  {
    "objectID": "schedule.html#schedule-and-course-materials",
    "href": "schedule.html#schedule-and-course-materials",
    "title": "Schedule",
    "section": "",
    "text": "For Qmd files, go to the course GitHub repository and navigate the directories, or best of all to clone the repo and navigate within RStudio.\n\n\n\n\n\n\n\n\n\n\n\nWeek\nDates\nTopics\nProjects\n\n\n\n\n\nModule 1\n\nStatistical programming at the command-line\n\n\n\n\n\n\n\n\n\n\n\nWeek 1\nOct 26\nCourse introduction [syllabus]\n🌴 Project 1 [html] [Qmd]\n\n\n\n\n\nBuilding websites with quarto [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek 2\nOct 31\nIntroduction to the command-line [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 2\nMore advanced command-line tools [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nWeek 3\nNov 7\nVersion control (git) [html] [Qmd]\n🌴 Project 2 [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nNov 9\nVersion control (GitHub) [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 10\n\n🍂 Project 1 due\n\n\n\n\n\n\n\n\n\n\nModule 2\n\nR software development\n\n\n\n\n\n\n\n\n\n\n\nWeek 4\nNov 14\nObject Oriented Programming [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 16\nMore OOP\n\n\n\n\n\n\n\n\n\n\n\nWeek 5\nNov 21\nR package software development [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nNov 23\n🦃 No lecture, enjoy the break!\n\n\n\n\n\n\n\n\n\n\n\n\nNov 24\n\n\n\n\n\n\n\n\n\n\n\n\nModule 3\n\nAdvanced programming paradigms\n\n\n\n\n\n\n\n\n\n\n\nWeek 6\nNov 28\nFunctional programming with purrr [html] [Qmd]\n🍂 Project 2 due  🌴 Project 3 [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nNov 30\nPackage website with pkgdown [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nWeek 7\nDec 5\nRetrieving data from APIs [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDec 7\nRelational databases and SQL basics [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nModule 4\n\nInteractive web apps and dashboards\n\n\n\n\n\n\n\n\n\n\n\nWeek 8\nDec 12\nBuilding dashboards with flexdashboard and shinydashboard [html] [Qmd]\n🍂 Project 3 due  🌴 Project 4 [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nDec 14\nScraping data from the web with rvest [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\nModule 5\n\nDealing with “big” data\n\n\n\n\n\n\n\n\n\n\n\nWeek 9\nDec 19\nStrategies for dealing with large data [html] [Qmd]\n\n\n\n\n\n\n\n\n\n\n\n\nDec 21\n❄️ Class is canceled\n\n\n\n\n\n\n\n\n\n\n\n\nDec 22\n\n🍂 Project 4 due"
  }
]