{
  "hash": "1d64b2a2d6773ca7e9d8e6302273b95c",
  "result": {
    "markdown": "---\ntitle: \"Retrieving data from APIs with `httr`\"\nauthor: \n  - name: Joe Sartini\n    affiliation: Department of Biostatistics, Johns Hopkins\n    affiliation_url: https://publichealth.jhu.edu\ndescription: \"Introduction to JSON files and interacting with APIs with `httr`\"\ndate: 2023-12-05\ncategories: [module 3, week 7, JSON, APIs, httr]\n---\n\n\n# Pre-lecture materials\n\n### Read ahead\n\n::: callout-note\n## Read ahead\n\n**Before class, you can prepare by reading the following materials:**\n\n1. <https://jeroen.cran.dev/jsonlite>\n2. <https://httr.r-lib.org>\n:::\n\n\n### Acknowledgements\n\nMaterial for this lecture was borrowed and adopted from\n\n- <https://jhu-advdatasci.github.io/2019/lectures/04-gettingdata-api.html>\n- <https://aws.amazon.com/what-is/api>\n- <https://bookdown.org/paul/apis_for_social_scientists/github.com-api.html>\n- <https://statisticsglobe.com/api-in-r>\n\n### Install new packages\n\nBefore we begin, you will need to install\nthese packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\ninstall.packages(\"jsonlite\")\ninstall.packages(\"httr\")\n```\n:::\n\n\nNow we load a few R packages\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(jsonlite)\nlibrary(httr)\n```\n:::\n\n\n\n\n# Learning objectives\n\n::: callout-note\n\n**At the end of this lesson you will:**\n\n- Describe what the difference is between \"raw\" vs \"clean\" data\n- Learn about what are JSON files and how we can convert them into data frames in R \n- Describe some best practices on sharing data with collaborators\n- Know what does API mean and state four types of API architectures\n- Practice with two APIs: the GitHub API and the openFDA API\n\n:::\n\n# Motivation\n\nToday, we are going to talk about getting data from APIs and\nexamples of common data formats. \n\nFirst, let's have a bit of a philosophical discussion about data. \n\n## \"Raw\" vs \"Clean\" data\n\nAs data analysts, this is what we wished data \nlooked like whenever we start a project\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/tidy-data-example.png)\n:::\n:::\n\n\nHowever, the reality, is data is rarely in that \nform in comes in all types of _\"raw\"_ formats that \nneed to be transformed into a _\"clean\"_ format. \n\nFor example, in field of genomics, raw data \nlooks like something like this: \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/fastq.png)\n:::\n:::\n\n\nOr if you are interested in analyzing data from \nTwitter: \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/twitter-api.png)\n:::\n:::\n\n\nOr data from Electronic Healthcare Records (EHRs): \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/ehr.png)\n:::\n:::\n\n\nWe all have our scary spreadsheet tales. Here is \nJenny Bryan from Posit and UBC actually asking \nfor some of those spreadsheet tales on twitter. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/spreadsheet-tales.png)\n:::\n:::\n\n\nFor example, this is an actual \n[spreadsheet from Enron in 2001](https://github.com/jennybc/2016-06_spreadsheets/blob/master/2016-06_useR-stanford.pdf): \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/enron-spreadsheet.png)\n:::\n:::\n\n\n## What do we mean by \"raw\" data? \n\nFrom [https://simplystatistics.org/posts/2016-07-20-relativity-raw-data/](https://simplystatistics.org/posts/2016-07-20-relativity-raw-data/)\nraw data is defined as data... \n\n> ...if you have done no processing, manipulation, coding, or analysis of the data. In other words, the file you received from the person before you is untouched. But it may not be the rawest version of the data. The person who gave you the raw data may have done some computations. They have a different \"raw data set\".\n\n## Where do data live? \n\nData lives anywhere and everywhere. Data \nmight be stored simply in a `.csv` or `.txt`\nfile. Data might be stored in an Excel or \nGoogle Spreadsheet. Data might be stored in \nlarge databases that require users to write \nspecial functions to interact with to extract \nthe data they are interested in. \n\nFor example, you may have heard of the terms \n`mySQL` or `MongoDB`. \n\nFrom [Wikipedia, MySQL](https://en.wikipedia.org/wiki/MySQL) \nis defined as _an open-source relational database management system (RDBMS). Its name is a combination of \"My\", the name of co-founder Michael Widenius's daughter,[7] and \"SQL\", the abbreviation for Structured Query Language_. \n\nFrom [Wikipeda, MongoDB](https://en.wikipedia.org/wiki/MongoDB)\nis defined as _\"a free and open-source cross-platform document-oriented database program. Classified as a NoSQL database program, MongoDB uses JSON-like documents with schemata.\"_\n\nSo after reading that, we get the sense that there\nare multiple ways large databases can be structured, \ndata can be formatted and interacted with. \nIn addition, we see that database programs \n(e.g. MySQL and MongoDB) can also interact \nwith each other.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/databases.png)\n:::\n:::\n\n\nWe will learn more about `JSON` today and learn about `SQL` in a later lecture more formally. \n\n# Best practices on sharing data\n\nA great article in PeerJ was written \ntitled [_How to share data for collaboration_](https://peerj.com/preprints/3139v5.pdf), \nin which the authors describe a set of guidelines\nfor sharing data:\n\n> We highlight the need to provide raw data to the statistician, the importance of consistent formatting, and the necessity of including all essential experimental information and pre-processing steps carried out to the statistician. With these guidelines we hope to avoid errors and delays in data analysis. the importance of consistent formatting, and the necessity of including all essential experimental information and pre-processing steps carried out to the statistician.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/ellis-datashare.png)\n:::\n:::\n\n\nIt's a great paper that describes the information \nyou should pass to a statistician to facilitate \nthe most efficient and timely analysis. \n\nSpecifically:\n\n1. The raw data (or the rawest form of the data to which you have access)\n    * Should not have modified, removed or summarized any data; Ran no software on data\n    * e.g. strange binary file your measurement machine spits out\n    * e.g. complicated JSON file you scrapped from Twitter Application Programming Interfaces (API)\n    * e.g. hand-entered numbers you collected looking through a microscope\n\n2. A clean data set\n    * This may or may not be transforming data into a `tidy` dataset, but possibly yes\n\n3. A code book describing each variable and its values in the clean or tidy data set.\n    * More detailed information about the measurements in the data set (e.g. units, experimental design, summary choices made)\n    * Doesn't quite fit into the column names in the spreadsheet\n    * Often reported in a `.md`, `.txt` or Word file. \n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/code-book.png)\n:::\n:::\n\n\n4. An explicit and exact recipe you used to go from 1 -> 2,3\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](https://github.com/jtleek/advdatasci/raw/master/imgs/recipe-best.png)\n:::\n:::\n\n\n# Getting data\n\n## JSON files \n\nJSON (or JavaScript Object Notation) is a file\nformat that stores information in human-readable, \norganized, logical, easy-to-access manner.\n\nFor example, here is what a JSON file looks \nlike: \n\n``` md\nvar stephanie = {\n\t\"job-title\" : \"Associate Professor\",\n\t\"hometown\" : \"Baltimore, MD\",\n\t\"pronouns\": \"she/her\",\n  \"states-lived\" : {\n    \"state1\" : \"Louisiana\",\n    \"state2\" : \"Texas\",\n    \"state3\" : \"Massachusetts\",\n    \"state4\" : \"Maryland\"\n  }\n}\n```\n\nSome features about `JSON` objects: \n\n* JSON objects are surrounded by curly braces `{}`\n* JSON objects are written in key/value pairs\n* Keys must be strings, and values must be a valid JSON data type (string, number, object, array, boolean)\n* Keys and values are separated by a colon\n* Each key/value pair is separated by a comma\n\n\n\n## Overview of APIs\n\n[From AWS](https://aws.amazon.com/what-is/api/), API stands for **Application Programming Interface**. \n\n- \"Application\" = any **software** with a distinct function\n- \"Interface\" = a **contract of service** between two applications. This contract defines how the two communicate with each other using requests and responses. \n\nThe **API documentation** contains information on how developers are to structure those requests and responses.\n\n:::{.callout-tip}\n\n### Purpose of APIs\n\nThe purpose of APIs is enable two software components to communicate with each other using a set of definitions and protocols. \n\nFor example, the weather bureau’s software system contains daily weather data. The weather app on your phone \"talks\" to this system via APIs and shows you daily weather updates on your phone.\n\n:::\n\n\n### How do APIs work?\n\nTo understand how APIs work, two terms that are important are \n\n1. **client**. This is the application sending the request.\n2. **server**. This is the application sending the response.\n\nSo in the weather example, the bureau's weather database is the server, and the mobile app is the client. \n\n### Four types of API architectures\n\nThere are four different ways that APIs can work depending on when and why they were created.\n\n1. **SOAP APIs**. These APIs use **Simple Object Access Protocol**. Client and server exchange messages using XML. This is a less flexible API that was more popular in the past.\n\n2. **RPC APIs**. These APIs are called **Remote Procedure Calls**. The client completes a function (or procedure) on the server, and the server sends the output back to the client.\n\n3. **Websocket APIs**. Websocket API is another **modern web** API development that uses JSON objects to pass data. A WebSocket API supports two-way communication between client apps and the server. The server can send callback messages to connected clients, making it more efficient than REST API.\n\n4. **REST APIs**. REST stands for **Representational State Transfer** (and are the most popular and flexible APIs). The client sends requests to the server as data. The server uses this client input to start internal functions and returns output data back to the client. REST defines a set of functions like GET, PUT, DELETE, etc. that clients can use to access server data. Clients and servers exchange data using HTTP.\n\nThe main feature of REST API is **statelessness** (i.e. servers do not save client data between requests). Client requests to the server are similar to URLs you type in your browser to visit a website. The response from the server is plain data, without the typical graphical rendering of a web page.\n\n\n### How to use an API?\n\nThe basic steps to using an API are:\n\n1. **Obtaining an API key**. This is done by creating a verified account with the API provider.\n2. **Set up an HTTP API client**. This tool allows you to structure API requests easily using the API keys received. Here, we will use the `GET()` function from the `httr` package. \n3. If you don’t have an API client, you can try to structure the request yourself in your browser by referring to the API documentation.\n4. Once you are comfortable with the new API syntax, you can start using it in your code.\n\n\n### Where can I find new APIs?\n\nNew web APIs can be found on API marketplaces and API directories, such as:\n\n- [Rapid API](https://rapidapi.com/) – One of the largest global API markets (10k+ public APIs). Users to test APIs directly on the platform before committing to purchase.\n- [Public REST APIs](https://documenter.getpostman.com/view/8854915/Szf7znEe) – Groups REST APIs into categories, making it easier to browse and find the right one to meet your needs.\n- [APIForThat](https://apiforthat.posthaven.com/) and [APIList](https://apilist.fun) – Both these websites have lists of 500+ web APIs, along with in-depth information on how to use them.    \n\n\n# GitHub API\n\nThe [GitHub REST API](https://docs.github.com/en/rest) may be of interest when studying online communities, working methods, organizational structures, communication and discussions, etc. with a focus on (open-source) software development. \n\nMany projects that are hosted on GitHub are open-source projects with a transparent development process and communications. For private projects, which can also be hosted on GitHub, there’s understandably only a few aggregate data available.\n\nLet's say we want to use the \n[GitHub REST API](https://docs.github.com/en/rest)\nto find out how many of my GitHub repositories\nhave open issues? \n\n:::{.callout-tip}\n\n### Pro-tip\n\nThe API can be used for free and you can send up to 60 requests per hour if you are not authenticated (i.e. if you don’t provide an API key). \n\nFor serious data collection, this is not much, so it is recommended to sign up on GitHub and generate a personal access token that acts as API key. \n\nThis token can then be used to authenticate your API requests. Your quota is then 5000 requests per hour.\n\n:::\n\n## Access the API from R\n\nThere are packages for many programming languages that provide convenient access for communicating with the GitHub API, but there are no such packages (that I'm aware of) for accessing the API from R.  \n\nThis means we can only access the API directly, e.g. by using the [`jsonlite`](https://cran.r-project.org/web/packages/jsonlite/index.html) package to fetch the data and convert it to an R `list` or `data.frame`.\n\nSpecifically, we will use the `jsonlite::fromJSON()` function\nto convert from a JSON object to a data frame. \n\nThe JSON file is located at \n[https://api.github.com/users/stephaniehicks/repos](https://api.github.com/users/stephaniehicks/repos)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngithub_url = \"https://api.github.com/users/stephaniehicks/repos\"\n\nlibrary(jsonlite)\nlibrary(tidyverse)\njsonData <- as_tibble(fromJSON(github_url))\nglimpse(jsonData)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 30\nColumns: 79\n$ id                          <int> 160194123, 132884754, 647539937, 225501707…\n$ node_id                     <chr> \"MDEwOlJlcG9zaXRvcnkxNjAxOTQxMjM=\", \"MDEwO…\n$ name                        <chr> \"2018-bioinfosummer-scrnaseq\", \"advdatasci…\n$ full_name                   <chr> \"stephaniehicks/2018-bioinfosummer-scrnase…\n$ private                     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ owner                       <df[,18]> <data.frame[26 x 18]>\n$ html_url                    <chr> \"https://github.com/stephaniehicks/201…\n$ description                 <chr> NA, NA, \"Repo to share code for the atlas-…\n$ fork                        <lgl> FALSE, TRUE, FALSE, TRUE, TRUE, FALSE, FAL…\n$ url                         <chr> \"https://api.github.com/repos/stephaniehic…\n$ forks_url                   <chr> \"https://api.github.com/repos/stephaniehic…\n$ keys_url                    <chr> \"https://api.github.com/repos/stephaniehic…\n$ collaborators_url           <chr> \"https://api.github.com/repos/stephaniehic…\n$ teams_url                   <chr> \"https://api.github.com/repos/stephaniehic…\n$ hooks_url                   <chr> \"https://api.github.com/repos/stephaniehic…\n$ issue_events_url            <chr> \"https://api.github.com/repos/stephaniehic…\n$ events_url                  <chr> \"https://api.github.com/repos/stephaniehic…\n$ assignees_url               <chr> \"https://api.github.com/repos/stephaniehic…\n$ branches_url                <chr> \"https://api.github.com/repos/stephaniehic…\n$ tags_url                    <chr> \"https://api.github.com/repos/stephaniehic…\n$ blobs_url                   <chr> \"https://api.github.com/repos/stephaniehic…\n$ git_tags_url                <chr> \"https://api.github.com/repos/stephaniehic…\n$ git_refs_url                <chr> \"https://api.github.com/repos/stephaniehic…\n$ trees_url                   <chr> \"https://api.github.com/repos/stephaniehic…\n$ statuses_url                <chr> \"https://api.github.com/repos/stephaniehic…\n$ languages_url               <chr> \"https://api.github.com/repos/stephaniehic…\n$ stargazers_url              <chr> \"https://api.github.com/repos/stephaniehic…\n$ contributors_url            <chr> \"https://api.github.com/repos/stephaniehic…\n$ subscribers_url             <chr> \"https://api.github.com/repos/stephaniehic…\n$ subscription_url            <chr> \"https://api.github.com/repos/stephaniehic…\n$ commits_url                 <chr> \"https://api.github.com/repos/stephaniehic…\n$ git_commits_url             <chr> \"https://api.github.com/repos/stephaniehic…\n$ comments_url                <chr> \"https://api.github.com/repos/stephaniehic…\n$ issue_comment_url           <chr> \"https://api.github.com/repos/stephaniehic…\n$ contents_url                <chr> \"https://api.github.com/repos/stephaniehic…\n$ compare_url                 <chr> \"https://api.github.com/repos/stephaniehic…\n$ merges_url                  <chr> \"https://api.github.com/repos/stephaniehic…\n$ archive_url                 <chr> \"https://api.github.com/repos/stephaniehic…\n$ downloads_url               <chr> \"https://api.github.com/repos/stephaniehic…\n$ issues_url                  <chr> \"https://api.github.com/repos/stephaniehic…\n$ pulls_url                   <chr> \"https://api.github.com/repos/stephaniehic…\n$ milestones_url              <chr> \"https://api.github.com/repos/stephaniehic…\n$ notifications_url           <chr> \"https://api.github.com/repos/stephaniehic…\n$ labels_url                  <chr> \"https://api.github.com/repos/stephaniehic…\n$ releases_url                <chr> \"https://api.github.com/repos/stephaniehic…\n$ deployments_url             <chr> \"https://api.github.com/repos/stephaniehic…\n$ created_at                  <chr> \"2018-12-03T13:20:45Z\", \"2018-05-10T10:22:…\n$ updated_at                  <chr> \"2019-08-08T02:18:17Z\", \"2018-05-10T10:22:…\n$ pushed_at                   <chr> \"2018-12-05T17:07:09Z\", \"2017-12-18T17:18:…\n$ git_url                     <chr> \"git://github.com/stephaniehicks/2018-bioi…\n$ ssh_url                     <chr> \"git@github.com:stephaniehicks/2018-bioinf…\n$ clone_url                   <chr> \"https://github.com/stephaniehicks/2018-bi…\n$ svn_url                     <chr> \"https://github.com/stephaniehicks/2018-bi…\n$ homepage                    <chr> NA, NA, NA, NA, NA, \"\", NA, NA, NA, NA, NA…\n$ size                        <int> 60296, 172353, 8858, 121, 675, 26688, 20, …\n$ stargazers_count            <int> 4, 0, 1, 1, 0, 0, 1, 8, 0, 1, 0, 14, 3, 0,…\n$ watchers_count              <int> 4, 0, 1, 1, 0, 0, 1, 8, 0, 1, 0, 14, 3, 0,…\n$ language                    <chr> \"TeX\", \"HTML\", \"R\", NA, NA, \"R\", \"R\", \"Jup…\n$ has_issues                  <lgl> TRUE, FALSE, TRUE, FALSE, FALSE, TRUE, TRU…\n$ has_projects                <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_downloads               <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_wiki                    <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ has_pages                   <lgl> TRUE, FALSE, FALSE, FALSE, FALSE, FALSE, F…\n$ has_discussions             <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ forks_count                 <int> 4, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 4, 1, 1, …\n$ mirror_url                  <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\n$ archived                    <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ disabled                    <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ open_issues_count           <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ license                     <df[,5]> <data.frame[26 x 5]>\n$ allow_forking               <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, …\n$ is_template                 <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\n$ web_commit_signoff_required <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, …\n$ topics                      <list> <>, <>, <>, <>, <>, <>, <>, <>, <>, <>, <>…\n$ visibility                  <chr> \"public\", \"public\", \"public\", \"public\", \"p…\n$ forks                       <int> 4, 0, 0, 0, 1, 1, 0, 2, 0, 0, 0, 4, 1, 1,…\n$ open_issues                 <int> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ watchers                    <int> 4, 0, 1, 1, 0, 0, 1, 8, 0, 1, 0, 14, 3, 0,…\n$ default_branch              <chr> \"master\", \"master\", \"main\", \"master\", \"mas…\n```\n:::\n:::\n\n\nThe function `fromJSON()` has now converted the JSON file into a data frame. \n\nHowever, from here, we see that there are only 30 rows (or 30 repositories). \nIf you look on my github page, you can see there are more than 30 repositories. \n\n- <https://github.com/stephaniehicks?tab=repositories> \n\n\n:::{.callout-tip}\n\n### APIs limit info from users\n\nWhat's happening is called **pagination**. \n\nAt a high-level, the API is limiting the amount of items a user gets and **splitting it into pages**.\n\nFormally, pagination is the process of splitting the contents or a section of a website into discrete pages. Users tend to get lost when there's bunch of data and with pagination splitting they can concentrate on a particular amount of content. Hierarchy and paginated structure improve the readability score of the content.\n\nIn this use case Github api splits the result into 30 items per resonse, depends on the request\n\n:::\n\n\n\n**Solution**: You should explicitly specify in your request how many items you would like to receive from server pagination engine, using formula for Github pagination api: \n\n`?page=1&per_page=<numberOfItemsYouSpecify>\"`\n\nYou can read more about pagination here: \n\n- <https://docs.github.com/en/rest/guides/using-pagination-in-the-rest-api>\n\n\n\n:::{.callout-tip}\n\n### Example\n\nHere we can visit this website: \n\n- <https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000> \n\nAnd see there are more than 30 repos. Let's read it into R. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ngithub_url = \"https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000\"\n\njsonDataAll <- as_tibble(fromJSON(github_url))\ndim(jsonDataAll)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 90 79\n```\n:::\n:::\n\n\nWe now get all the public repositories! yay! \n\n:::\n\n\n## Using API keys\n\nAuthenticating with the GitHub API via an API key allows you to send much more requests to the API. \n\nAPI access keys for the GitHub API are called **personal access tokens** (PAT) and the [documentation explains how to generate a PAT](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token) once you have logged into your GitHub account. \n\n:::{.callout-tip}\n\n### Where to store API keys\n\nFirst, **please be careful with your PATs and never publish them.**\n\nIf you want guidance on where you should store them, I like this post: \n\n- <https://www.r-bloggers.com/2015/11/how-to-store-and-use-webservice-keys-and-authentication-details-with-r/> \n\nPersonally, I keep mine in my `.Renviron` file which looks something like this on the inside: \n\n```\nGITHUB_API_KEY = <add my GitHub API key here> \nCENSUS_API_KEY = <add my tidycensus API key here> \nOPENFDA_API_KEY = <add my openFDA API key here> \n```\n\nIf you do not have an `.Renviron` file in your home directory, you can make one: \n\n``` bash\ncd ~\ntouch .Renviron\n```\n\n:::\n\n\nAssuming you have created and stored an API key in the `.Renviron` file in your home directory, you can fetch it with the `Sys.getenv()` function. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ngithub_key <- Sys.getenv(\"GITHUB_API_KEY\")\n```\n:::\n\n\nWe will use this in a little bit. \n\n\n\n## Access API with `httr` and `GET`\n\nThere are a set of [basic HTTP verbs](https://docs.oracle.com/en/cloud/saas/marketing/eloqua-develop/Developers/GettingStarted/APIRequests/HTTP-verbs.htm) that allow you access a set of **endpoints**. \n\nThe basic request patterns are:\n\n- Retrieve a single item (GET)\n- Retrieve a list of items (GET)\n- Create an item (POST)\n- Update an item (PUT)\n- Delete an item (DELETE)\n\nHere, we will use the `GET()` function from [`httr`](https://cran.r-project.org/web/packages/httr/index.html) package (i.e. tools to work with URLs and HTTP) to retrieve a single JSON file. \n\nWe will also make this an **authenticated HTTP response** to the GitHub API using `authenticate()` from the `httr` package. \n\n\n:::{.callout-tip}\n\n### Example \n\nLet's start by using the GitHub API to learn information about myself (Stephanie Hicks)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngithub_key <- Sys.getenv(\"GITHUB_API_KEY\")\nresponse <- GET('https://api.github.com/user', \n                authenticate(user = 'stephaniehicks', \n                             password = github_key))\nresponse\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse [https://api.github.com/user]\n  Date: 2023-11-24 10:21\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 1.76 kB\n{\n  \"login\": \"stephaniehicks\",\n  \"id\": 1452065,\n  \"node_id\": \"MDQ6VXNlcjE0NTIwNjU=\",\n  \"avatar_url\": \"https://avatars.githubusercontent.com/u/1452065?v=4\",\n  \"gravatar_id\": \"\",\n  \"url\": \"https://api.github.com/users/stephaniehicks\",\n  \"html_url\": \"https://github.com/stephaniehicks\",\n  \"followers_url\": \"https://api.github.com/users/stephaniehicks/followers\",\n  \"following_url\": \"https://api.github.com/users/stephaniehicks/following{/ot...\n...\n```\n:::\n:::\n\n\nWe see the response we got is a JSON file. \n\n:::\n\nNext we extract / retrieve the contents from the raw JSON output using the `content()` function from the `httr` package. If you use the argument `as = 'text'`, it extracts the contents as a character vector. \n\n\n::: {.cell}\n\n```{.r .cell-code}\naccount_details <- fromJSON(httr::content(response, as = 'text'))\naccount_details[1:30]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n$login\n[1] \"stephaniehicks\"\n\n$id\n[1] 1452065\n\n$node_id\n[1] \"MDQ6VXNlcjE0NTIwNjU=\"\n\n$avatar_url\n[1] \"https://avatars.githubusercontent.com/u/1452065?v=4\"\n\n$gravatar_id\n[1] \"\"\n\n$url\n[1] \"https://api.github.com/users/stephaniehicks\"\n\n$html_url\n[1] \"https://github.com/stephaniehicks\"\n\n$followers_url\n[1] \"https://api.github.com/users/stephaniehicks/followers\"\n\n$following_url\n[1] \"https://api.github.com/users/stephaniehicks/following{/other_user}\"\n\n$gists_url\n[1] \"https://api.github.com/users/stephaniehicks/gists{/gist_id}\"\n\n$starred_url\n[1] \"https://api.github.com/users/stephaniehicks/starred{/owner}{/repo}\"\n\n$subscriptions_url\n[1] \"https://api.github.com/users/stephaniehicks/subscriptions\"\n\n$organizations_url\n[1] \"https://api.github.com/users/stephaniehicks/orgs\"\n\n$repos_url\n[1] \"https://api.github.com/users/stephaniehicks/repos\"\n\n$events_url\n[1] \"https://api.github.com/users/stephaniehicks/events{/privacy}\"\n\n$received_events_url\n[1] \"https://api.github.com/users/stephaniehicks/received_events\"\n\n$type\n[1] \"User\"\n\n$site_admin\n[1] FALSE\n\n$name\n[1] \"Stephanie Hicks\"\n\n$company\n[1] \"Johns Hopkins\"\n\n$blog\n[1] \"http://www.stephaniehicks.com\"\n\n$location\n[1] \"Baltimore, MD\"\n\n$email\nNULL\n\n$hireable\nNULL\n\n$bio\n[1] \"Associate Prof at Johns Hopkins Biostatistics\"\n\n$twitter_username\n[1] \"stephaniehicks\"\n\n$public_repos\n[1] 90\n\n$public_gists\n[1] 8\n\n$followers\n[1] 275\n\n$following\n[1] 18\n```\n:::\n:::\n\n\nNext, let's perform the same request we did above about my 85 repositories, but instead of reading in the JSON file from the web, we use an authenticated `GET()` response: \n\n\n::: {.cell}\n\n```{.r .cell-code}\nresponse <- GET('https://api.github.com/users/stephaniehicks/repos?page=1&per_page=1000',\n                authenticate('stephaniehicks', github_key))\nrepo_details <- as_tibble(fromJSON(httr::content(response, as = 'text')))\nrepo_details\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 90 × 80\n       id node_id name  full_name private owner$login html_url description fork \n    <int> <chr>   <chr> <chr>     <lgl>   <chr>       <chr>    <chr>       <lgl>\n 1 1.60e8 MDEwOl… 2018… stephani… FALSE   stephanieh… https:/… <NA>        FALSE\n 2 1.33e8 MDEwOl… advd… stephani… FALSE   stephanieh… https:/… <NA>        TRUE \n 3 6.48e8 R_kgDO… atla… stephani… FALSE   stephanieh… https:/… Repo to sh… FALSE\n 4 2.26e8 MDEwOl… Awes… stephani… FALSE   stephanieh… https:/… A curated … TRUE \n 5 6.38e7 MDEwOl… awes… stephani… FALSE   stephanieh… https:/… List of so… TRUE \n 6 1.66e7 MDEwOl… Back… stephani… FALSE   stephanieh… https:/… Gene expre… FALSE\n 7 2.88e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… <NA>        FALSE\n 8 1.69e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… Benchmarki… FALSE\n 9 1.40e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… Repository… FALSE\n10 1.78e8 MDEwOl… benc… stephani… FALSE   stephanieh… https:/… Data and B… FALSE\n# ℹ 80 more rows\n# ℹ 88 more variables: owner$id <int>, $node_id <chr>, $avatar_url <chr>,\n#   $gravatar_id <chr>, $url <chr>, $html_url <chr>, $followers_url <chr>,\n#   $following_url <chr>, $gists_url <chr>, $starred_url <chr>,\n#   $subscriptions_url <chr>, $organizations_url <chr>, $repos_url <chr>,\n#   $events_url <chr>, $received_events_url <chr>, $type <chr>,\n#   $site_admin <lgl>, url <chr>, forks_url <chr>, keys_url <chr>, …\n```\n:::\n:::\n\n\n## A bit of EDA fun\n\nLet's have a bit of fun and explore some questions:  \n\n- How many have forks? How many forks? \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(repo_details$forks)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n 0  1  2  3  4  5  6  7  8  9 11 22 \n61 10  4  2  6  1  1  1  1  1  1  1 \n```\n:::\n:::\n\n\nWhat's the most popular language? \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(repo_details$language)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n             CSS             HTML       JavaScript Jupyter Notebook \n               1               20                7                1 \n        Makefile             Perl                R             Ruby \n               1                1               29                3 \n           Shell              TeX \n               2                5 \n```\n:::\n:::\n\n\nTo find out how many repos that I have\nwith open issues, we can just create \na table: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# how many repos have open issues? \ntable(repo_details$open_issues_count)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n 0  1  2 \n83  6  1 \n```\n:::\n:::\n\n\nWhew! Not as many as I thought.\n\n:::{.callout-tip}\n\n### More about `GET`\n\nYou can use the `query` argument to specify details about the response. \n\nLet's look how many open issues there are in the `dplyr` package in the `tidyverse`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreq <- GET(\"https://api.github.com/repos/tidyverse/dplyr/issues\", \n           query = list(state = \"open\", per_page = 100, page = 1))\ndplyr_details <- as_tibble(fromJSON(httr::content(req, as = 'text')))\ndplyr_details\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 × 30\n   url         repository_url labels_url comments_url events_url html_url     id\n   <chr>       <chr>          <chr>      <chr>        <chr>      <chr>     <int>\n 1 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.01e9\n 2 https://ap… https://api.g… https://a… https://api… https://a… https:/… 2.00e9\n 3 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.99e9\n 4 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.98e9\n 5 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.98e9\n 6 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.96e9\n 7 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.95e9\n 8 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.94e9\n 9 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.92e9\n10 https://ap… https://api.g… https://a… https://api… https://a… https:/… 1.87e9\n# ℹ 40 more rows\n# ℹ 23 more variables: node_id <chr>, number <int>, title <chr>,\n#   user <df[,18]>, labels <list>, state <chr>, locked <lgl>,\n#   assignee <df[,18]>, assignees <list>, milestone <lgl>, comments <int>,\n#   created_at <chr>, updated_at <chr>, closed_at <lgl>,\n#   author_association <chr>, active_lock_reason <chr>, body <chr>,\n#   reactions <df[,10]>, timeline_url <chr>, performed_via_github_app <lgl>, …\n```\n:::\n:::\n\n\n:::\n\n## Other examples with GitHub API\n\nFinally, I will leave you with a few other examples of using GitHub API: \n\n* [How long does it take to close a GitHub Issue in the `dplyr` package?](https://blog.exploratory.io/analyzing-issue-data-with-github-rest-api-63945017dedc)\n* [How to retrieve all commits for a branch](https://stackoverflow.com/questions/9179828/github-api-retrieve-all-commits-for-all-branches-for-a-repo)\n* [Getting my GitHub Activity](https://masalmon.eu/2017/12/21/wherehaveyoubeen/)\n\n\n# openFDA API\n\nNext, we will demonstrate how to request data from the API at [openFDA API](https://open.fda.gov), which returns JSON files.  \n\nThis API provides create easy access to public data, to create a new level of openness and accountability, to ensure the privacy and security of public FDA data, and ultimately to educate the public and save lives. See [data definitions](https://open.fda.gov/data/datadictionary) for all included data.\n\n## Register for an API Key\n\nFirst, you need to register for an API key here\n\n- <https://open.fda.gov/apis/authentication/>\n\nYou should also store the API key in your `.Renviron` like above for the GitHub API key. \n\n## Building the URL for `GET`\n\nFirst, we will request a summarized set of counts around food recalls either voluntary by a firm or mandated by the FDA. \n\nThe URL we want is the following\n\n```\nhttps://api.fda.gov/food/enforcement.json?api_key=<your_API_key_here>&count=voluntary_mandated.exact\n```\n\nLet's build up the URL. \n\n- The first is the base URL: `https://api.fda.gov/food/enforcement.json`. This part of the URL **will be the same for all our calls** to the food enforcement API (but is different if you want to investigate e.g. patient responses from drugs).\n- Next, `?apiKey=<your_API_key_here>` is how I use my authorization token, which tells the openFDA servers that I am allowed to ask for this data.\n- Finally, we want to return a set of summarized counts for a specific field (`&count=voluntary_mandated.exact`)\n\nNow that we have dissected the anatomy of an API, you can see how easy it is to build them!\n\nBasically anybody with an internet connection, an authorization token, and who knows the grammar of the API can access it. Most APIs are published with extensive documentation to help you understand the available options and parameters.\n\n\n## Calling an API with `GET`\n\nLet's join the URL together: \n\n\n::: {.cell}\n\n```{.r .cell-code}\n## extract my API from `.Renviron`\nopenFDA_key <- Sys.getenv(\"OPENFDA_API_KEY\")\n\n## build the URL\nbase <- 'https://api.fda.gov/food/enforcement.json?api_key='\nquery <- '&count=voluntary_mandated.exact'\n\n## put it all together\nAPI_URL <- paste0(base, openFDA_key, query)\n```\n:::\n\n\nNow we have the entire URL stored in a simple R object called `API_URL`.\n\nWe can now use the URL to call the API, and we will store the returned data in an object called `raw_data`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nraw_data <- GET(API_URL)\nraw_data\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nResponse [https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact]\n  Date: 2023-11-24 10:21\n  Status: 200\n  Content-Type: application/json; charset=utf-8\n  Size: 711 B\n{\n  \"meta\": {\n    \"disclaimer\": \"Do not rely on openFDA to make decisions regarding medical...\n    \"terms\": \"https://open.fda.gov/terms/\",\n    \"license\": \"https://open.fda.gov/license/\",\n    \"last_updated\": \"2023-11-22\"\n  },\n  \"results\": [\n    {\n      \"term\": \"Voluntary: Firm initiated\",\n...\n```\n:::\n:::\n\n\n:::{.callout-tip}\n\n### Pro-tip\n\nWe can see `status` element of the list. Traditionally, a status of “200” means that the API call was successful, and other codes are used to indicate errors. You can troubleshoot those error codes using the API documentation.\n\n:::\n\nNext, we can inspect the object and we see that it is a list.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(raw_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 10\n $ url        : chr \"https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact\"\n $ status_code: int 200\n $ headers    :List of 22\n  ..$ date                            : chr \"Fri, 24 Nov 2023 10:21:51 GMT\"\n  ..$ content-type                    : chr \"application/json; charset=utf-8\"\n  ..$ vary                            : chr \"Accept-Encoding\"\n  ..$ access-control-allow-credentials: chr \"true\"\n  ..$ access-control-allow-origin     : chr \"*\"\n  ..$ age                             : chr \"0\"\n  ..$ cache-control                   : chr \"no-cache, no-store, must-revalidate\"\n  ..$ content-security-policy         : chr \"default-src 'none'\"\n  ..$ etag                            : chr \"W/\\\"2c7-D4yYChONTPyF2qQYL1Qita83Uu4\\\"\"\n  ..$ strict-transport-security       : chr \"max-age=31536000;\"\n  ..$ strict-transport-security       : chr \"max-age=31536000; preload\"\n  ..$ vary                            : chr \"Accept-Encoding\"\n  ..$ via                             : chr \"https/1.1 api-umbrella (ApacheTrafficServer [cMsSf ])\"\n  ..$ x-api-umbrella-request-id       : chr \"cc03cq16o9mdgfjlqf30\"\n  ..$ x-cache                         : chr \"MISS\"\n  ..$ x-content-type-options          : chr \"nosniff\"\n  ..$ x-ratelimit-limit               : chr \"240\"\n  ..$ x-ratelimit-remaining           : chr \"239\"\n  ..$ x-vcap-request-id               : chr \"d6a63001-2511-441a-4dab-58c1ab363d6d\"\n  ..$ x-xss-protection                : chr \"1; mode=block\"\n  ..$ x-frame-options                 : chr \"deny\"\n  ..$ content-encoding                : chr \"gzip\"\n  ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ all_headers:List of 1\n  ..$ :List of 3\n  .. ..$ status : int 200\n  .. ..$ version: chr \"HTTP/2\"\n  .. ..$ headers:List of 22\n  .. .. ..$ date                            : chr \"Fri, 24 Nov 2023 10:21:51 GMT\"\n  .. .. ..$ content-type                    : chr \"application/json; charset=utf-8\"\n  .. .. ..$ vary                            : chr \"Accept-Encoding\"\n  .. .. ..$ access-control-allow-credentials: chr \"true\"\n  .. .. ..$ access-control-allow-origin     : chr \"*\"\n  .. .. ..$ age                             : chr \"0\"\n  .. .. ..$ cache-control                   : chr \"no-cache, no-store, must-revalidate\"\n  .. .. ..$ content-security-policy         : chr \"default-src 'none'\"\n  .. .. ..$ etag                            : chr \"W/\\\"2c7-D4yYChONTPyF2qQYL1Qita83Uu4\\\"\"\n  .. .. ..$ strict-transport-security       : chr \"max-age=31536000;\"\n  .. .. ..$ strict-transport-security       : chr \"max-age=31536000; preload\"\n  .. .. ..$ vary                            : chr \"Accept-Encoding\"\n  .. .. ..$ via                             : chr \"https/1.1 api-umbrella (ApacheTrafficServer [cMsSf ])\"\n  .. .. ..$ x-api-umbrella-request-id       : chr \"cc03cq16o9mdgfjlqf30\"\n  .. .. ..$ x-cache                         : chr \"MISS\"\n  .. .. ..$ x-content-type-options          : chr \"nosniff\"\n  .. .. ..$ x-ratelimit-limit               : chr \"240\"\n  .. .. ..$ x-ratelimit-remaining           : chr \"239\"\n  .. .. ..$ x-vcap-request-id               : chr \"d6a63001-2511-441a-4dab-58c1ab363d6d\"\n  .. .. ..$ x-xss-protection                : chr \"1; mode=block\"\n  .. .. ..$ x-frame-options                 : chr \"deny\"\n  .. .. ..$ content-encoding                : chr \"gzip\"\n  .. .. ..- attr(*, \"class\")= chr [1:2] \"insensitive\" \"list\"\n $ cookies    :'data.frame':\t0 obs. of  7 variables:\n  ..$ domain    : logi(0) \n  ..$ flag      : logi(0) \n  ..$ path      : logi(0) \n  ..$ secure    : logi(0) \n  ..$ expiration: 'POSIXct' num(0) \n  ..$ name      : logi(0) \n  ..$ value     : logi(0) \n $ content    : raw [1:711] 7b 0a 20 20 ...\n $ date       : POSIXct[1:1], format: \"2023-11-24 10:21:51\"\n $ times      : Named num [1:6] 0 0.062 0.137 0.218 0.386 ...\n  ..- attr(*, \"names\")= chr [1:6] \"redirect\" \"namelookup\" \"connect\" \"pretransfer\" ...\n $ request    :List of 7\n  ..$ method    : chr \"GET\"\n  ..$ url       : chr \"https://api.fda.gov/food/enforcement.json?api_key=6cz2JMCPEw0gxiI8GtZeZXDD6wt1J3aM3Mp9rDDE&count=voluntary_mandated.exact\"\n  ..$ headers   : Named chr \"application/json, text/xml, application/xml, */*\"\n  .. ..- attr(*, \"names\")= chr \"Accept\"\n  ..$ fields    : NULL\n  ..$ options   :List of 2\n  .. ..$ useragent: chr \"libcurl/8.1.2 r-curl/5.1.0 httr/1.4.7\"\n  .. ..$ httpget  : logi TRUE\n  ..$ auth_token: NULL\n  ..$ output    : list()\n  .. ..- attr(*, \"class\")= chr [1:2] \"write_memory\" \"write_function\"\n  ..- attr(*, \"class\")= chr \"request\"\n $ handle     :Class 'curl_handle' <externalptr> \n - attr(*, \"class\")= chr \"response\"\n```\n:::\n:::\n\n\nOne of the elements is `content` and we can inspect that\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstr(raw_data$content)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n raw [1:711] 7b 0a 20 20 ...\n```\n:::\n:::\n\n\nWe see the actual data have been stored as raw vectors (or raw bytes), which need to be converted to character vectors. This is not in a useable format yet. \n\n## Converting JSON to a `data.frame`\n\nThere is a function in base R `rawTo_Char()` that converts raw bytes to characters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nopenFDA_data <- fromJSON(rawToChar(raw_data$content), flatten = TRUE)\n```\n:::\n\n\nThis converts the raw data into a list. \n\n:::{.callout-note}\n\nWe can also do this with `httr::content` (as above) and just define the encoding for the character set. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nopenFDA_data <- fromJSON(httr::content(raw_data, \n                                       as = 'text', \n                                       encoding =  \"UTF-8\"))\nstr(openFDA_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 2\n $ meta   :List of 4\n  ..$ disclaimer  : chr \"Do not rely on openFDA to make decisions regarding medical care. While we make every effort to ensure that data\"| __truncated__\n  ..$ terms       : chr \"https://open.fda.gov/terms/\"\n  ..$ license     : chr \"https://open.fda.gov/license/\"\n  ..$ last_updated: chr \"2023-11-22\"\n $ results:'data.frame':\t4 obs. of  2 variables:\n  ..$ term : chr [1:4] \"Voluntary: Firm initiated\" \"Voluntary: Firm Initiated\" \"FDA Mandated\" \"\"\n  ..$ count: int [1:4] 24217 563 397 6\n```\n:::\n:::\n\n\n:::\n\nNow that it is in a list format, you can see that it actually contains several data frames!\n\nYou can use this data right away if you are already familiar with lists in R, or you can extract the data frames into separate objects, like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nts_df <- openFDA_data$results\nts_df\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                       term count\n1 Voluntary: Firm initiated 24217\n2 Voluntary: Firm Initiated   563\n3              FDA Mandated   397\n4                               6\n```\n:::\n:::\n\n\nWe could wrangle and visualize the data from here. \n\n\n# Post-lecture materials\n\n## Other good R packages to know about \n\n- [googlesheets4](https://cran.r-project.org/web/packages/googlesheets4/index.html) to interact with Google Sheets in R\n- [googledrive](https://googledrive.tidyverse.org/) to interact with files on your Google Drive\n\n## Final Questions\n\nHere are some post-lecture questions to help you think about the material discussed.\n\n::: callout-note\n### Questions\n\n1.  Using the GitHub API, access the repository information and ask how many open github issues you have?\n2. Pick another API that we have not discussed here and use `httr` to retreive data from it. \n:::\n\n## Additional Resources\n\n::: callout-tip\n- <https://jeroen.cran.dev/jsonlite>\n- <https://httr.r-lib.org>\n:::\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}